<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>学习 on Yan Tang</title><link>https://ehehe.cn/categories/%E5%AD%A6%E4%B9%A0/</link><description>Recent content in 学习 on Yan Tang</description><generator>Hugo -- 0.152.2</generator><language>zh-cn</language><lastBuildDate>Wed, 05 Nov 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://ehehe.cn/categories/%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml"/><item><title>深入理解 PyTorch SGD 优化器参数</title><link>https://ehehe.cn/posts/2025/03-pytorch-sgd-optimizer/</link><pubDate>Wed, 05 Nov 2025 00:00:00 +0000</pubDate><guid>https://ehehe.cn/posts/2025/03-pytorch-sgd-optimizer/</guid><description>本文通过可视化损失函数和梯度下降路径，深入探讨了 PyTorch SGD 优化器中的各种参数（如动量、权重衰减、Nesterov 动量、动量抑制因子等）对简单线性回归问题的影响，以深入理解神经网络训练中的复杂性。</description></item><item><title>基于 NeRF 的三维场景生成</title><link>https://ehehe.cn/posts/2024/01-nerf/</link><pubDate>Thu, 29 Feb 2024 14:20:32 +0000</pubDate><guid>https://ehehe.cn/posts/2024/01-nerf/</guid><description>基于 NeRF 的三维场景生成</description></item><item><title>词嵌入方法（Word2Vec）</title><link>https://ehehe.cn/posts/2024/02-word2vec/</link><pubDate>Wed, 28 Feb 2024 23:06:29 +0000</pubDate><guid>https://ehehe.cn/posts/2024/02-word2vec/</guid><description>本篇文章介绍了Word2Vec方法，该方法通过在给定中心词的情况下预测上下文词的概率来学习单词的分布式表示，从而克服了独热表示的缺点，提高了词汇相似度的表达能力。</description></item><item><title>Swin Transformer：层级式特征图与移动窗口注意力机制</title><link>https://ehehe.cn/posts/2023/02-swin-transformer/</link><pubDate>Wed, 09 Aug 2023 00:00:00 +0000</pubDate><guid>https://ehehe.cn/posts/2023/02-swin-transformer/</guid><description>Swin Transformer 是一种创新的 Vision Transformer 架构，通过引入层级式特征图和移动窗口注意力机制，解决了 Vision Transformer 在计算复杂度和多尺度特征提取方面的限制，使其成为计算机视觉任务中高效的骨干网络。</description></item><item><title>Vision Transformer —— 图像识别中的 Transformer 架构</title><link>https://ehehe.cn/posts/2023/01-vit/</link><pubDate>Wed, 26 Jul 2023 15:27:24 +0000</pubDate><guid>https://ehehe.cn/posts/2023/01-vit/</guid><description>本文介绍了 Vision Transformer (ViT) 的核心概念，包括如何将 Transformer 架构应用于图像识别任务，以及与传统 CNNs 的比较。</description></item><item><title>DeepLabv2：基于空洞卷积与 ASPP 的语义图像分割</title><link>https://ehehe.cn/posts/2023/07-deeplabv2/</link><pubDate>Tue, 04 Jul 2023 00:00:00 +0000</pubDate><guid>https://ehehe.cn/posts/2023/07-deeplabv2/</guid><description>DeepLabv2 通过空洞卷积和上采样滤波器进行密集特征提取，将在图像分类上训练的网络重新用于语义分割任务。文中进一步提出ASPP以在多个尺度上编码对象以及图像上下文。为了产生语义准确的预测和精细的物体边界分割图，文中还结合了深度卷积神经网络和全连接条件随机场的思想。</description></item><item><title>机器学习中的爱因斯坦求和（Einsums）</title><link>https://ehehe.cn/posts/2022/01-einsums/</link><pubDate>Sun, 20 Mar 2022 12:32:44 +0000</pubDate><guid>https://ehehe.cn/posts/2022/01-einsums/</guid><description>机器学习中的爱因斯坦求和（Einsums）</description></item></channel></rss>