<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Swin Transformer：层级式特征图与移动窗口注意力机制 | Yan Tang</title><meta name=keywords content="Swin Transformer,Transformer"><meta name=description content="Swin Transformer 是一种创新的 Vision Transformer 架构，通过引入层级式特征图和移动窗口注意力机制，解决了 Vision Transformer 在计算复杂度和多尺度特征提取方面的限制，使其成为计算机视觉任务中高效的骨干网络。"><meta name=author content="Yan Tang"><link rel=canonical href=https://ehehe.cn/posts/2023/02-swin-transformer/><link crossorigin=anonymous href=/assets/css/stylesheet.16688c28815fab2857aba83927b88054dc9027b8a2b37dd2c695d9111db01da3.css integrity="sha256-FmiMKIFfqyhXq6g5J7iAVNyQJ7iis33SxpXZER2wHaM=" rel="preload stylesheet" as=style><link rel=icon href=https://ehehe.cn/assets/images/favicon-16x16.ico><link rel=icon type=image/png sizes=16x16 href=https://ehehe.cn/assets/images/favicon-16x16.ico><link rel=icon type=image/png sizes=32x32 href=https://ehehe.cn/assets/images/favicon-32x32.ico><link rel=apple-touch-icon href=https://ehehe.cn/assets/images/apple-touch-icon.png><link rel=mask-icon href=https://ehehe.cn/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ehehe.cn/posts/2023/02-swin-transformer/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.css integrity=sha384-WcoG4HRXMzYzfCgiyfrySxx90XSl2rxY5mnVY5TwtWE6KLrArNKn0T/mOgNL0Mmi crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.js integrity=sha384-J+9dG2KMoiR9hqcFao0IBLwxt6zpcyN68IgwzsCSkbreXUjmNVRhPFTssqdSGjwQ crossorigin=anonymous></script><meta property="og:url" content="https://ehehe.cn/posts/2023/02-swin-transformer/"><meta property="og:site_name" content="Yan Tang"><meta property="og:title" content="Swin Transformer：层级式特征图与移动窗口注意力机制"><meta property="og:description" content="Swin Transformer 是一种创新的 Vision Transformer 架构，通过引入层级式特征图和移动窗口注意力机制，解决了 Vision Transformer 在计算复杂度和多尺度特征提取方面的限制，使其成为计算机视觉任务中高效的骨干网络。"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-08-09T00:00:00+00:00"><meta property="article:modified_time" content="2023-08-09T00:00:00+00:00"><meta property="article:tag" content="Swin Transformer"><meta property="article:tag" content="Transformer"><meta name=twitter:card content="summary"><meta name=twitter:title content="Swin Transformer：层级式特征图与移动窗口注意力机制"><meta name=twitter:description content="Swin Transformer 是一种创新的 Vision Transformer 架构，通过引入层级式特征图和移动窗口注意力机制，解决了 Vision Transformer 在计算复杂度和多尺度特征提取方面的限制，使其成为计算机视觉任务中高效的骨干网络。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://ehehe.cn/posts/"},{"@type":"ListItem","position":2,"name":"Swin Transformer：层级式特征图与移动窗口注意力机制","item":"https://ehehe.cn/posts/2023/02-swin-transformer/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Swin Transformer：层级式特征图与移动窗口注意力机制","name":"Swin Transformer：层级式特征图与移动窗口注意力机制","description":"Swin Transformer 是一种创新的 Vision Transformer 架构，通过引入层级式特征图和移动窗口注意力机制，解决了 Vision Transformer 在计算复杂度和多尺度特征提取方面的限制，使其成为计算机视觉任务中高效的骨干网络。","keywords":["Swin Transformer","Transformer"],"articleBody":"ViT 证明了一个经过简单调整的普通 Transformer，可以在 ImageNet 数据集上与最有效的 CNN 达到差不多甚至更好的效果，但它尚未用于其他视觉任务（例如：目标检测、语义分割等）。Swin Transformer 的提出正是为了解决这一问题，由于其在各项视觉任务中具有优异的性能，因此是目前常用的一种骨干网络。\nViT 直接用于目标检测、语义分割等任务，会存在一些问题，最明显的两个是：（1）ViT 的计算复杂度与图像大小成平方关系；（2）ViT 中单一尺度、固定大小的图像块（16×1616 \\times 1616×16）不适用于处理具有多尺度目标的视觉问题。\nSwin Transformer 作为 ViT 的改进，引入了两个关键的方法：层级式的特征图 和 移动窗口的注意力机制。Swin 的名字也正是来自移动窗口（Shifted windows）。Swin Transformer 由于引入了这两个改进，所以在方法上相对要复杂不少。\nSwin Transformer 整体架构图，展示了从输入图像到输出特征的完整流程，包括Patch Partition、Linear Embedding、Swin Transformer Block 和 Patch Merging 等核心组件。\n网络结构 上图展示了 Swin Transformer 的架构图，输入图像首先通过 Patch Partition 模块分割成不重叠的 Patch，每个 Patch 视作一个 “token”。在这个 Patch 的基础上使用一个 Linear Embedding 模块，将其投影到任意的嵌入维度。\n后面则是交替使用的 “Swin Transformer Block 模块” 和 “Patch Merging 模块”，这两个模块是 Swin Transformer 的主要组成部分。Patch Merging 模块得作用是将输入特征分辨率降低一倍，通道数增加一倍，对应于 CNN 中的降采样过程。Swin Transformer Block 模块用于进行特征变换，其输入和输出的形状是相同的。\n由此，可以看到，Swin Transformer 是将 Transformer 和常用的 VGG、ResNet 等网络联系起来了。Swin Transformer 同样可以生成多尺度的特征图，直接替换现有方法中的骨干网，应用于各种下游视觉任务。\nStage Layer Input shape Output shape Input Patch partition (H,W,3)(\\mathrm{H}, \\mathrm{W}, 3)(H,W,3) (H/4, W/4,48)(\\mathrm{H} / 4, \\mathrm{~W} / 4,48)(H/4, W/4,48) Stage1 Linear Embedding (H/4, W/4,48)(\\mathrm{H} / 4, \\mathrm{~W} / 4,48)(H/4, W/4,48) (H/4, W/4,C)(\\mathrm{H} / 4, \\mathrm{~W} / 4, \\mathrm{C})(H/4, W/4,C) Swin Transformer blocks 不改变形状 Stage2 Patch merging (H/4, W/4,C)(\\mathrm{H} / 4, \\mathrm{~W} / 4, \\mathrm{C})(H/4, W/4,C) (H/8,H/8,4C)(\\mathrm{H} / 8, \\mathrm{H} / 8,4 \\mathrm{C})(H/8,H/8,4C) Linear projection (H/8,H/8,4C)(\\mathrm{H} / 8, \\mathrm{H} / 8,4 \\mathrm{C})(H/8,H/8,4C) (H/8,H/8,2C)(\\mathrm{H} / 8, \\mathrm{H} / 8,2 \\mathrm{C})(H/8,H/8,2C) Swin Transformer blocks 不改变形状 Stage3 Patch merging (H/8,H/8,2C)(\\mathrm{H} / 8, \\mathrm{H} / 8,2 \\mathrm{C})(H/8,H/8,2C) (H/16,H/16,8C)(H / 16, H / 16,8 C)(H/16,H/16,8C) Linear projection (H/16,H/16,8C)(H / 16, H / 16,8 C)(H/16,H/16,8C) (H/16,H/16,4C)(H / 16, H / 16,4 C)(H/16,H/16,4C) Swin Transformer blocks 不改变形状 Stage4 Patch merging (H/16,H/16,4C)(\\mathrm{H} / 16, \\mathrm{H} / 16,4 \\mathrm{C})(H/16,H/16,4C) (H/32,H/32,16C)(\\mathrm{H} / 32, \\mathrm{H} / 32,16 \\mathrm{C})(H/32,H/32,16C) Linear projection (H/32,H/32,16C)(\\mathrm{H} / 32, \\mathrm{H} / 32,16 \\mathrm{C})(H/32,H/32,16C) (H/32,H/32,8C)(\\mathrm{H} / 32, \\mathrm{H} / 32,8 \\mathrm{C})(H/32,H/32,8C) Swin Transformer blocks 不改变形状 1. Patch Partition / Linear Embedding 第一步是将输入图像分块，变成 Patch Embedding，这与 ViT 中是完全相同的。不同的是，ViT 中的 Patch 大小为 16×1616 \\times 1616×16，在 Swin Transformer 中使用了 4×44 \\times 44×4 大小的 Patch，并且嵌入的维度为 969696。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class PatchEmbedding(nn.Module): def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768): super().__init__() self.img_size = img_size self.patch_size = patch_size self.n_patches = (img_size // patch_size) ** 2 self.patch_size = patch_size self.in_chans = in_chans self.embed_dim = embed_dim self.proj = nn.Conv2d( in_chans, embed_dim, kernel_size=patch_size, stride=patch_size ) def forward(self, x): # proj: [B, 3, H, W] -\u003e [B, embed, n_patch_h, n_patch_w] # flatten: [B, embed, n_patch_h, n_patch_w] -\u003e [B, embed, n_patch] # transpose: [B, embed, n_patch] -\u003e [B, n_patch, embed] x = self.proj(x).flatten(2).transpose(1, 2) return x 1 2 3 4 5 x = torch.randn(1, 3, 224, 224) patch_embed = PatchEmbedding(img_size=224, patch_size=4, embed_dim=96) patch_embed(x).shape \u003e\u003e torch.Size([1, 3136, 96]) 可以看到，此时 Patch 的数量为 313631363136，每个 Patch 的维度为 969696，对应特征图的话，即 (56,56,96)(56, 56, 96)(56,56,96) 大小。\nPatch 的数量相比较 ViT 中的 196196196 要多出很多。由于注意力机制的复杂度是 O(N2)\\mathcal{O}(N^2)O(N2) 的，如果直接使用普通的 Transformer Block 会变得比较低效，因此，Swin Transformer 中提出了对全局注意力机制的改进。\n2. Patch Merging Patch Merging 将 2×22 \\times 22×2 大小的窗口中的特征沿深度方向堆叠起来，然后进行合并，最后在 4C4C4C 的特征维度上使用线性层，将特征减少为 2C2C2C。\n这一操作其实是完成了CNN中的下采样操作，空间分辨率减低一倍的同时，特征通道数增加一倍。\nPatch Merging 操作示意图：将 2×2 相邻窗口的特征沿深度方向堆叠，实现特征图分辨率的降低和通道数的增加，相当于 CNN 中的下采样过程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class PatchMerging(nn.Module): def __init__(self, input_resolution, dim): super().__init__() self.input_resolution = input_resolution self.dim = dim self.norm = nn.LayerNorm(dim * 4) self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False) def forward(self, x): H, W = self.input_resolution B, n_patch, C = x.shape x = x.view(B, H, W, C) # [B, n_patch, C] -\u003e [B, H, W, C] x0 = x[:, 0::2, 0::2, :] # [B, H, W, C] -\u003e [B, H/2, W/2, C] x1 = x[:, 1::2, 0::2, :] # [B, H, W, C] -\u003e [B, H/2, W/2, C] x2 = x[:, 0::2, 1::2, :] # [B, H, W, C] -\u003e [B, H/2, W/2, C] x3 = x[:, 1::2, 1::2, :] # [B, H, W, C] -\u003e [B, H/2, W/2, C] x = torch.cat([x0, x1, x2, x3], dim=-1) # [B, H/2, W/2, 4*C] x = x.view(B, -1, 4 * C) # [B, H/2, W/2, 4*C] -\u003e [B, n_patch/4, 4*C] x = self.norm(x) x = self.reduction(x) # [B, n_patch/4, 4*C] -\u003e [B, n_patch/4, 2*C] return x 1 2 3 4 5 x = torch.randn(1, 56 * 56, 96)\t# input feature map: (56, 56, 96) patch_merge = PatchMerging(input_resolution=(56, 56), dim=96) patch_merge(x).shape \u003e\u003e torch.Size([1, 784, 192]) # output feature map: (28, 28, 192) 在 Swin Transformer 中，正是通过 Patch Merging 的方式，完成了层级式特征图的获取。这样，就将 Transformer 和卷积神经网络（如：VGG、ResNet）对等起来了，现在 Transformer 也可以提取不同层级的、多尺度特征了。\nSwin Transformer 生成的层级式特征图，展示了 3 个不同阶段的特征分辨率变化，实现多尺度特征提取。\n3. Swin Transformer Block Swin Transformer Block 包含两种类型，每一种类型都由一个标准化层，一个注意力模块，另一个标准化层和一个 MLP 层组成，这与普通的 Transformer Block 是一样的。\n不同的地方在于，Swin Transformer Block 中使用的两种注意力机制：窗口自注意力（W-MSA）模块、移动窗口的自注意力（SW-MSA）模块。\n在实际使用中，W-MSA 和 SW-MSA 通常会连续使用。这一点也可以从 Swin Transformer 不同阶段的设计中看出，其每个阶段包含的 Swin Transformer Block 都是偶数个。\nSwin Transformer Block 结构图，展示了一个 Block 中包含的 LayerNorm、W-MSA/SW-MSA 注意力模块和 MLP 层的完整组合。\n4. 移动窗口自注意力 ViT 中使用的标准多头自注意力执行全局自注意力，并计算每个 Patch 与其他所有 Patch 之间的关系。这导致与 Patch 的数量呈平方复杂性，使其不适用于高分辨率图像。\n为了计算的高效性，Swin Transformer 使用基于窗口的多头自注意力方法。窗口就是一个不重叠的 Patch 的集合，并且 注意力计算仅在每个窗口内部进行。\n但是，这种窗口化的自注意力机制限制了只有窗口内的 Patch 之间能进行交互，限制了模型的能力。为了引入窗口之间的交互，同时保持非重叠窗口的高效计算，文中引入了移动窗口的注意力。通过 交替使用窗口自注意力和移动窗口自注意力 来实现。\n（1）窗口自注意力 窗口自注意力将输入特征图均匀地、非重叠地分割成不同的窗口。假设输入特征图包含 h×wh \\times wh×w 个 Patch，窗口大小为 MMM（默认情况下 M=7M=7M=7），全局的 MSA 模块和窗口的 MSA 模块的计算复杂度分别为：\nΩ( MSA )=4hwC2+2(hw)2CΩ( W-MSA )=4hwC2+2M2hwC \\begin{aligned} \u0026 \\Omega(\\text { MSA })=4 h w C^2+2(h w)^2 C \\\\ \u0026 \\Omega(\\text { W-MSA })=4 h w C^2+2 M^2 h w C \\end{aligned} ​Ω( MSA )=4hwC2+2(hw)2CΩ( W-MSA )=4hwC2+2M2hwC​可以看到，MSA 随着 Patch 数量的增加成平方级别增加，W-MSA 则是线性的。\n对于矩阵 A(m×n)\\mathbf{A}(m \\times n)A(m×n) 和矩阵 B(n×p)B(n \\times p)B(n×p)，那么 A×B\\mathbf{A} \\times \\mathbf{B}A×B 的复杂度为 O(m⋅n⋅p)\\mathcal{O}(m \\cdot n \\cdot p)O(m⋅n⋅p)，下面用一段简单的代码解释这一复杂度计算：\n1 2 3 4 5 6 7 for (int i = 0; i \u003c m; i++) {\t// A矩阵中的m行 for (int j = 0; i \u003c p; j++) {\t// B矩阵中的p列 for (int k = 0; k \u003c n; k++) {\t// A矩阵中的n列或B矩阵中的n行 C[i][j] = C[i][j] + A[i][k] * B[k][j]; } } } 对于全局的多头自注意力（MSA），如下面的示意图，在计算过程中，有四个线性层，分别是将输入映射到 Q\\mathbf{Q}Q、K\\mathbf{K}K、V\\mathbf{V}V，以及将注意力结果映射到输出 Out\\mathbf{Out}Out。这四个线性层的计算是相同的，即 (N,C)×(C,C)(N, C) \\times (C, C)(N,C)×(C,C)。因此，这四个线性层的计算量为：4NC24NC^24NC2。\n在注意力部分，首先是 QKT\\mathbf{Q}\\mathbf{K}^{\\mathrm{T}}QKT，即 (N,C)×(C,N)(N, C) \\times (C, N)(N,C)×(C,N)，这一步的计算量为 N2CN^2CN2C。这里忽略 scale 和 Softmax 的计算量。然后是 Attn×V\\mathbf{Attn} \\times \\mathbf{V}Attn×V，即 (N,N)×(N,C)(N, N) \\times (N, C)(N,N)×(N,C)，这一步的计算量也是 N2CN^2CN2C。\n考虑到这里一共有 h×wh \\times wh×w 个 Patch（N=h×wN = h \\times wN=h×w），于是，MSA 的计算复杂度为：4NC2+2N2C=4hwC2+2(hw)2C4NC^2+2N^2C = 4hwC^2+2(hw)^2C4NC2+2N2C=4hwC2+2(hw)2C。\n标准多头自注意力模块结构图，展示了输入经过 QQQ、KKK、VVV 线性变换后，通过注意力计算和输出映射的完整流程。\n对于窗口自注意力（W-MSA），先考虑每个窗口内的计算量，即 N=M2N=M^2N=M2，则每个窗口内的计算量为：4M2C2+2M4C4M^2C^2+2M^4C4M2C2+2M4C。考虑到有 hM×wM\\frac{h}{M} \\times \\frac{w}{M}Mh​×Mw​ 个窗口：\nΩ(W-MSA)=hM×wM×(4M2C2+2M4C)=4hwC2+2M2hwC \\begin{align} \\Omega(\\text{W-MSA}) \u0026= \\frac{h}{M} \\times \\frac{w}{M} \\times \\left(4M^2C^2+2M^4C\\right) \\\\ \u0026= 4 h w C^2+2 M^2 h w C \\end{align} Ω(W-MSA)​=Mh​×Mw​×(4M2C2+2M4C)=4hwC2+2M2hwC​​（2）移动窗口 为了引入跨窗口的连接，移动窗口的自注意力将窗口向右下移动 ⌊M2⌋\\left\\lfloor\\frac{M}{2}\\right\\rfloor⌊2M​⌋ 的大小。这样原来的窗口就可以与其相邻的窗口建立联系。\n然而，这种操作会出现一些大小不一的窗口，比如下图中展示的窗口 AAA、BBB 和 CCC。这些窗口可以通过 Pad 的方式填充成 M×MM \\times MM×M 大小的窗口进行。然而，为了避免增加计算量，文中提出了 循环移位（Cyclic Shift） 的方式，将一些不完整的 Patch 移动到一起，形成完整的窗口。\n移动窗口自注意力示意图：通过循环移位将窗口向右下移动 ⌊M2⌋\\left\\lfloor\\frac{M}{2}\\right\\rfloor⌊2M​⌋ 个位置，使原始窗口能够与相邻窗口建立联系，解决非重叠窗口缺乏跨窗口交互的问题。\n需要注意的是，这种移动之后，一个窗口可能由原始特征图中非相邻的 Patch 组成。因此，在计算过程中，对于这类窗口需要 使用掩码来限制自注意力只作用于相邻的 Patch。\n这种循环移位的操作是为了计算上的效率，在计算完成后，需要使用 逆循环移位（Reverse Cyclic Shift） 将特征图还原。\n下面是生成注意力掩码的 PyTorch 代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 import torch import matplotlib.pyplot as plt def window_partition(x, window_size): \"\"\" Partitions the given input into windows. Args: x: (B, H, W, C) window_size (int): window size Returns: windows: (num_windows*B, window_size, window_size, C) \"\"\" B, H, W, C = x.shape x = x.view(B, H // window_size, window_size, W // window_size, window_size, C) windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C) return windows window_size = 7 shift_size = window_size // 2 H, W = 14, 14 img_mask = torch.zeros((1, H, W, 1)) # 1 H W 1 h_slices = (slice(0, -window_size), slice(-window_size, -shift_size), slice(-shift_size, None)) w_slices = (slice(0, -window_size), slice(-window_size, -shift_size), slice(-shift_size, None)) cnt = 0 for h in h_slices: for w in w_slices: img_mask[:, h, w, :] = cnt cnt += 1 mask_windows = window_partition(img_mask, window_size) # nW, window_size, window_size, 1 mask_windows = mask_windows.view(-1, window_size * window_size) attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2) attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0)) plt.matshow(img_mask[0, :, :, 0].numpy()) plt.matshow(attn_mask[0].numpy()) plt.matshow(attn_mask[1].numpy()) plt.matshow(attn_mask[2].numpy()) plt.matshow(attn_mask[3].numpy()) plt.show() 注意力掩码可视化结果：左侧为不同区域的划分，右侧为对应窗口的注意力掩码矩阵。\n（3）相对位置偏差（Relative Position Bias） 在普通的 Transformer 中，使用 位置编码 给模型提供序列中元素的位置信息。在 Swin Transformer 中，不直接给输入添加位置编码，而是在自注意力机制中引入 相对位置偏差。加入了相对位置编码的注意力计算：\nAttention(Q,K,V)=softmax(QKT+Bdk)V \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^{\\mathrm{T}} + {\\color{Red} B} }{\\sqrt{d_k}}\\right) V Attention(Q,K,V)=softmax(dk​​QKT+B​)V假设窗口大小为 MMM，则 Q,K,V∈RM2×dkQ, K, V \\in \\mathbb{R}^{M^2 \\times d_k}Q,K,V∈RM2×dk​，B∈RM2×M2B \\in \\mathbb{R}^{M^2 \\times M^2}B∈RM2×M2。\n相对位置偏差在自注意力计算中的应用：在 QKTQK^{\\mathrm{T}}QKT 的基础上添加可学习的相对位置偏差矩阵 BBB，为模型提供位置信息。\n在窗口大小为 MMM 的情况下，每一个方向上的相对位置都在 [−M+1,M−1][-M+1, M-1][−M+1,M−1] 的范围中，例如：M=4→range[−3,3]M=4 \\rightarrow range [-3,3]M=4→range[−3,3]。这说明了相对位置可选的值最多只有 2M−12M-12M−1 种。因此，在代码实现中，是 预设了一个可学习的相对位置偏差的查询表 B^∈R(2M−1)×(2M−1)\\hat{B} \\in \\mathbb{R}^{(2 M-1) \\times(2 M-1)}B^∈R(2M−1)×(2M−1)，每一个 BBB 都是从 B^\\hat{B}B^ 中获取的。\n下面是获取相对位置偏置的 PyTorch 代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 参数 window_size = (4, 4) # 构建相对位置偏置的查询表 relative_position_bias_table = nn.Parameter( torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), heads) ) # 计算窗口内每个位置相对于其他位置之间的相对位置索引 coords_h = torch.arange(window_size[0]) coords_w = torch.arange(window_size[1]) coords = torch.stack(torch.meshgrid([coords_h, coords_w])) coords_flatten = torch.flatten(coords, 1) relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :] relative_coords = relative_coords.permute(1, 2, 0).contiguous() relative_coords[:, :, 0] += window_size[0] - 1 relative_coords[:, :, 1] += window_size[1] - 1 relative_coords[:, :, 0] *= 2 * window_size[1] - 1 relative_position_index = relative_coords.sum(-1) # 在前向推理过程中，就直接从查询表中按索引获取值 relative_position_bias = relative_position_bias_table[relative_position_index.view(-1)] relative_position_bias = relative_position_bias.view( window_size[0] * window_size[1], window_size[0] * window_size[1], -1 ) relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous() 下图以窗口大小 M=2M=2M=2 为例，展示了相对位置偏差的计算过程。\n相对位置偏差实现示意图（窗口大小 M=2M=2M=2）：展示如何通过相对位置索引从预设的查询表中获取对应的偏置值。\n参考资料 A Comprehensive Guide to Microsoft’s Swin Transformer Swin Transformer Swin Transformer 论文精读【论文精读】 ","wordCount":"1375","inLanguage":"en","datePublished":"2023-08-09T00:00:00Z","dateModified":"2023-08-09T00:00:00Z","author":{"@type":"Person","name":"Yan Tang"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://ehehe.cn/posts/2023/02-swin-transformer/"},"publisher":{"@type":"Organization","name":"Yan Tang","logo":{"@type":"ImageObject","url":"https://ehehe.cn/assets/images/favicon-16x16.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://ehehe.cn/ accesskey=h title="Yan Tang (Alt + H)">Yan Tang</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://ehehe.cn/ title=Posts><span>Posts</span></a></li><li><a href=https://ehehe.cn/about/ title=About><span>About</span></a></li><li><a href=https://ehehe.cn/publications/ title=Publications><span>Publications</span></a></li><li><a href=https://ehehe.cn/archives/ title=Archives><span>Archives</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Swin Transformer：层级式特征图与移动窗口注意力机制</h1><div class=post-meta><span title='2023-08-09 00:00:00 +0000 UTC'>August 9, 2023</span>&nbsp;·&nbsp;<span>7 min</span>&nbsp;·&nbsp;<span>Yan Tang</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e7%bd%91%e7%bb%9c%e7%bb%93%e6%9e%84 aria-label=网络结构>网络结构</a><ul><li><a href=#1-patch-partition--linear-embedding aria-label="1. Patch Partition / Linear Embedding">1. Patch Partition / Linear Embedding</a></li><li><a href=#2-patch-merging aria-label="2. Patch Merging">2. Patch Merging</a></li><li><a href=#3-swin-transformer-block aria-label="3. Swin Transformer Block">3. Swin Transformer Block</a></li><li><a href=#4-%e7%a7%bb%e5%8a%a8%e7%aa%97%e5%8f%a3%e8%87%aa%e6%b3%a8%e6%84%8f%e5%8a%9b aria-label="4. 移动窗口自注意力">4. 移动窗口自注意力</a><ul><li><a href=#1%e7%aa%97%e5%8f%a3%e8%87%aa%e6%b3%a8%e6%84%8f%e5%8a%9b aria-label=（1）窗口自注意力>（1）窗口自注意力</a></li><li><a href=#2%e7%a7%bb%e5%8a%a8%e7%aa%97%e5%8f%a3 aria-label=（2）移动窗口>（2）移动窗口</a></li><li><a href=#3%e7%9b%b8%e5%af%b9%e4%bd%8d%e7%bd%ae%e5%81%8f%e5%b7%aerelative-position-bias aria-label="（3）相对位置偏差（Relative Position Bias）">（3）相对位置偏差（Relative Position Bias）</a></li></ul></li></ul></li><li><a href=#%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99 aria-label=参考资料>参考资料</a></li></ul></div></details></div><div class=post-content><p>ViT 证明了一个经过简单调整的普通 Transformer，可以在 ImageNet 数据集上与最有效的 CNN 达到差不多甚至更好的效果，但它尚未用于其他视觉任务（例如：目标检测、语义分割等）。Swin Transformer 的提出正是为了解决这一问题，由于其在各项视觉任务中具有优异的性能，因此是目前常用的一种骨干网络。</p><p>ViT 直接用于目标检测、语义分割等任务，会存在一些问题，最明显的两个是：（1）ViT 的计算复杂度与图像大小成平方关系；（2）ViT 中单一尺度、固定大小的图像块（<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mo>×</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">16 \times 16</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7278em;vertical-align:-.0833em></span><span class=mord>16</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.6444em></span><span class=mord>16</span></span></span></span>）不适用于处理具有多尺度目标的视觉问题。</p><p>Swin Transformer 作为 ViT 的改进，引入了两个关键的方法：<strong>层级式的特征图</strong> 和 <strong>移动窗口的注意力机制</strong>。Swin 的名字也正是来自移动窗口（<strong>S</strong>hifted <strong>win</strong>dows）。Swin Transformer 由于引入了这两个改进，所以在方法上相对要复杂不少。</p><figure><img loading=lazy src=images/swin-transformer-architecture.png alt="Swin Transformer architecture"><figcaption><p>Swin Transformer 整体架构图，展示了从输入图像到输出特征的完整流程，包括Patch Partition、Linear Embedding、Swin Transformer Block 和 Patch Merging 等核心组件。</p></figcaption></figure><h2 id=网络结构>网络结构<a hidden class=anchor aria-hidden=true href=#网络结构>#</a></h2><p>上图展示了 Swin Transformer 的架构图，输入图像首先通过 Patch Partition 模块分割成不重叠的 Patch，每个 Patch 视作一个 “token”。在这个 Patch 的基础上使用一个 Linear Embedding 模块，将其投影到任意的嵌入维度。</p><p>后面则是交替使用的 “Swin Transformer Block 模块” 和 “Patch Merging 模块”，这两个模块是 Swin Transformer 的主要组成部分。Patch Merging 模块得作用是将输入特征分辨率降低一倍，通道数增加一倍，对应于 CNN 中的降采样过程。Swin Transformer Block 模块用于进行特征变换，其输入和输出的形状是相同的。</p><p>由此，可以看到，Swin Transformer 是将 Transformer 和常用的 VGG、ResNet 等网络联系起来了。Swin Transformer 同样可以生成多尺度的特征图，直接替换现有方法中的骨干网，应用于各种下游视觉任务。</p><table><thead><tr><th style=text-align:center>Stage</th><th style=text-align:center>Layer</th><th style=text-align:center>Input shape</th><th style=text-align:center>Output shape</th></tr></thead><tbody><tr><td style=text-align:center><strong>Input</strong></td><td style=text-align:center>Patch partition</td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">H</mi><mo separator="true">,</mo><mi mathvariant="normal">W</mi><mo separator="true">,</mo><mn>3</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathrm{H}, \mathrm{W}, 3)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathrm">H</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathrm" style=margin-right:.01389em>W</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>3</span><span class=mclose>)</span></span></span></span></td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>4</mn><mo separator="true">,</mo><mrow><mtext> </mtext><mi mathvariant="normal">W</mi></mrow><mi mathvariant="normal">/</mi><mn>4</mn><mo separator="true">,</mo><mn>48</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathrm{H} / 4, \mathrm{~W} / 4,48)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathrm">H</span><span class=mord>/4</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mspace nobreak"> </span><span class="mord mathrm" style=margin-right:.01389em>W</span></span><span class=mord>/4</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>48</span><span class=mclose>)</span></span></span></span></td></tr><tr><td style=text-align:center><strong>Stage1</strong></td><td style=text-align:center>Linear Embedding</td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>4</mn><mo separator="true">,</mo><mrow><mtext> </mtext><mi mathvariant="normal">W</mi></mrow><mi mathvariant="normal">/</mi><mn>4</mn><mo separator="true">,</mo><mn>48</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathrm{H} / 4, \mathrm{~W} / 4,48)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathrm">H</span><span class=mord>/4</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mspace nobreak"> </span><span class="mord mathrm" style=margin-right:.01389em>W</span></span><span class=mord>/4</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>48</span><span class=mclose>)</span></span></span></span></td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>4</mn><mo separator="true">,</mo><mrow><mtext> </mtext><mi mathvariant="normal">W</mi></mrow><mi mathvariant="normal">/</mi><mn>4</mn><mo separator="true">,</mo><mi mathvariant="normal">C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathrm{H} / 4, \mathrm{~W} / 4, \mathrm{C})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathrm">H</span><span class=mord>/4</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mspace nobreak"> </span><span class="mord mathrm" style=margin-right:.01389em>W</span></span><span class=mord>/4</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathrm">C</span><span class=mclose>)</span></span></span></span></td></tr><tr><td style=text-align:center></td><td style=text-align:center>Swin Transformer blocks</td><td style=text-align:center>不改变形状</td><td style=text-align:center></td></tr><tr><td style=text-align:center><strong>Stage2</strong></td><td style=text-align:center>Patch merging</td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>4</mn><mo separator="true">,</mo><mrow><mtext> </mtext><mi mathvariant="normal">W</mi></mrow><mi mathvariant="normal">/</mi><mn>4</mn><mo separator="true">,</mo><mi mathvariant="normal">C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathrm{H} / 4, \mathrm{~W} / 4, \mathrm{C})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathrm">H</span><span class=mord>/4</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mspace nobreak"> </span><span class="mord mathrm" style=margin-right:.01389em>W</span></span><span class=mord>/4</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathrm">C</span><span class=mclose>)</span></span></span></span></td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>8</mn><mo separator="true">,</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>8</mn><mo separator="true">,</mo><mn>4</mn><mi mathvariant="normal">C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathrm{H} / 8, \mathrm{H} / 8,4 \mathrm{C})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathrm">H</span><span class=mord>/8</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathrm">H</span><span class=mord>/8</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>4</span><span class="mord mathrm">C</span><span class=mclose>)</span></span></span></span></td></tr><tr><td style=text-align:center></td><td style=text-align:center>Linear projection</td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>8</mn><mo separator="true">,</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>8</mn><mo separator="true">,</mo><mn>4</mn><mi mathvariant="normal">C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathrm{H} / 8, \mathrm{H} / 8,4 \mathrm{C})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathrm">H</span><span class=mord>/8</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathrm">H</span><span class=mord>/8</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>4</span><span class="mord mathrm">C</span><span class=mclose>)</span></span></span></span></td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>8</mn><mo separator="true">,</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>8</mn><mo separator="true">,</mo><mn>2</mn><mi mathvariant="normal">C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathrm{H} / 8, \mathrm{H} / 8,2 \mathrm{C})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathrm">H</span><span class=mord>/8</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathrm">H</span><span class=mord>/8</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>2</span><span class="mord mathrm">C</span><span class=mclose>)</span></span></span></span></td></tr><tr><td style=text-align:center></td><td style=text-align:center>Swin Transformer blocks</td><td style=text-align:center>不改变形状</td><td style=text-align:center></td></tr><tr><td style=text-align:center><strong>Stage3</strong></td><td style=text-align:center>Patch merging</td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>8</mn><mo separator="true">,</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>8</mn><mo separator="true">,</mo><mn>2</mn><mi mathvariant="normal">C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathrm{H} / 8, \mathrm{H} / 8,2 \mathrm{C})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathrm">H</span><span class=mord>/8</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathrm">H</span><span class=mord>/8</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>2</span><span class="mord mathrm">C</span><span class=mclose>)</span></span></span></span></td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>H</mi><mi mathvariant="normal">/</mi><mn>16</mn><mo separator="true">,</mo><mi>H</mi><mi mathvariant="normal">/</mi><mn>16</mn><mo separator="true">,</mo><mn>8</mn><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(H / 16, H / 16,8 C)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.08125em>H</span><span class=mord>/16</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.08125em>H</span><span class=mord>/16</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>8</span><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=mclose>)</span></span></span></span></td></tr><tr><td style=text-align:center></td><td style=text-align:center>Linear projection</td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>H</mi><mi mathvariant="normal">/</mi><mn>16</mn><mo separator="true">,</mo><mi>H</mi><mi mathvariant="normal">/</mi><mn>16</mn><mo separator="true">,</mo><mn>8</mn><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(H / 16, H / 16,8 C)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.08125em>H</span><span class=mord>/16</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.08125em>H</span><span class=mord>/16</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>8</span><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=mclose>)</span></span></span></span></td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>H</mi><mi mathvariant="normal">/</mi><mn>16</mn><mo separator="true">,</mo><mi>H</mi><mi mathvariant="normal">/</mi><mn>16</mn><mo separator="true">,</mo><mn>4</mn><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(H / 16, H / 16,4 C)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.08125em>H</span><span class=mord>/16</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.08125em>H</span><span class=mord>/16</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>4</span><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=mclose>)</span></span></span></span></td></tr><tr><td style=text-align:center></td><td style=text-align:center>Swin Transformer blocks</td><td style=text-align:center>不改变形状</td><td style=text-align:center></td></tr><tr><td style=text-align:center><strong>Stage4</strong></td><td style=text-align:center>Patch merging</td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>16</mn><mo separator="true">,</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>16</mn><mo separator="true">,</mo><mn>4</mn><mi mathvariant="normal">C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathrm{H} / 16, \mathrm{H} / 16,4 \mathrm{C})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathrm">H</span><span class=mord>/16</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathrm">H</span><span class=mord>/16</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>4</span><span class="mord mathrm">C</span><span class=mclose>)</span></span></span></span></td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>32</mn><mo separator="true">,</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>32</mn><mo separator="true">,</mo><mn>16</mn><mi mathvariant="normal">C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathrm{H} / 32, \mathrm{H} / 32,16 \mathrm{C})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathrm">H</span><span class=mord>/32</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathrm">H</span><span class=mord>/32</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>16</span><span class="mord mathrm">C</span><span class=mclose>)</span></span></span></span></td></tr><tr><td style=text-align:center></td><td style=text-align:center>Linear projection</td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>32</mn><mo separator="true">,</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>32</mn><mo separator="true">,</mo><mn>16</mn><mi mathvariant="normal">C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathrm{H} / 32, \mathrm{H} / 32,16 \mathrm{C})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathrm">H</span><span class=mord>/32</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathrm">H</span><span class=mord>/32</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>16</span><span class="mord mathrm">C</span><span class=mclose>)</span></span></span></span></td><td style=text-align:center><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>32</mn><mo separator="true">,</mo><mi mathvariant="normal">H</mi><mi mathvariant="normal">/</mi><mn>32</mn><mo separator="true">,</mo><mn>8</mn><mi mathvariant="normal">C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathrm{H} / 32, \mathrm{H} / 32,8 \mathrm{C})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathrm">H</span><span class=mord>/32</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathrm">H</span><span class=mord>/32</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>8</span><span class="mord mathrm">C</span><span class=mclose>)</span></span></span></span></td></tr><tr><td style=text-align:center></td><td style=text-align:center>Swin Transformer blocks</td><td style=text-align:center>不改变形状</td><td style=text-align:center></td></tr></tbody></table><h3 id=1-patch-partition--linear-embedding>1. Patch Partition / Linear Embedding<a hidden class=anchor aria-hidden=true href=#1-patch-partition--linear-embedding>#</a></h3><p>第一步是将输入图像分块，变成 Patch Embedding，这与 ViT 中是完全相同的。不同的是，ViT 中的 Patch 大小为 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mo>×</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">16 \times 16</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7278em;vertical-align:-.0833em></span><span class=mord>16</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.6444em></span><span class=mord>16</span></span></span></span>，在 Swin Transformer 中使用了 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">4 \times 4</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7278em;vertical-align:-.0833em></span><span class=mord>4</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.6444em></span><span class=mord>4</span></span></span></span> 大小的 Patch，并且嵌入的维度为 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>96</mn></mrow><annotation encoding="application/x-tex">96</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6444em></span><span class=mord>96</span></span></span></span>。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>PatchEmbedding</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>img_size</span><span class=o>=</span><span class=mi>224</span><span class=p>,</span> <span class=n>patch_size</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span> <span class=n>in_chans</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>embed_dim</span><span class=o>=</span><span class=mi>768</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>img_size</span> <span class=o>=</span> <span class=n>img_size</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>patch_size</span> <span class=o>=</span> <span class=n>patch_size</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>n_patches</span> <span class=o>=</span> <span class=p>(</span><span class=n>img_size</span> <span class=o>//</span> <span class=n>patch_size</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>patch_size</span> <span class=o>=</span> <span class=n>patch_size</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>in_chans</span> <span class=o>=</span> <span class=n>in_chans</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>embed_dim</span> <span class=o>=</span> <span class=n>embed_dim</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>in_chans</span><span class=p>,</span> <span class=n>embed_dim</span><span class=p>,</span> <span class=n>kernel_size</span><span class=o>=</span><span class=n>patch_size</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=n>patch_size</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># proj: [B, 3, H, W] -&gt; [B, embed, n_patch_h, n_patch_w]</span>
</span></span><span class=line><span class=cl>        <span class=c1># flatten: [B, embed, n_patch_h, n_patch_w] -&gt; [B, embed, n_patch]</span>
</span></span><span class=line><span class=cl>        <span class=c1># transpose: [B, embed, n_patch] -&gt; [B, n_patch, embed]</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>patch_embed</span> <span class=o>=</span> <span class=n>PatchEmbedding</span><span class=p>(</span><span class=n>img_size</span><span class=o>=</span><span class=mi>224</span><span class=p>,</span> <span class=n>patch_size</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>embed_dim</span><span class=o>=</span><span class=mi>96</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>patch_embed</span><span class=p>(</span><span class=n>x</span><span class=p>)</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>3136</span><span class=p>,</span> <span class=mi>96</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><p>可以看到，此时 Patch 的数量为 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3136</mn></mrow><annotation encoding="application/x-tex">3136</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6444em></span><span class=mord>3136</span></span></span></span>，每个 Patch 的维度为 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>96</mn></mrow><annotation encoding="application/x-tex">96</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6444em></span><span class=mord>96</span></span></span></span>，对应特征图的话，即 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>56</mn><mo separator="true">,</mo><mn>56</mn><mo separator="true">,</mo><mn>96</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(56, 56, 96)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class=mord>56</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>56</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>96</span><span class=mclose>)</span></span></span></span> 大小。</p><p>Patch 的数量相比较 ViT 中的 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>196</mn></mrow><annotation encoding="application/x-tex">196</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6444em></span><span class=mord>196</span></span></span></span> 要多出很多。由于注意力机制的复杂度是 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(N^2)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0641em;vertical-align:-.25em></span><span class="mord mathcal" style=margin-right:.02778em>O</span><span class=mopen>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span> 的，如果直接使用普通的 Transformer Block 会变得比较低效，因此，Swin Transformer 中提出了对全局注意力机制的改进。</p><h3 id=2-patch-merging>2. Patch Merging<a hidden class=anchor aria-hidden=true href=#2-patch-merging>#</a></h3><p>Patch Merging 将 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2 \times 2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7278em;vertical-align:-.0833em></span><span class=mord>2</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.6444em></span><span class=mord>2</span></span></span></span> 大小的窗口中的特征沿深度方向堆叠起来，然后进行合并，最后在 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>C</mi></mrow><annotation encoding="application/x-tex">4C</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class=mord>4</span><span class="mord mathnormal" style=margin-right:.07153em>C</span></span></span></span> 的特征维度上使用线性层，将特征减少为 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>C</mi></mrow><annotation encoding="application/x-tex">2C</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class=mord>2</span><span class="mord mathnormal" style=margin-right:.07153em>C</span></span></span></span>。</p><p>这一操作其实是完成了CNN中的下采样操作，空间分辨率减低一倍的同时，特征通道数增加一倍。</p><figure><img loading=lazy src=images/patch-merging.png alt="Patch Merging"><figcaption><p>Patch Merging 操作示意图：将 2×2 相邻窗口的特征沿深度方向堆叠，实现特征图分辨率的降低和通道数的增加，相当于 CNN 中的下采样过程。</p></figcaption></figure><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>PatchMerging</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>input_resolution</span><span class=p>,</span> <span class=n>dim</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>input_resolution</span> <span class=o>=</span> <span class=n>input_resolution</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dim</span> <span class=o>=</span> <span class=n>dim</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>norm</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>dim</span> <span class=o>*</span> <span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>reduction</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>4</span> <span class=o>*</span> <span class=n>dim</span><span class=p>,</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>dim</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>H</span><span class=p>,</span> <span class=n>W</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>input_resolution</span>
</span></span><span class=line><span class=cl>        <span class=n>B</span><span class=p>,</span> <span class=n>n_patch</span><span class=p>,</span> <span class=n>C</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>W</span><span class=p>,</span> <span class=n>C</span><span class=p>)</span> <span class=c1># [B, n_patch, C] -&gt; [B, H, W, C]</span>
</span></span><span class=line><span class=cl>        <span class=n>x0</span> <span class=o>=</span> <span class=n>x</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>::</span><span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>::</span><span class=mi>2</span><span class=p>,</span> <span class=p>:]</span> <span class=c1># [B, H, W, C] -&gt; [B, H/2, W/2, C]</span>
</span></span><span class=line><span class=cl>        <span class=n>x1</span> <span class=o>=</span> <span class=n>x</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>::</span><span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>::</span><span class=mi>2</span><span class=p>,</span> <span class=p>:]</span> <span class=c1># [B, H, W, C] -&gt; [B, H/2, W/2, C]</span>
</span></span><span class=line><span class=cl>        <span class=n>x2</span> <span class=o>=</span> <span class=n>x</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>::</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>::</span><span class=mi>2</span><span class=p>,</span> <span class=p>:]</span> <span class=c1># [B, H, W, C] -&gt; [B, H/2, W/2, C]</span>
</span></span><span class=line><span class=cl>        <span class=n>x3</span> <span class=o>=</span> <span class=n>x</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>::</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>::</span><span class=mi>2</span><span class=p>,</span> <span class=p>:]</span> <span class=c1># [B, H, W, C] -&gt; [B, H/2, W/2, C]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>x0</span><span class=p>,</span> <span class=n>x1</span><span class=p>,</span> <span class=n>x2</span><span class=p>,</span> <span class=n>x3</span><span class=p>],</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span> <span class=c1># [B, H/2, W/2, 4*C]</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>4</span> <span class=o>*</span> <span class=n>C</span><span class=p>)</span> <span class=c1># [B, H/2, W/2, 4*C] -&gt; [B, n_patch/4, 4*C]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>reduction</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=c1># [B, n_patch/4, 4*C] -&gt; [B, n_patch/4, 2*C]</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>56</span> <span class=o>*</span> <span class=mi>56</span><span class=p>,</span> <span class=mi>96</span><span class=p>)</span>	<span class=c1># input feature map: (56, 56, 96)</span>
</span></span><span class=line><span class=cl><span class=n>patch_merge</span> <span class=o>=</span> <span class=n>PatchMerging</span><span class=p>(</span><span class=n>input_resolution</span><span class=o>=</span><span class=p>(</span><span class=mi>56</span><span class=p>,</span> <span class=mi>56</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>96</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>patch_merge</span><span class=p>(</span><span class=n>x</span><span class=p>)</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>&gt;&gt;</span> <span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>784</span><span class=p>,</span> <span class=mi>192</span><span class=p>])</span> <span class=c1># output feature map: (28, 28, 192)</span>
</span></span></code></pre></td></tr></table></div></div><p>在 Swin Transformer 中，正是通过 Patch Merging 的方式，完成了层级式特征图的获取。这样，就将 Transformer 和卷积神经网络（如：VGG、ResNet）对等起来了，现在 Transformer 也可以提取不同层级的、多尺度特征了。</p><figure class=align-center><img loading=lazy src=images/hierarchical-feature-maps.png#center alt="hierarchical feature maps" width=500px><figcaption><p>Swin Transformer 生成的层级式特征图，展示了 3 个不同阶段的特征分辨率变化，实现多尺度特征提取。</p></figcaption></figure><h3 id=3-swin-transformer-block>3. Swin Transformer Block<a hidden class=anchor aria-hidden=true href=#3-swin-transformer-block>#</a></h3><p>Swin Transformer Block 包含两种类型，每一种类型都由一个标准化层，一个注意力模块，另一个标准化层和一个 MLP 层组成，这与普通的 Transformer Block 是一样的。</p><p>不同的地方在于，Swin Transformer Block 中使用的两种注意力机制：<strong>窗口自注意力（W-MSA）模块</strong>、<strong>移动窗口的自注意力（SW-MSA）模块</strong>。</p><p>在实际使用中，W-MSA 和 SW-MSA 通常会连续使用。这一点也可以从 Swin Transformer 不同阶段的设计中看出，其每个阶段包含的 Swin Transformer Block 都是偶数个。</p><figure class=align-center><img loading=lazy src=images/swin-transformer-block.png#center alt="Swin Transformer Block" width=300px><figcaption><p>Swin Transformer Block 结构图，展示了一个 Block 中包含的 LayerNorm、W-MSA/SW-MSA 注意力模块和 MLP 层的完整组合。</p></figcaption></figure><h3 id=4-移动窗口自注意力>4. 移动窗口自注意力<a hidden class=anchor aria-hidden=true href=#4-移动窗口自注意力>#</a></h3><p>ViT 中使用的标准多头自注意力执行全局自注意力，并计算每个 Patch 与其他所有 Patch 之间的关系。这导致与 Patch 的数量呈平方复杂性，使其不适用于高分辨率图像。</p><p>为了计算的高效性，Swin Transformer 使用基于窗口的多头自注意力方法。窗口就是一个不重叠的 Patch 的集合，并且 <strong>注意力计算仅在每个窗口内部进行</strong>。</p><p>但是，这种窗口化的自注意力机制限制了只有窗口内的 Patch 之间能进行交互，限制了模型的能力。为了引入窗口之间的交互，同时保持非重叠窗口的高效计算，文中引入了移动窗口的注意力。通过 <strong>交替使用窗口自注意力和移动窗口自注意力</strong> 来实现。</p><h4 id=1窗口自注意力>（1）窗口自注意力<a hidden class=anchor aria-hidden=true href=#1窗口自注意力>#</a></h4><p>窗口自注意力将输入特征图均匀地、非重叠地分割成不同的窗口。假设输入特征图包含 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>×</mo><mi>w</mi></mrow><annotation encoding="application/x-tex">h \times w</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7778em;vertical-align:-.0833em></span><span class="mord mathnormal">h</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal" style=margin-right:.02691em>w</span></span></span></span> 个 Patch，窗口大小为 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.10903em>M</span></span></span></span>（默认情况下 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>=</mo><mn>7</mn></mrow><annotation encoding="application/x-tex">M=7</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.6444em></span><span class=mord>7</span></span></span></span>），全局的 MSA 模块和窗口的 MSA 模块的计算复杂度分别为：</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi mathvariant="normal">Ω</mi><mo stretchy="false">(</mo><mtext> MSA </mtext><mo stretchy="false">)</mo><mo>=</mo><mn>4</mn><mi>h</mi><mi>w</mi><msup><mi>C</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><mo stretchy="false">(</mo><mi>h</mi><mi>w</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mi>C</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi mathvariant="normal">Ω</mi><mo stretchy="false">(</mo><mtext> W-MSA </mtext><mo stretchy="false">)</mo><mo>=</mo><mn>4</mn><mi>h</mi><mi>w</mi><msup><mi>C</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><msup><mi>M</mi><mn>2</mn></msup><mi>h</mi><mi>w</mi><mi>C</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
&amp; \Omega(\text { MSA })=4 h w C^2+2(h w)^2 C \\
&amp; \Omega(\text { W-MSA })=4 h w C^2+2 M^2 h w C
\end{aligned}
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:3.0482em;vertical-align:-1.2741em></span><span class=mord><span class=mtable><span class=col-align-r><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.7741em><span style=top:-3.7741em><span class=pstrut style=height:2.8641em></span><span class=mord></span></span><span style=top:-2.25em><span class=pstrut style=height:2.8641em></span><span class=mord></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2741em><span></span></span></span></span></span><span class=col-align-l><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.7741em><span style=top:-3.91em><span class=pstrut style=height:3em></span><span class=mord><span class=mord></span><span class=mord>Ω</span><span class=mopen>(</span><span class="mord text"><span class=mord> MSA </span></span><span class=mclose>)</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span><span class=mord>4</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=mord><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8641em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:.2222em></span><span class=mord>2</span><span class=mopen>(</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=mclose><span class=mclose>)</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8641em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:.07153em>C</span></span></span><span style=top:-2.3859em><span class=pstrut style=height:3em></span><span class=mord><span class=mord></span><span class=mord>Ω</span><span class=mopen>(</span><span class="mord text"><span class=mord> W-MSA </span></span><span class=mclose>)</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span><span class=mord>4</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=mord><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8641em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:.2222em></span><span class=mord>2</span><span class=mord><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8641em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal">h</span><span class="mord mathnormal" style=margin-right:.07153em>wC</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2741em><span></span></span></span></span></span></span></span></span></span></span></span><p>可以看到，MSA 随着 Patch 数量的增加成平方级别增加，W-MSA 则是线性的。</p><p>对于矩阵 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi><mo stretchy="false">(</mo><mi>m</mi><mo>×</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{A}(m \times n)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathbf">A</span><span class=mopen>(</span><span class="mord mathnormal">m</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal">n</span><span class=mclose>)</span></span></span></span> 和矩阵 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo stretchy="false">(</mo><mi>n</mi><mo>×</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">B(n \times p)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.05017em>B</span><span class=mopen>(</span><span class="mord mathnormal">n</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal">p</span><span class=mclose>)</span></span></span></span>，那么 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi><mo>×</mo><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf{A} \times \mathbf{B}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7694em;vertical-align:-.0833em></span><span class="mord mathbf">A</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.6861em></span><span class="mord mathbf">B</span></span></span></span> 的复杂度为 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">O</mi><mo stretchy="false">(</mo><mi>m</mi><mo>⋅</mo><mi>n</mi><mo>⋅</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{O}(m \cdot n \cdot p)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathcal" style=margin-right:.02778em>O</span><span class=mopen>(</span><span class="mord mathnormal">m</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.4445em></span><span class="mord mathnormal">n</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal">p</span><span class=mclose>)</span></span></span></span>，下面用一段简单的代码解释这一复杂度计算：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>i</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>m</span><span class=p>;</span> <span class=n>i</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>	<span class=c1>// A矩阵中的m行
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>j</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>p</span><span class=p>;</span> <span class=n>j</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>	<span class=c1>// B矩阵中的p列
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>for</span> <span class=p>(</span><span class=kt>int</span> <span class=n>k</span> <span class=o>=</span> <span class=mi>0</span><span class=p>;</span> <span class=n>k</span> <span class=o>&lt;</span> <span class=n>n</span><span class=p>;</span> <span class=n>k</span><span class=o>++</span><span class=p>)</span> <span class=p>{</span>	<span class=c1>// A矩阵中的n列或B矩阵中的n行
</span></span></span><span class=line><span class=cl><span class=c1></span>            <span class=n>C</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>]</span> <span class=o>=</span> <span class=n>C</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>j</span><span class=p>]</span> <span class=o>+</span> <span class=n>A</span><span class=p>[</span><span class=n>i</span><span class=p>][</span><span class=n>k</span><span class=p>]</span> <span class=o>*</span> <span class=n>B</span><span class=p>[</span><span class=n>k</span><span class=p>][</span><span class=n>j</span><span class=p>];</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>对于全局的多头自注意力（MSA），如下面的示意图，在计算过程中，有四个线性层，分别是将输入映射到 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Q</mi></mrow><annotation encoding="application/x-tex">\mathbf{Q}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8805em;vertical-align:-.1944em></span><span class="mord mathbf">Q</span></span></span></span>、<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">K</mi></mrow><annotation encoding="application/x-tex">\mathbf{K}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6861em></span><span class="mord mathbf">K</span></span></span></span>、<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">V</mi></mrow><annotation encoding="application/x-tex">\mathbf{V}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6861em></span><span class="mord mathbf" style=margin-right:.01597em>V</span></span></span></span>，以及将注意力结果映射到输出 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">O</mi><mi mathvariant="bold">u</mi><mi mathvariant="bold">t</mi></mrow><annotation encoding="application/x-tex">\mathbf{Out}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6861em></span><span class=mord><span class="mord mathbf">Out</span></span></span></span></span>。这四个线性层的计算是相同的，即 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>C</mi><mo stretchy="false">)</mo><mo>×</mo><mo stretchy="false">(</mo><mi>C</mi><mo separator="true">,</mo><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, C) \times (C, C)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=mclose>)</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=mclose>)</span></span></span></span>。因此，这四个线性层的计算量为：<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>N</mi><msup><mi>C</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">4NC^2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8141em></span><span class=mord>4</span><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=mord><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>。</p><p>在注意力部分，首先是 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">Q</mi><msup><mi mathvariant="bold">K</mi><mi mathvariant="normal">T</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{Q}\mathbf{K}^{\mathrm{T}}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0358em;vertical-align:-.1944em></span><span class="mord mathbf">Q</span><span class=mord><span class="mord mathbf">K</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8413em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">T</span></span></span></span></span></span></span></span></span></span></span></span>，即 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>C</mi><mo stretchy="false">)</mo><mo>×</mo><mo stretchy="false">(</mo><mi>C</mi><mo separator="true">,</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, C) \times (C, N)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=mclose>)</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=mclose>)</span></span></span></span>，这一步的计算量为 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>N</mi><mn>2</mn></msup><mi>C</mi></mrow><annotation encoding="application/x-tex">N^2C</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8141em></span><span class=mord><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:.07153em>C</span></span></span></span>。这里忽略 scale 和 Softmax 的计算量。然后是 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="bold">A</mi><mi mathvariant="bold">t</mi><mi mathvariant="bold">t</mi><mi mathvariant="bold">n</mi></mrow><mo>×</mo><mi mathvariant="bold">V</mi></mrow><annotation encoding="application/x-tex">\mathbf{Attn} \times \mathbf{V}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7694em;vertical-align:-.0833em></span><span class=mord><span class="mord mathbf">Attn</span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.6861em></span><span class="mord mathbf" style=margin-right:.01597em>V</span></span></span></span>，即 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>N</mi><mo stretchy="false">)</mo><mo>×</mo><mo stretchy="false">(</mo><mi>N</mi><mo separator="true">,</mo><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N, N) \times (N, C)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=mclose>)</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=mclose>)</span></span></span></span>，这一步的计算量也是 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>N</mi><mn>2</mn></msup><mi>C</mi></mrow><annotation encoding="application/x-tex">N^2C</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8141em></span><span class=mord><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:.07153em>C</span></span></span></span>。</p><p>考虑到这里一共有 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>×</mo><mi>w</mi></mrow><annotation encoding="application/x-tex">h \times w</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7778em;vertical-align:-.0833em></span><span class="mord mathnormal">h</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal" style=margin-right:.02691em>w</span></span></span></span> 个 Patch（<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>=</mo><mi>h</mi><mo>×</mo><mi>w</mi></mrow><annotation encoding="application/x-tex">N = h \times w</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.7778em;vertical-align:-.0833em></span><span class="mord mathnormal">h</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal" style=margin-right:.02691em>w</span></span></span></span>），于是，MSA 的计算复杂度为：<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>N</mi><msup><mi>C</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><msup><mi>N</mi><mn>2</mn></msup><mi>C</mi><mo>=</mo><mn>4</mn><mi>h</mi><mi>w</mi><msup><mi>C</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><mo stretchy="false">(</mo><mi>h</mi><mi>w</mi><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mi>C</mi></mrow><annotation encoding="application/x-tex">4NC^2+2N^2C = 4hwC^2+2(hw)^2C</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8974em;vertical-align:-.0833em></span><span class=mord>4</span><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=mord><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.8141em></span><span class=mord>2</span><span class=mord><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.8974em;vertical-align:-.0833em></span><span class=mord>4</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=mord><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:1.0641em;vertical-align:-.25em></span><span class=mord>2</span><span class=mopen>(</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=mclose><span class=mclose>)</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:.07153em>C</span></span></span></span>。</p><figure><img loading=lazy src=images/multi-head-self-attention.png alt=多头自注意力模块><figcaption><p>标准多头自注意力模块结构图，展示了输入经过 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8778em;vertical-align:-.1944em></span><span class="mord mathnormal">Q</span></span></span></span>、<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.07153em>K</span></span></span></span>、<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.22222em>V</span></span></span></span> 线性变换后，通过注意力计算和输出映射的完整流程。</p></figcaption></figure><p>对于窗口自注意力（W-MSA），先考虑每个窗口内的计算量，即 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>=</mo><msup><mi>M</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">N=M^2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.10903em>N</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.8141em></span><span class=mord><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>，则每个窗口内的计算量为：<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><msup><mi>M</mi><mn>2</mn></msup><msup><mi>C</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><msup><mi>M</mi><mn>4</mn></msup><mi>C</mi></mrow><annotation encoding="application/x-tex">4M^2C^2+2M^4C</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8974em;vertical-align:-.0833em></span><span class=mord>4</span><span class=mord><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mord><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.8141em></span><span class=mord>2</span><span class=mord><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:.07153em>C</span></span></span></span>。考虑到有 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>h</mi><mi>M</mi></mfrac><mo>×</mo><mfrac><mi>w</mi><mi>M</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{h}{M} \times \frac{w}{M}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.2251em;vertical-align:-.345em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.8801em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.10903em>M</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:.04em></span></span><span style=top:-3.394em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.345em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:1.0404em;vertical-align:-.345em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.6954em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.10903em>M</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:.04em></span></span><span style=top:-3.394em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.02691em>w</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.345em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 个窗口：</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd class ="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi mathvariant="normal">Ω</mi><mo stretchy="false">(</mo><mtext>W-MSA</mtext><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mi>h</mi><mi>M</mi></mfrac><mo>×</mo><mfrac><mi>w</mi><mi>M</mi></mfrac><mo>×</mo><mrow><mo fence="true">(</mo><mn>4</mn><msup><mi>M</mi><mn>2</mn></msup><msup><mi>C</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><msup><mi>M</mi><mn>4</mn></msup><mi>C</mi><mo fence="true">)</mo></mrow></mrow></mstyle></mtd><mtd class ="mtr-glue"></mtd><mtd class ="mml-eqn-num"></mtd></mtr><mtr><mtd class ="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>4</mn><mi>h</mi><mi>w</mi><msup><mi>C</mi><mn>2</mn></msup><mo>+</mo><mn>2</mn><msup><mi>M</mi><mn>2</mn></msup><mi>h</mi><mi>w</mi><mi>C</mi></mrow></mstyle></mtd><mtd class ="mtr-glue"></mtd><mtd class ="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{align}
\Omega(\text{W-MSA})
&amp;= \frac{h}{M} \times \frac{w}{M} \times \left(4M^2C^2+2M^4C\right) \\
&amp;= 4 h w C^2+2 M^2 h w C
\end{align}
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:3.8815em;vertical-align:-1.6908em></span><span class=mtable><span class=col-align-r><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:2.1908em><span style=top:-4.1908em><span class=pstrut style=height:3.3714em></span><span class=mord><span class=mord>Ω</span><span class=mopen>(</span><span class="mord text"><span class=mord>W-MSA</span></span><span class=mclose>)</span></span></span><span style=top:-2.3407em><span class=pstrut style=height:3.3714em></span><span class=mord></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.6908em><span></span></span></span></span></span><span class=col-align-l><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:2.1908em><span style=top:-4.1908em><span class=pstrut style=height:3.3714em></span><span class=mord><span class=mord></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3714em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:.10903em>M</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal">h</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.1076em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:.10903em>M</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span><span class=minner><span class="mopen delimcenter" style=top:0><span class="delimsizing size1">(</span></span><span class=mord>4</span><span class=mord><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8641em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mord><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8641em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:.2222em></span><span class=mord>2</span><span class=mord><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8641em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class="mclose delimcenter" style=top:0><span class="delimsizing size1">)</span></span></span></span></span><span style=top:-2.3407em><span class=pstrut style=height:3.3714em></span><span class=mord><span class=mord></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span><span class=mord>4</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=mord><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8641em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:.2222em></span><span class=mord>2</span><span class=mord><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8641em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal">h</span><span class="mord mathnormal" style=margin-right:.07153em>wC</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.6908em><span></span></span></span></span></span></span></span><span class=tag><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:2.1908em><span style=top:-4.1908em><span class=pstrut style=height:3.3714em></span><span class=eqn-num></span></span><span style=top:-2.3407em><span class=pstrut style=height:3.3714em></span><span class=eqn-num></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.6908em><span></span></span></span></span></span></span></span></span><h4 id=2移动窗口>（2）移动窗口<a hidden class=anchor aria-hidden=true href=#2移动窗口>#</a></h4><p>为了引入跨窗口的连接，移动窗口的自注意力将窗口向右下移动 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">⌊</mo><mfrac><mi>M</mi><mn>2</mn></mfrac><mo fence="true">⌋</mo></mrow><annotation encoding="application/x-tex">\left\lfloor\frac{M}{2}\right\rfloor</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.2223em;vertical-align:-.35em></span><span class=minner><span class="mopen delimcenter" style=top:0><span class="delimsizing size1">⌊</span></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.8723em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:.04em></span></span><span style=top:-3.394em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.10903em>M</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.345em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style=top:0><span class="delimsizing size1">⌋</span></span></span></span></span></span> 的大小。这样原来的窗口就可以与其相邻的窗口建立联系。</p><p>然而，这种操作会出现一些大小不一的窗口，比如下图中展示的窗口 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal">A</span></span></span></span>、<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.05017em>B</span></span></span></span> 和 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.07153em>C</span></span></span></span>。这些窗口可以通过 Pad 的方式填充成 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>×</mo><mi>M</mi></mrow><annotation encoding="application/x-tex">M \times M</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7667em;vertical-align:-.0833em></span><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>×</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.10903em>M</span></span></span></span> 大小的窗口进行。然而，为了避免增加计算量，文中提出了 <strong>循环移位（Cyclic Shift）</strong> 的方式，将一些不完整的 Patch 移动到一起，形成完整的窗口。</p><figure><img loading=lazy src=images/self-attention-shifted-window.png alt=self-attention_in_shifted_window_partitioning><figcaption><p>移动窗口自注意力示意图：通过循环移位将窗口向右下移动 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">⌊</mo><mfrac><mi>M</mi><mn>2</mn></mfrac><mo fence="true">⌋</mo></mrow><annotation encoding="application/x-tex">\left\lfloor\frac{M}{2}\right\rfloor</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.2223em;vertical-align:-.35em></span><span class=minner><span class="mopen delimcenter" style=top:0><span class="delimsizing size1">⌊</span></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.8723em><span style=top:-2.655em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:.04em></span></span><span style=top:-3.394em><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.10903em>M</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.345em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style=top:0><span class="delimsizing size1">⌋</span></span></span></span></span></span> 个位置，使原始窗口能够与相邻窗口建立联系，解决非重叠窗口缺乏跨窗口交互的问题。</p></figcaption></figure><p>需要注意的是，这种移动之后，一个窗口可能由原始特征图中非相邻的 Patch 组成。因此，在计算过程中，对于这类窗口需要 <strong>使用掩码来限制自注意力只作用于相邻的 Patch</strong>。</p><p>这种循环移位的操作是为了计算上的效率，在计算完成后，需要使用 <strong>逆循环移位（Reverse Cyclic Shift）</strong> 将特征图还原。</p><p>下面是生成注意力掩码的 PyTorch 代码：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>window_partition</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>window_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Partitions the given input into windows.
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        x: (B, H, W, C)
</span></span></span><span class=line><span class=cl><span class=s2>        window_size (int): window size
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        windows: (num_windows*B, window_size, window_size, C)
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>B</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>W</span><span class=p>,</span> <span class=n>C</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=n>H</span> <span class=o>//</span> <span class=n>window_size</span><span class=p>,</span> <span class=n>window_size</span><span class=p>,</span> <span class=n>W</span> <span class=o>//</span> <span class=n>window_size</span><span class=p>,</span> <span class=n>window_size</span><span class=p>,</span> <span class=n>C</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>windows</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>window_size</span><span class=p>,</span> <span class=n>window_size</span><span class=p>,</span> <span class=n>C</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>windows</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>window_size</span> <span class=o>=</span> <span class=mi>7</span>
</span></span><span class=line><span class=cl><span class=n>shift_size</span> <span class=o>=</span> <span class=n>window_size</span> <span class=o>//</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>H</span><span class=p>,</span> <span class=n>W</span> <span class=o>=</span> <span class=mi>14</span><span class=p>,</span> <span class=mi>14</span>
</span></span><span class=line><span class=cl><span class=n>img_mask</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>W</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>  <span class=c1># 1 H W 1</span>
</span></span><span class=line><span class=cl><span class=n>h_slices</span> <span class=o>=</span> <span class=p>(</span><span class=nb>slice</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=o>-</span><span class=n>window_size</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=nb>slice</span><span class=p>(</span><span class=o>-</span><span class=n>window_size</span><span class=p>,</span> <span class=o>-</span><span class=n>shift_size</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=nb>slice</span><span class=p>(</span><span class=o>-</span><span class=n>shift_size</span><span class=p>,</span> <span class=kc>None</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>w_slices</span> <span class=o>=</span> <span class=p>(</span><span class=nb>slice</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=o>-</span><span class=n>window_size</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=nb>slice</span><span class=p>(</span><span class=o>-</span><span class=n>window_size</span><span class=p>,</span> <span class=o>-</span><span class=n>shift_size</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=nb>slice</span><span class=p>(</span><span class=o>-</span><span class=n>shift_size</span><span class=p>,</span> <span class=kc>None</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>cnt</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>h</span> <span class=ow>in</span> <span class=n>h_slices</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>w</span> <span class=ow>in</span> <span class=n>w_slices</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>img_mask</span><span class=p>[:,</span> <span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>,</span> <span class=p>:]</span> <span class=o>=</span> <span class=n>cnt</span>
</span></span><span class=line><span class=cl>        <span class=n>cnt</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>mask_windows</span> <span class=o>=</span> <span class=n>window_partition</span><span class=p>(</span><span class=n>img_mask</span><span class=p>,</span> <span class=n>window_size</span><span class=p>)</span>  <span class=c1># nW, window_size, window_size, 1</span>
</span></span><span class=line><span class=cl><span class=n>mask_windows</span> <span class=o>=</span> <span class=n>mask_windows</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>window_size</span> <span class=o>*</span> <span class=n>window_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>attn_mask</span> <span class=o>=</span> <span class=n>mask_windows</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>-</span> <span class=n>mask_windows</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>attn_mask</span> <span class=o>=</span> <span class=n>attn_mask</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>attn_mask</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=o>-</span><span class=mf>100.0</span><span class=p>))</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>attn_mask</span> <span class=o>==</span> <span class=mi>0</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=mf>0.0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>matshow</span><span class=p>(</span><span class=n>img_mask</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>numpy</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>matshow</span><span class=p>(</span><span class=n>attn_mask</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>numpy</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>matshow</span><span class=p>(</span><span class=n>attn_mask</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>numpy</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>matshow</span><span class=p>(</span><span class=n>attn_mask</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>numpy</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>matshow</span><span class=p>(</span><span class=n>attn_mask</span><span class=p>[</span><span class=mi>3</span><span class=p>]</span><span class=o>.</span><span class=n>numpy</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><figure><img loading=lazy src=images/visualization-attention-mask.png alt=Visualization_of_attention_mask><figcaption><p>注意力掩码可视化结果：左侧为不同区域的划分，右侧为对应窗口的注意力掩码矩阵。</p></figcaption></figure><h4 id=3相对位置偏差relative-position-bias>（3）相对位置偏差（Relative Position Bias）<a hidden class=anchor aria-hidden=true href=#3相对位置偏差relative-position-bias>#</a></h4><p>在普通的 Transformer 中，使用 <strong>位置编码</strong> 给模型提供序列中元素的位置信息。在 Swin Transformer 中，不直接给输入添加位置编码，而是在自注意力机制中引入 <strong>相对位置偏差</strong>。加入了相对位置编码的注意力计算：</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Attention</mtext><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi mathvariant="normal">T</mi></msup><mo>+</mo><mstyle mathcolor="Red"><mi>B</mi></mstyle></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^{\mathrm{T}} + {\color{Red} B} }{\sqrt{d_k}}\right) V
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord text"><span class=mord>Attention</span></span><span class=mopen>(</span><span class="mord mathnormal">Q</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.07153em>K</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.22222em>V</span><span class=mclose>)</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:2.4684em;vertical-align:-.95em></span><span class="mord text"><span class=mord>softmax</span></span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0><span class="delimsizing size3">(</span></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.5183em><span style=top:-2.2528em><span class=pstrut style=height:3em></span><span class=mord><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.8572em><span class=svg-align style=top:-3em><span class=pstrut style=height:3em></span><span class=mord style=padding-left:.833em><span class=mord><span class="mord mathnormal">d</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3361em><span style=top:-2.55em;margin-left:0;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.03148em>k</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span><span style=top:-2.8172em><span class=pstrut style=height:3em></span><span class=hide-tail style=min-width:.853em;height:1.08em><svg width="400em" height="1.08em" viewBox="0 0 4e5 1080" preserveAspectRatio="xMinYMin slice"><path d="M95 702c-2.7.0-7.17-2.7-13.5-8-5.8-5.3-9.5-10-9.5-14 0-2 .3-3.3 1-4 1.3-2.7 23.83-20.7 67.5-54 44.2-33.3 65.8-50.3 66.5-51 1.3-1.3 3-2 5-2 4.7.0 8.7 3.3 12 10s173 378 173 378c.7.0 35.3-71 104-213s137.5-285 206.5-429S812 97.3 814 94c5.3-9.3 12-14 20-14H4e5v40H845.2724s-225.272 467-225.272 467-235 486-235 486c-2.7 4.7-9 7-19 7-6 0-10-1-12-3s-194-422-194-422-65 47-65 47zM834 80h4e5v40H834z"/></svg></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.1828em><span></span></span></span></span></span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal">Q</span><span class=mord><span class="mord mathnormal" style=margin-right:.07153em>K</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8413em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">T</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:.2222em></span><span class=mord><span class="mord mathnormal" style=margin-right:.05017em;color:Red>B</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.93em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style=top:0><span class="delimsizing size3">)</span></span></span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.22222em>V</span></span></span></span></span><p>假设窗口大小为 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.10903em>M</span></span></span></span>，则 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msup><mi>M</mi><mn>2</mn></msup><mo>×</mo><msub><mi>d</mi><mi>k</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">Q, K, V \in \mathbb{R}^{M^2 \times d_k}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8778em;vertical-align:-.1944em></span><span class="mord mathnormal">Q</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.07153em>K</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.22222em>V</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.9869em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.9869em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.10903em>M</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8913em><span style=top:-2.931em;margin-right:.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3448em><span style=top:-2.3488em;margin-left:0;margin-right:.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style=margin-right:.03148em>k</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.1512em><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>，<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><msup><mi>M</mi><mn>2</mn></msup><mo>×</mo><msup><mi>M</mi><mn>2</mn></msup></mrow></msup></mrow><annotation encoding="application/x-tex">B \in \mathbb{R}^{M^2 \times M^2}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7224em;vertical-align:-.0391em></span><span class="mord mathnormal" style=margin-right:.05017em>B</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.9869em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.9869em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.10903em>M</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8913em><span style=top:-2.931em;margin-right:.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.10903em>M</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8913em><span style=top:-2.931em;margin-right:.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>。</p><figure><img loading=lazy src=images/relative-position-bias.png alt="relative position bias"><figcaption><p>相对位置偏差在自注意力计算中的应用：在 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi mathvariant="normal">T</mi></msup></mrow><annotation encoding="application/x-tex">QK^{\mathrm{T}}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0358em;vertical-align:-.1944em></span><span class="mord mathnormal">Q</span><span class=mord><span class="mord mathnormal" style=margin-right:.07153em>K</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8413em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">T</span></span></span></span></span></span></span></span></span></span></span></span> 的基础上添加可学习的相对位置偏差矩阵 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.05017em>B</span></span></span></span>，为模型提供位置信息。</p></figcaption></figure><p>在窗口大小为 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.10903em>M</span></span></span></span> 的情况下，每一个方向上的相对位置都在 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mo>−</mo><mi>M</mi><mo>+</mo><mn>1</mn><mo separator="true">,</mo><mi>M</mi><mo>−</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[-M+1, M-1]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>[</span><span class=mord>−</span><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.8778em;vertical-align:-.1944em></span><span class=mord>1</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mord>1</span><span class=mclose>]</span></span></span></span> 的范围中，例如：<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>=</mo><mn>4</mn><mo>→</mo><mi>r</mi><mi>a</mi><mi>n</mi><mi>g</mi><mi>e</mi><mo stretchy="false">[</mo><mo>−</mo><mn>3</mn><mo separator="true">,</mo><mn>3</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">M=4 \rightarrow range [-3,3]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.6444em></span><span class=mord>4</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>→</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.02778em>r</span><span class="mord mathnormal">an</span><span class="mord mathnormal" style=margin-right:.03588em>g</span><span class="mord mathnormal">e</span><span class=mopen>[</span><span class=mord>−</span><span class=mord>3</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>3</span><span class=mclose>]</span></span></span></span>。这说明了相对位置可选的值最多只有 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>M</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">2M-1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7667em;vertical-align:-.0833em></span><span class=mord>2</span><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.6444em></span><span class=mord>1</span></span></span></span> 种。因此，在代码实现中，是 <strong>预设了一个可学习的相对位置偏差的查询表</strong> <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>B</mi><mo>^</mo></mover><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mi>M</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>×</mo><mo stretchy="false">(</mo><mn>2</mn><mi>M</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\hat{B} \in \mathbb{R}^{(2 M-1) \times(2 M-1)}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.9859em;vertical-align:-.0391em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.9468em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal" style=margin-right:.05017em>B</span></span><span style=top:-3.2523em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-.1667em><span class=mord>^</span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.888em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.888em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mord mathnormal mtight" style=margin-right:.10903em>M</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mbin mtight">×</span><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mord mathnormal mtight" style=margin-right:.10903em>M</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span>，每一个 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.05017em>B</span></span></span></span> 都是从 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>B</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{B}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.9468em></span><span class="mord accent"><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.9468em><span style=top:-3em><span class=pstrut style=height:3em></span><span class="mord mathnormal" style=margin-right:.05017em>B</span></span><span style=top:-3.2523em><span class=pstrut style=height:3em></span><span class=accent-body style=left:-.1667em><span class=mord>^</span></span></span></span></span></span></span></span></span></span> 中获取的。</p><p>下面是获取相对位置偏置的 PyTorch 代码：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 参数</span>
</span></span><span class=line><span class=cl><span class=n>window_size</span> <span class=o>=</span> <span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 构建相对位置偏置的查询表</span>
</span></span><span class=line><span class=cl><span class=n>relative_position_bias_table</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>((</span><span class=mi>2</span> <span class=o>*</span> <span class=n>window_size</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=n>window_size</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>-</span> <span class=mi>1</span><span class=p>),</span> <span class=n>heads</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 计算窗口内每个位置相对于其他位置之间的相对位置索引</span>
</span></span><span class=line><span class=cl><span class=n>coords_h</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>window_size</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>coords_w</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>window_size</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>coords</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>meshgrid</span><span class=p>([</span><span class=n>coords_h</span><span class=p>,</span> <span class=n>coords_w</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=n>coords_flatten</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=n>coords</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>relative_coords</span> <span class=o>=</span> <span class=n>coords_flatten</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>]</span> <span class=o>-</span> <span class=n>coords_flatten</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl><span class=n>relative_coords</span> <span class=o>=</span> <span class=n>relative_coords</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>relative_coords</span><span class=p>[:,</span> <span class=p>:,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>+=</span> <span class=n>window_size</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>-</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=n>relative_coords</span><span class=p>[:,</span> <span class=p>:,</span> <span class=mi>1</span><span class=p>]</span> <span class=o>+=</span> <span class=n>window_size</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>-</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=n>relative_coords</span><span class=p>[:,</span> <span class=p>:,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*=</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>window_size</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>-</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=n>relative_position_index</span> <span class=o>=</span> <span class=n>relative_coords</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 在前向推理过程中，就直接从查询表中按索引获取值</span>
</span></span><span class=line><span class=cl><span class=n>relative_position_bias</span> <span class=o>=</span> <span class=n>relative_position_bias_table</span><span class=p>[</span><span class=n>relative_position_index</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)]</span>
</span></span><span class=line><span class=cl><span class=n>relative_position_bias</span> <span class=o>=</span> <span class=n>relative_position_bias</span><span class=o>.</span><span class=n>view</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>window_size</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>window_size</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>window_size</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>window_size</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=o>-</span><span class=mi>1</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>relative_position_bias</span> <span class=o>=</span> <span class=n>relative_position_bias</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>下图以窗口大小 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">M=2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.6444em></span><span class=mord>2</span></span></span></span> 为例，展示了相对位置偏差的计算过程。</p><figure><img loading=lazy src=images/relative-position-bias-implementation.png alt=relative_position_bias_implementation><figcaption><p>相对位置偏差实现示意图（窗口大小 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">M=2</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.10903em>M</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.6444em></span><span class=mord>2</span></span></span></span>）：展示如何通过相对位置索引从预设的查询表中获取对应的偏置值。</p></figcaption></figure><h2 id=参考资料>参考资料<a hidden class=anchor aria-hidden=true href=#参考资料>#</a></h2><ol><li><a href=https://towardsdatascience.com/a-comprehensive-guide-to-swin-transformer-64965f89d14c>A Comprehensive Guide to Microsoft&rsquo;s Swin Transformer</a></li><li><a href=https://amaarora.github.io/posts/2022-07-04-swintransformerv1.html>Swin Transformer</a></li><li><a href="https://www.bilibili.com/video/BV13L4y1475U/?vd_source=bc305312099c57b5c8ae25c6cf3544b6">Swin Transformer 论文精读【论文精读】</a></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://ehehe.cn/tags/swin-transformer/>Swin Transformer</a></li><li><a href=https://ehehe.cn/tags/transformer/>Transformer</a></li></ul><nav class=paginav><a class=prev href=https://ehehe.cn/posts/2024/02-word2vec/><span class=title>« Prev</span><br><span>词嵌入方法（Word2Vec）</span>
</a><a class=next href=https://ehehe.cn/posts/2023/01-vit/><span class=title>Next »</span><br><span>Vision Transformer —— 图像识别中的 Transformer 架构</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://ehehe.cn/>Yan Tang</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){function e(){var e,t,n,s=document.getElementsByTagName("code");for(n=0;n<s.length;){if(t=s[n],t.parentNode.tagName!=="PRE"&&t.childElementCount===0&&(e=t.textContent,/^\$[^$]/.test(e)&&/[^$]\$$/.test(e)&&(e=e.replace(/^\$/,"\\(").replace(/\$$/,"\\)"),t.textContent=e),/^\\\((.|\s)+\\\)$/.test(e)||/^\\\[(.|\s)+\\\]$/.test(e)||/^\$(.|\s)+\$$/.test(e)||/^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(e))){t.outerHTML=t.innerHTML;continue}n++}}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",e,{once:!0}):e()})()</script><script>(function(){var n=window.pageYOffset||document.documentElement.scrollTop||0,s=800,t=!1,e=null;function o(){if(t=!1,e||(e=document.getElementById("top-link")),!e)return;var o=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,i=o>n;n=o<0?0:o,o>s&&!i?(e.style.visibility="visible",e.style.opacity="1"):(e.style.visibility="hidden",e.style.opacity="0")}window.addEventListener("scroll",function(){t||(window.requestAnimationFrame(o),t=!0)},{passive:!0})})()</script><script>(function(){var t=10;function n(e){if(!e)return[0,20];var n,s,o=window.getComputedStyle(e),t=parseFloat(o.lineHeight);return(!t||isNaN(t))&&(t=20),n=e.getBoundingClientRect(),s=n.height||e.offsetHeight||0,[Math.round(s/t),t]}function e(){var e=document.querySelectorAll(".highlight");if(!e||!e.length)return;Array.prototype.forEach.call(e,function(e){if(e.classList.contains("expanded")||e.classList.contains("collapsible"))return;var s,o,a,r,c,l,i=e.querySelector("pre code");if(!i)return;if(r=i.className||"",r.indexOf("language-mermaid")>=0||e.classList.contains("mermaid"))return;if(a=n(i),c=a[0],l=a[1],c<=t)return;e.classList.add("collapsible"),e.style.setProperty("--code-line-height",l+"px"),e.id||(e.id="code-block-"+Math.random().toString(36).slice(2)),o=document.createElement("div"),o.className="code-expand-wrapper",s=document.createElement("button"),s.type="button",s.className="code-expand-link",s.textContent="Show more",s.setAttribute("aria-expanded","false"),s.setAttribute("aria-controls",e.id),s.addEventListener("click",function(){var n,i,a,o=e.classList.contains("expanded"),r=getComputedStyle(e).getPropertyValue("--code-line-height"),t=parseFloat(r)*(parseFloat(getComputedStyle(e).getPropertyValue("--code-max-lines"))||10);(!isFinite(t)||t<=0)&&(t=10*20),i=e.getBoundingClientRect().height,a=o?t:e.scrollHeight,e.style.maxHeight=i+"px",e.offsetHeight,o?e.classList.remove("expanded"):e.classList.add("expanded"),e.style.maxHeight=a+"px",n=function(t){if(t.propertyName!=="max-height")return;if(e.removeEventListener("transitionend",n),e.style.maxHeight="",e.classList.contains("expanded"))s.textContent="Show less",s.setAttribute("aria-expanded","true");else{s.textContent="Show more",s.setAttribute("aria-expanded","false");try{e.scrollIntoView({behavior:"smooth",block:"nearest"})}catch{}}window.dispatchEvent(new Event("resize"))},e.addEventListener("transitionend",n)}),o.appendChild(s),e.nextSibling?e.parentNode.insertBefore(o,e.nextSibling):e.parentNode.appendChild(o)})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",e,{once:!0}):e()})()</script><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>