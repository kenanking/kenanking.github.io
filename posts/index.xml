<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Posts on Yan Tang</title><link>https://kenanking.github.io/posts/</link><description>Recent content in Posts on Yan Tang</description><generator>Hugo -- 0.150.1</generator><language>zh-cn</language><lastBuildDate>Sun, 24 Aug 2025 20:18:30 +0000</lastBuildDate><atom:link href="https://kenanking.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>强化学习玩 Flappy Bird</title><link>https://kenanking.github.io/posts/2025/01-flappy-bird-dqn/</link><pubDate>Sun, 24 Aug 2025 20:18:30 +0000</pubDate><guid>https://kenanking.github.io/posts/2025/01-flappy-bird-dqn/</guid><description>Flappy Bird 是一款看似简单的移动端游戏，玩家需要控制一只小鸟向前飞行，并穿越一系列障碍物。小鸟只有飞翔和下落两种动作，通过控制小鸟的飞行高度来穿越障碍物。本文记录了我使用 DQN 训练 Flappy Bird 的过程。</description></item><item><title>DINOv2 可视化 🦖</title><link>https://kenanking.github.io/posts/2025/02-dino-visualization/</link><pubDate>Sat, 09 Nov 2024 00:00:00 +0000</pubDate><guid>https://kenanking.github.io/posts/2025/02-dino-visualization/</guid><description>介绍如何通过 PCA 方式可视化 DINOv2 模型的图像嵌入表示。</description></item><item><title>基于 NeRF 的三维场景生成</title><link>https://kenanking.github.io/posts/2024/01-nerf/</link><pubDate>Thu, 29 Feb 2024 14:20:32 +0000</pubDate><guid>https://kenanking.github.io/posts/2024/01-nerf/</guid><description>基于 NeRF 的三维场景生成</description></item><item><title>词嵌入方法（Word2Vec）</title><link>https://kenanking.github.io/posts/2024/02-word2vec/</link><pubDate>Wed, 28 Feb 2024 23:06:29 +0000</pubDate><guid>https://kenanking.github.io/posts/2024/02-word2vec/</guid><description>本篇文章介绍了Word2Vec方法，该方法通过在给定中心词的情况下预测上下文词的概率来学习单词的分布式表示，从而克服了独热表示的缺点，提高了词汇相似度的表达能力。</description></item><item><title>Swin Transformer：层级式特征图与移动窗口注意力机制</title><link>https://kenanking.github.io/posts/2023/02-swin-transformer/</link><pubDate>Wed, 09 Aug 2023 00:00:00 +0000</pubDate><guid>https://kenanking.github.io/posts/2023/02-swin-transformer/</guid><description>Swin Transformer 是一种创新的 Vision Transformer 架构，通过引入层级式特征图和移动窗口注意力机制，解决了 Vision Transformer 在计算复杂度和多尺度特征提取方面的限制，使其成为计算机视觉任务中高效的骨干网络。</description></item><item><title>Vision Transformer —— 图像识别中的 Transformer 架构</title><link>https://kenanking.github.io/posts/2023/01-vit/</link><pubDate>Wed, 26 Jul 2023 15:27:24 +0000</pubDate><guid>https://kenanking.github.io/posts/2023/01-vit/</guid><description>本文介绍了 Vision Transformer (ViT) 的核心概念，包括如何将 Transformer 架构应用于图像识别任务，以及与传统 CNNs 的比较。</description></item><item><title>DeepLabv2：基于空洞卷积与 ASPP 的语义图像分割</title><link>https://kenanking.github.io/posts/2023/07-deeplabv2/</link><pubDate>Tue, 04 Jul 2023 00:00:00 +0000</pubDate><guid>https://kenanking.github.io/posts/2023/07-deeplabv2/</guid><description>DeepLabv2 通过空洞卷积和上采样滤波器进行密集特征提取，将在图像分类上训练的网络重新用于语义分割任务。文中进一步提出ASPP以在多个尺度上编码对象以及图像上下文。为了产生语义准确的预测和精细的物体边界分割图，文中还结合了深度卷积神经网络和全连接条件随机场的思想。</description></item><item><title>机器学习中的爱因斯坦求和（Einsums）</title><link>https://kenanking.github.io/posts/2022/01-einsums/</link><pubDate>Sun, 20 Mar 2022 12:32:44 +0000</pubDate><guid>https://kenanking.github.io/posts/2022/01-einsums/</guid><description>机器学习中的爱因斯坦求和（Einsums）</description></item></channel></rss>