<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>词嵌入方法（Word2Vec） | Yan Tang</title><meta name=keywords content="Word2Vec,词嵌入,自然语言处理,Skip-gram,机器学习"><meta name=description content="本篇文章介绍了Word2Vec方法，该方法通过在给定中心词的情况下预测上下文词的概率来学习单词的分布式表示，从而克服了独热表示的缺点，提高了词汇相似度的表达能力。"><meta name=author content="Yan Tang"><link rel=canonical href=https://ehehe.cn/posts/2024/02-word2vec/><link crossorigin=anonymous href=/assets/css/stylesheet.16688c28815fab2857aba83927b88054dc9027b8a2b37dd2c695d9111db01da3.css integrity="sha256-FmiMKIFfqyhXq6g5J7iAVNyQJ7iis33SxpXZER2wHaM=" rel="preload stylesheet" as=style><link rel=icon href=https://ehehe.cn/assets/images/favicon-16x16.ico><link rel=icon type=image/png sizes=16x16 href=https://ehehe.cn/assets/images/favicon-16x16.ico><link rel=icon type=image/png sizes=32x32 href=https://ehehe.cn/assets/images/favicon-32x32.ico><link rel=apple-touch-icon href=https://ehehe.cn/assets/images/apple-touch-icon.png><link rel=mask-icon href=https://ehehe.cn/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://ehehe.cn/posts/2024/02-word2vec/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.css integrity=sha384-WcoG4HRXMzYzfCgiyfrySxx90XSl2rxY5mnVY5TwtWE6KLrArNKn0T/mOgNL0Mmi crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.js integrity=sha384-J+9dG2KMoiR9hqcFao0IBLwxt6zpcyN68IgwzsCSkbreXUjmNVRhPFTssqdSGjwQ crossorigin=anonymous></script><meta property="og:url" content="https://ehehe.cn/posts/2024/02-word2vec/"><meta property="og:site_name" content="Yan Tang"><meta property="og:title" content="词嵌入方法（Word2Vec）"><meta property="og:description" content="本篇文章介绍了Word2Vec方法，该方法通过在给定中心词的情况下预测上下文词的概率来学习单词的分布式表示，从而克服了独热表示的缺点，提高了词汇相似度的表达能力。"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-02-28T23:06:29+00:00"><meta property="article:modified_time" content="2024-02-28T23:06:29+00:00"><meta property="article:tag" content="Word2Vec"><meta property="article:tag" content="词嵌入"><meta property="article:tag" content="自然语言处理"><meta property="article:tag" content="Skip-Gram"><meta property="article:tag" content="机器学习"><meta name=twitter:card content="summary"><meta name=twitter:title content="词嵌入方法（Word2Vec）"><meta name=twitter:description content="本篇文章介绍了Word2Vec方法，该方法通过在给定中心词的情况下预测上下文词的概率来学习单词的分布式表示，从而克服了独热表示的缺点，提高了词汇相似度的表达能力。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://ehehe.cn/posts/"},{"@type":"ListItem","position":2,"name":"词嵌入方法（Word2Vec）","item":"https://ehehe.cn/posts/2024/02-word2vec/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"词嵌入方法（Word2Vec）","name":"词嵌入方法（Word2Vec）","description":"本篇文章介绍了Word2Vec方法，该方法通过在给定中心词的情况下预测上下文词的概率来学习单词的分布式表示，从而克服了独热表示的缺点，提高了词汇相似度的表达能力。","keywords":["Word2Vec","词嵌入","自然语言处理","Skip-gram","机器学习"],"articleBody":"背景 机器学习算法和深度神经网络模型，例如大型语言模型（LLMs），无法直接处理原始文本数据。这是因为文本数据在本质上是 分类数据（categorical），不适合直接用于模型实施和训练中的数学运算。因此，需要一种方法将单词转换为 连续数值向量（continous-valued vectors）。这种将单词转换成向量的过程被称为 词表示（Word Representation），或者 词嵌入（Word Embedding）。\n从本质上来讲，嵌入是一种从离散对象到连续向量空间中的点的映射。其目的是把那些本身不是数字形式的数据转化成神经网络能够识别和处理的格式。 不同的嵌入形式\n最简单且直接的方法是使用 独热表示（One-hot representation）。这种表示法的优点是其简单性和明确性，且不会有信息损失。然而，它也有明显的缺点：\n向量维度过大（取决于词汇表的大小）； 元素离散性，元素用 0 或 1 表示； 局部性，向量中只有一个元素为 1 起决定性作用，其余均为 0。 这第一种缺点可能导致所谓的 维度灾难，而后两种缺点则使得独热表示 难以表达词汇间的相似度。\n为此，另一种表示为 分布式表示（Distributed representation），用于避免独热表示的上述缺点。分布式表示具有以下特点：\n相对较低的维度； 元素为连续实数，而非离散值； 每个元素都对最终表示有贡献。 在分布式表示中有很多种方法，下面我们介绍 Word2Vec 方法，可参考下面的论文：Efficient Estimation of Word Representations in Vector Space。\nWord2Vec 假设 我们用 V={ω1,ω2,⋯ ,ω∣V∣}V=\\left\\{\\omega_1, \\omega_2, \\cdots, \\omega_{|V|}\\right\\}V={ω1​,ω2​,⋯,ω∣V∣​} 表示词汇表。给定一个大型的未标注训练数据集（语料库），我们将其视为一个序列：w1,w2,⋯ ,wTw_1, w_2, \\cdots , w_Tw1​,w2​,⋯,wT​，其中每一个 wtw_twt​ 都表示一个随机变量。我们的目标是获得单词的分布式向量表示，其特点是维度较低且能够用于比较相似度。\n例如，考虑“张三”和“李四”这两个词，它们之间存在一定的相似度。我们是如何得出这个结论的？\n通过比较描述张三和李四的上下文，若它们相似，我们可以推断这两个词具有一定的相似度。 反之，如果已知张三和李四相似，我们可以推断它们的上下文也相似。 下一步，我们将使用数学语言（即概率分布）来描述这个问题。我们来看 w1,w2,⋯ ,wTw_1, w_2, \\cdots, w_Tw1​,w2​,⋯,wT​ 的联合概率分布：\nP(w1:T)=P(wt)⋅P(context⁡(wt)∣wt) P\\left(w_{1: T}\\right)=P\\left(w_t\\right) \\cdot P\\left(\\operatorname{context}\\left(w_t\\right) \\mid w_t\\right) P(w1:T​)=P(wt​)⋅P(context(wt​)∣wt​)这里的 context⁡(⋅)\\operatorname{context}(\\cdot)context(⋅) 为上下文，表示除了 wtw_twt​ 以外所有随机变量的联合概率分布。\n这个式子计算起来肯定非常复杂，所以为了简便，我们引入第一个假设：为上下文设定一个大小固定的窗口。\n假设一： 窗口大小（ 2C2C2C ） 于是，上面的式子可以改写为：\nP(w1:T)=P(wt)⋅P(context⁡(wt)∣wt)≜P(wt)⋅P(wt−c:t−1,wt+1:t+c∣wt) \\begin{aligned} P\\left(w_{1: T}\\right) \u0026 =P\\left(w_t\\right) \\cdot P\\left(\\operatorname{context}\\left(w_t\\right) \\mid w_t\\right) \\\\ \u0026 \\triangleq P\\left(w_t\\right) \\cdot P\\left(w_{t-c: t-1}, w_{t+1: t+c} \\mid w_t\\right) \\end{aligned} P(w1:T​)​=P(wt​)⋅P(context(wt​)∣wt​)≜P(wt​)⋅P(wt−c:t−1​,wt+1:t+c​∣wt​)​下一步我们构造似然函数。由于我们不考虑 P(wt)P(w_t)P(wt​)，因此对于所有样本的似然函数可简化为：\n∏t=1TP(wt−c:t−1,wt+1:t+c∣wt) \\prod_{t=1}^T P\\left(w_{t-c: t-1}, w_{t+1: t+c} \\mid w_t\\right) t=1∏T​P(wt−c:t−1​,wt+1:t+c​∣wt​)这里构造似然函数时，我们引入了假设二：对于不同的 wtw_twt​，条件联合概率分布 P(wt−c:t−1,wt+1:t+c∣wt)P\\left(w_{t-c:t-1}, w_{t+1:t+c} \\mid w_t\\right)P(wt−c:t−1​,wt+1:t+c​∣wt​) 是相互独立的。\n假设二： 条件联合概率分布相互独立 对似然函数取对数，同时除以样本数 TTT，可得：\n1T∑t=1Tlog⁡P(wt−c:t−1,wt+1:t+c∣wt) \\frac{1}{T} \\sum_{t=1}^T \\log P\\left(w_{t-c: t-1}, w_{t+1: t+c} \\mid w_t\\right) T1​t=1∑T​logP(wt−c:t−1​,wt+1:t+c​∣wt​) 假设三： 给定 wtw_twt​ 的情况下，窗口内的其他随机变量 P(wt+i∣wt)P\\left(w_{t+i} \\mid w_t\\right)P(wt+i​∣wt​) 是独立同分布的（i.i.d.） 基于假设三，我们可以展开上面的对数似然函数：\n1T∑t=1Tlog⁡P(wt−c:t−1,wt+1:t+c∣wt)≜1T∑t=1Tlog⁡∏i∈[−c,c]i≠0P(wt+i∣wt)=1T∑t=1T∑i∈[−c,c]i≠0log⁡P(wt+i∣wt) \\begin{aligned} \u0026 \\frac{1}{T} \\sum_{t=1}^T \\log P\\left(w_{t-c: t-1}, w_{t+1: t+c} \\mid w_t\\right) \\\\ \\triangleq \u0026 \\frac{1}{T} \\sum_{t=1}^T \\log \\prod_{\\substack{i \\in[-c, c] \\\\ i \\neq 0}} P\\left(w_{t+i} \\mid w_t\\right) \\\\ = \u0026 \\frac{1}{T} \\sum_{t=1}^T \\sum_{\\substack{i \\in[-c, c] \\\\ i \\neq 0}} \\log P\\left(w_{t+i} \\mid w_t\\right) \\end{aligned} ≜=​T1​t=1∑T​logP(wt−c:t−1​,wt+1:t+c​∣wt​)T1​t=1∑T​logi∈[−c,c]i=0​∏​P(wt+i​∣wt​)T1​t=1∑T​i∈[−c,c]i=0​∑​logP(wt+i​∣wt​)​利用这三个假设，我们得出了最终的似然函数。为什么要写出这样一个似然函数？是因为我们想建立模型和目标函数。在一系列假设后，我们发现这个公式最终表示的是给定一个中心词 wtw_twt​ 时，窗口内其他词 wt+iw_{t+i}wt+i​ 的概率。\nWord2Vec 模型 下面，我们写出优化问题的目标函数 J(θ)J(\\theta)J(θ)，即负对数似然函数：\nJ(θ)=−1T∑t=1T∑i∈[−c,c]i≠0log⁡P(wt+i∣wt) J(\\theta)=-\\frac{1}{T} \\sum_{t=1}^T \\sum_{\\substack{i \\in[-c, c] \\\\ i \\neq 0}} \\log P\\left(w_{t+i} \\mid w_t\\right) J(θ)=−T1​t=1∑T​i∈[−c,c]i=0​∑​logP(wt+i​∣wt​)现在，我们的问题在于条件概率分布 P(wt+i∣wt)P\\left(w_{t+i} \\mid w_t\\right)P(wt+i​∣wt​)。在给定 wtw_twt​ 时，wt+1w_{t+1}wt+1​ 的概率分布应该是什么样子的？\n下面，我们用 wOw_OwO​ 和 wIw_IwI​ 来分别表示 wt+1w_{t+1}wt+1​ 和 wtw_twt​ 以此简化符号，III 表示输入（Input），OOO 表示输出（Output）。此时，条件概率分布表示为：P(wO∣wI)P\\left(w_O \\mid w_I\\right)P(wO​∣wI​)。\n词向量条件概率分布的表格\n在给定一个 wI=ωiw_I = \\omega_iwI​=ωi​ 作为中心词后，wO∣wI=ωiw_O \\mid w_I = \\omega_iwO​∣wI​=ωi​ 是一个离散型随机变量，我们可以通过表格的方式写出它的 概率质量函数（Probability mass function），如上图所示。并且这个概率值满足下面的关系式：\n∑j=1∣V∣pj=1,pj∈[0,1] \\sum_{j=1}^{|V|} p_j=1, \\quad p_j \\in[0,1] j=1∑∣V∣​pj​=1,pj​∈[0,1]那么，这个问题其实可以看做机器学习中的多分类问题。在给出输入 wI=ωiw_I = \\omega_iwI​=ωi​ 后，我们来预测下一个词 wOw_OwO​ 的概率，即：\nPj=P{wO=ωj∣wI=ωi}=softmax⁡(Δj) \\begin{aligned} P_j \u0026 =P\\left\\{w_O=\\omega_j \\mid w_I=\\omega_i\\right\\} \\\\ \u0026 =\\operatorname{softmax}(\\Delta_j) \\end{aligned} Pj​​=P{wO​=ωj​∣wI​=ωi​}=softmax(Δj​)​我们可以用神经网络的方式来建模这里的 Δ\\DeltaΔ，然后用 Softmax⁡\\operatorname{Softmax}Softmax 来做一下归一化，得到最终的概率值。\n神经网络建模词向量\n观察这个神经网络，它可以表示成如下的矩阵乘法的形式：\nωiT⋅W⋅U=ΔT \\omega_i^\\mathrm{T} \\cdot W \\cdot U = \\Delta^\\mathrm{T} ωiT​⋅W⋅U=ΔT其中，ωi=[0,0,⋯ ,0,1,0,⋯ ,0,0]T\\omega_i = [0, 0, \\cdots, 0, 1, 0, \\cdots, 0, 0]^\\mathrm{T}ωi​=[0,0,⋯,0,1,0,⋯,0,0]T。矩阵乘法 ωiT⋅W\\omega_i^\\mathrm{T} \\cdot WωiT​⋅W 实际就是将权重矩阵 WWW 的第 iii 行取出来。\nWord2Vec 实现示例 Word2Vec 包含两种对偶结构：Skip-gram 与 CBOW。\nSkip-gram：已知中心词 wtw_twt​，预测窗口内的上下文词 wt+iw_{t+i}wt+i​。适合小语料、能较好刻画低频词。 CBOW：已知上下文，预测中心词。训练更快，适合大语料。 1. 数据与词表构建 下面这段代码将语料打平成词序列，构建词表及索引映射。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 sentences = [ \"apple is red\", \"banana is yellow\", \"grape is purple\", \"apple is sweet\", \"banana is sweet\", \"grape is sweet\", \"orange is orange\", \"apple is fruit\", \"banana is fruit\", \"grape is fruit\", \"orange is fruit\", ] # Convert sentences to list of words words = \" \".join(sentences).split() vocab = sort(set(words)) word_to_idx = {w: i for i, w in enumerate(vocab)} idx_to_word = {i: w for i, w in enumerate(vocab)} vocab_size = len(vocab) word_to_idx / idx_to_word 提供了从离散词到序号的映射，后续 nn.Embedding 直接以词的索引作为输入进行查表。 2. 构造 Skip-gram 训练样本 create_skip_gram_data 会以窗口大小 window_size=2 滑动，生成 (中心词,上下文词)(\\text{中心词}, \\text{上下文词})(中心词,上下文词) 二元组。Skip-gram 的监督信号即这些配对的“正确上下文词”。\n1 2 3 4 5 6 7 8 9 10 11 12 13 def create_skip_gram_data(sentences, window_size=2): data = [] for sentence in sentences: words = sentence.split() for i, word in enumerate(words): for j in range( max(i - window_size, 0), min(i + window_size + 1, len(words)) ): if i != j: data.append((word, words[j])) return data skip_gram_data = create_skip_gram_data(sentences) 例子（以 “apple is red” 且窗口=2 为例）：\n生成的配对包括 (\"apple\",\"is\"), (\"apple\",\"red\"), (\"is\",\"apple\"), (\"is\",\"red\"), (\"red\",\"apple\"), (\"red\",\"is\")。 训练目标是：给定中心词（如 \"apple\"），最大化其投票出正确上下文（如 \"is\", \"red\"）的概率。 3. 模型定义 Skip-Gram 模型使用嵌入层（nn.Embedding）将输入单词索引映射到低维向量空间，然后通过线性层投影到词汇表大小的输出空间。该架构对应前文神经网络建模，其中输入到隐藏层的权重矩阵即为词嵌入矩阵。\n1 2 3 4 5 6 7 8 9 10 class SkipGram(nn.Module): def __init__(self, vocab_size, embedding_dim): super(SkipGram, self).__init__() self.input_to_hidden = nn.Embedding(vocab_size, embedding_dim) self.hidden_to_output = nn.Linear(embedding_dim, vocab_size, bias=False) def forward(self, x): # x: [batch_size,] x = self.input_to_hidden(x) # [B, d] x = self.hidden_to_output(x) # [B, |V|] -\u003e logits return x 矩阵视角：Skip-gram 模型本质上是两个矩阵变换的组合。\n设嵌入矩阵为 W∈R∣V∣×dW\\in\\mathbb{R}^{|V|\\times d}W∈R∣V∣×d，输出投影为 U∈Rd×∣V∣U\\in\\mathbb{R}^{d\\times |V|}U∈Rd×∣V∣。 one-hot 的 ωiTW\\omega_i^\\mathrm{T} WωiT​W 等价于从 WWW 取出第 iii 行，即中心词的嵌入 ewt\\mathbf{e}_{w_t}ewt​​。 logits Δ=ewtU\\Delta = \\mathbf{e}_{w_t} UΔ=ewt​​U，通过 softmax 得到 P(wt+i∣wt)P(w_{t+i}\\mid w_t)P(wt+i​∣wt​)。 通过 nn.Embedding 查表的方式等价于前文描述的：one-hot×权重，但训练实际只用 nn.Embedding，计算更高效。\n4. 模型训练 训练过程使用交叉熵损失（CrossEntropyLoss）优化模型参数，通过 SGD 优化器迭代 10000 个 epoch。每 epoch 随机打乱数据，计算平均损失。嵌入维度为 2，学习率为 0.001。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 embedding_dim = 2 learning_rate = 0.001 num_epochs = 10000 log_interval = 100 model = SkipGram(vocab_size, embedding_dim) criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(model.parameters(), lr=learning_rate) losses = [] for epoch in range(num_epochs): random.shuffle(skip_gram_data) loss_sum = 0 for context, target in skip_gram_data: context_idx = torch.tensor([word_to_idx[context]], dtype=torch.long) target_idx = torch.tensor([word_to_idx[target]], dtype=torch.long) outputs = model(context_idx) # logits: [1, |V|] loss = criterion(outputs, target_idx) optimizer.zero_grad() loss.backward() optimizer.step() loss_sum += loss.item() loss_sum = loss_sum / len(skip_gram_data) losses.append(loss_sum) CrossEntropyLoss(logits, target_idx) 等价于 log_softmax + NLLLoss，直接最小化 −log⁡P(wt+i∣wt)-\\log P(w_{t+i}\\mid w_t)−logP(wt+i​∣wt​)。 通过损失曲线可以看到，整体下降并趋于平稳，说明模型学到了 哪个中心词应与哪些上下文共现 的统计规律。\nSkip-gram 损失曲线\n下图展示了词嵌入在二维空间的散点分布，例如水果相关词汇（如：“apple”、“banana”、“grape”）趋于聚类，颜色词汇（如：“red”、“yellow”）则形成另一簇，语义相近的词（如颜色词、果名）明显靠得更近。\nSkip-gram 词嵌入在二维空间的散点分布\n5. 完整代码 为了方便参考，以下是整合后的完整代码：\n完整代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 import random import matplotlib.pyplot as plt import torch import torch.nn as nn import torch.optim as optim # Some sentences for training sentences = [ \"apple is red\", \"banana is yellow\", \"grape is purple\", \"apple is sweet\", \"banana is sweet\", \"grape is sweet\", \"orange is orange\", \"apple is fruit\", \"banana is fruit\", \"grape is fruit\", \"orange is fruit\", ] # Convert sentences to list of words words = \" \".join(sentences).split() vocab = sorted(set(words)) word_to_idx = {w: i for i, w in enumerate(vocab)} idx_to_word = {i: w for i, w in enumerate(vocab)} vocab_size = len(vocab) print(\"Vocab: \", vocab) print(\"Word to index: \", word_to_idx) print(\"Index to word: \", idx_to_word) print(\"Vocab size: \", vocab_size) # Generate training data def create_skip_gram_data(sentences, window_size=2): data = [] for sentence in sentences: words = sentence.split() for i, word in enumerate(words): for j in range( max(i - window_size, 0), min(i + window_size + 1, len(words)) ): if i != j: data.append((word, words[j])) return data skip_gram_data = create_skip_gram_data(sentences) print(\"Skip gram data: \", skip_gram_data) # Convert skip gram data to one-hot vectors def to_one_hot(word_idx, vocab_size): one_hot = torch.zeros(vocab_size) one_hot[word_idx] = 1 return one_hot # Define skip gram model class SkipGram(nn.Module): def __init__(self, vocab_size, embedding_dim): super(SkipGram, self).__init__() self.input_to_hidden = nn.Embedding(vocab_size, embedding_dim) self.hidden_to_output = nn.Linear(embedding_dim, vocab_size, bias=False) def forward(self, x): # x: [batch_size,] x = self.input_to_hidden(x) x = self.hidden_to_output(x) return x # Define training parameters embedding_dim = 2 learning_rate = 0.001 num_epochs = 10000 log_interval = 100 # Create skip gram model model = SkipGram(vocab_size, embedding_dim) print(model) # Define loss function and optimizer criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(model.parameters(), lr=learning_rate) # Train the model losses = [] for epoch in range(num_epochs): random.shuffle(skip_gram_data) loss_sum = 0 for context, target in skip_gram_data: context_idx = torch.tensor([word_to_idx[context]], dtype=torch.long) target_idx = torch.tensor([word_to_idx[target]], dtype=torch.long) # Forward pass outputs = model(context_idx) loss = criterion(outputs, target_idx) # Backward and optimize optimizer.zero_grad() loss.backward() optimizer.step() loss_sum += loss.item() loss_sum = loss_sum / len(skip_gram_data) losses.append(loss_sum) if (epoch + 1) % log_interval == 0: print(\"Epoch [{}/{}], Loss: {:.4f}\".format(epoch + 1, num_epochs, loss_sum)) # Plot losses plt.figure(figsize=(5, 5)) plt.plot(losses) plt.xlabel(\"Epoch\") plt.ylabel(\"Loss\") plt.title(\"Skip Gram (nn.Embedding) Loss\") plt.savefig(\"skip_gram_emb_loss.png\", dpi=300) # Get embeddings embeddings = model.input_to_hidden.weight.data.numpy() print(\"\\nEmbeddings:\") for word, idx in word_to_idx.items(): print(f\"{word}: {embeddings[idx]}\") # Plot embeddings plt.figure(figsize=(5, 5)) for word, idx in word_to_idx.items(): plt.scatter(embeddings[idx][0], embeddings[idx][1]) plt.annotate(word, (embeddings[idx][0], embeddings[idx][1])) plt.xlabel(\"Dimension 1\") plt.ylabel(\"Dimension 2\") plt.title(\"Skip Gram (nn.Embedding) Embeddings\") plt.savefig(\"skip_gram_emb_embeddings.png\", dpi=300) 参考资料 词向量(Word Vector)【白板推导系列】 ","wordCount":"1243","inLanguage":"en","datePublished":"2024-02-28T23:06:29Z","dateModified":"2024-02-28T23:06:29Z","author":{"@type":"Person","name":"Yan Tang"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://ehehe.cn/posts/2024/02-word2vec/"},"publisher":{"@type":"Organization","name":"Yan Tang","logo":{"@type":"ImageObject","url":"https://ehehe.cn/assets/images/favicon-16x16.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://ehehe.cn/ accesskey=h title="Yan Tang (Alt + H)">Yan Tang</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://ehehe.cn/ title=Posts><span>Posts</span></a></li><li><a href=https://ehehe.cn/about/ title=About><span>About</span></a></li><li><a href=https://ehehe.cn/publications/ title=Publications><span>Publications</span></a></li><li><a href=https://ehehe.cn/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://ehehe.cn/zotwatch/ title=ZotWatch><span>ZotWatch</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">词嵌入方法（Word2Vec）</h1><div class=post-meta><span title='2024-02-28 23:06:29 +0000 UTC'>February 28, 2024</span>&nbsp;·&nbsp;<span>6 min</span>&nbsp;·&nbsp;<span>Yan Tang</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e8%83%8c%e6%99%af aria-label=背景>背景</a></li><li><a href=#word2vec-%e5%81%87%e8%ae%be aria-label="Word2Vec 假设">Word2Vec 假设</a></li><li><a href=#word2vec-%e6%a8%a1%e5%9e%8b aria-label="Word2Vec 模型">Word2Vec 模型</a></li><li><a href=#word2vec-%e5%ae%9e%e7%8e%b0%e7%a4%ba%e4%be%8b aria-label="Word2Vec 实现示例">Word2Vec 实现示例</a><ul><li><a href=#1-%e6%95%b0%e6%8d%ae%e4%b8%8e%e8%af%8d%e8%a1%a8%e6%9e%84%e5%bb%ba aria-label="1. 数据与词表构建">1. 数据与词表构建</a></li><li><a href=#2-%e6%9e%84%e9%80%a0-skip-gram-%e8%ae%ad%e7%bb%83%e6%a0%b7%e6%9c%ac aria-label="2. 构造 Skip-gram 训练样本">2. 构造 Skip-gram 训练样本</a></li><li><a href=#3-%e6%a8%a1%e5%9e%8b%e5%ae%9a%e4%b9%89 aria-label="3. 模型定义">3. 模型定义</a></li><li><a href=#4-%e6%a8%a1%e5%9e%8b%e8%ae%ad%e7%bb%83 aria-label="4. 模型训练">4. 模型训练</a></li><li><a href=#5-%e5%ae%8c%e6%95%b4%e4%bb%a3%e7%a0%81 aria-label="5. 完整代码">5. 完整代码</a></li></ul></li><li><a href=#%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99 aria-label=参考资料>参考资料</a></li></ul></div></details></div><div class=post-content><h2 id=背景>背景<a hidden class=anchor aria-hidden=true href=#背景>#</a></h2><p>机器学习算法和深度神经网络模型，例如大型语言模型（LLMs），无法直接处理原始文本数据。这是因为文本数据在本质上是 <strong>分类数据（categorical）</strong>，不适合直接用于模型实施和训练中的数学运算。因此，需要一种方法将单词转换为 <strong>连续数值向量（continous-valued vectors）</strong>。这种将单词转换成向量的过程被称为 <strong>词表示（Word Representation）</strong>，或者 <strong>词嵌入（Word Embedding）</strong>。</p><div class="notice notice-note" role=note><span class=notice-icon aria-hidden=true><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M19 21l-7-5-7 5V5a2 2 0 012-2h10a2 2 0 012 2z"/></svg></span><div class=notice-content><strong>从本质上来讲，嵌入是一种从离散对象到连续向量空间中的点的映射。其目的是把那些本身不是数字形式的数据转化成神经网络能够识别和处理的格式。</strong></div></div><figure class=align-center><img loading=lazy src=images/different_embeddings.svg#center alt=不同的嵌入形式 width=600><figcaption><p>不同的嵌入形式</p></figcaption></figure><p>最简单且直接的方法是使用 <strong>独热表示（One-hot representation）</strong>。这种表示法的优点是其简单性和明确性，且不会有信息损失。然而，它也有明显的缺点：</p><ol><li>向量维度过大（取决于词汇表的大小）；</li><li>元素离散性，元素用 0 或 1 表示；</li><li>局部性，向量中只有一个元素为 1 起决定性作用，其余均为 0。</li></ol><p>这第一种缺点可能导致所谓的 <strong>维度灾难</strong>，而后两种缺点则使得独热表示 <strong>难以表达词汇间的相似度</strong>。</p><p>为此，另一种表示为 <strong>分布式表示（Distributed representation）</strong>，用于避免独热表示的上述缺点。分布式表示具有以下特点：</p><ol><li>相对较低的维度；</li><li>元素为连续实数，而非离散值；</li><li>每个元素都对最终表示有贡献。</li></ol><p>在分布式表示中有很多种方法，下面我们介绍 Word2Vec 方法，可参考下面的论文：<a href=https://arxiv.org/abs/1301.3781>Efficient Estimation of Word Representations in Vector Space</a>。</p><h2 id=word2vec-假设>Word2Vec 假设<a hidden class=anchor aria-hidden=true href=#word2vec-假设>#</a></h2><p>我们用 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mrow><mo fence="true">{</mo><msub><mi>ω</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>ω</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>ω</mi><mrow><mi mathvariant="normal">∣</mi><mi>V</mi><mi mathvariant="normal">∣</mi></mrow></msub><mo fence="true">}</mo></mrow></mrow><annotation encoding="application/x-tex">V=\left\{\omega_1, \omega_2, \cdots, \omega_{|V|}\right\}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.22222em>V</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:1.2052em;vertical-align:-.3552em></span><span class=minner><span class="mopen delimcenter" style=top:0><span class="delimsizing size1">{</span></span><span class=mord><span class="mord mathnormal" style=margin-right:.03588em>ω</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0359em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:.03588em>ω</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0359em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=minner>⋯</span><span class=mspace style=margin-right:.1667em></span><span class=mspace style=margin-right:.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:.03588em>ω</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3448em><span style=top:-2.5198em;margin-left:-.0359em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style=margin-right:.22222em>V</span><span class="mord mtight">∣</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.3552em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0><span class="delimsizing size1">}</span></span></span></span></span></span> 表示词汇表。给定一个大型的未标注训练数据集（语料库），我们将其视为一个序列：<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>w</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">w_1, w_2, \cdots , w_T</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.625em;vertical-align:-.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=minner>⋯</span><span class=mspace style=margin-right:.1667em></span><span class=mspace style=margin-right:.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span>，其中每一个 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">w_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 都表示一个随机变量。我们的目标是获得单词的分布式向量表示，其特点是维度较低且能够用于比较相似度。</p><p>例如，考虑“张三”和“李四”这两个词，它们之间存在一定的相似度。我们是如何得出这个结论的？</p><ul><li>通过比较描述张三和李四的上下文，若它们相似，我们可以推断这两个词具有一定的相似度。</li><li>反之，如果已知张三和李四相似，我们可以推断它们的上下文也相似。</li></ul><p>下一步，我们将使用数学语言（即概率分布）来描述这个问题。我们来看 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>w</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">w_1, w_2, \cdots, w_T</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.625em;vertical-align:-.1944em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=minner>⋯</span><span class=mspace style=margin-right:.1667em></span><span class=mspace style=margin-right:.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 的联合概率分布：</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mn>1</mn><mo>:</mo><mi>T</mi></mrow></msub><mo fence="true">)</mo></mrow><mo>=</mo><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow><mo>⋅</mo><mi>P</mi><mrow><mo fence="true">(</mo><mi mathvariant="normal">context</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
P\left(w_{1: T}\right)=P\left(w_t\right) \cdot P\left(\operatorname{context}\left(w_t\right) \mid w_t\right)
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style=margin-right:.13889em>T</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mop><span class="mord mathrm">context</span></span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span></span></span><p>这里的 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">context</mi><mo>⁡</mo><mo stretchy="false">(</mo><mo>⋅</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\operatorname{context}(\cdot)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mop><span class="mord mathrm">context</span></span><span class=mopen>(</span><span class=mord>⋅</span><span class=mclose>)</span></span></span></span> 为上下文，表示除了 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">w_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 以外所有随机变量的联合概率分布。</p><p>这个式子计算起来肯定非常复杂，所以为了简便，我们引入第一个假设：为上下文设定一个大小固定的窗口。</p><div class="notice notice-tip" role=note><span class=notice-icon aria-hidden=true><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2v2m0 16v2M4.93 4.93l1.41 1.41M17.66 17.66l1.41 1.41M2 12h2m16 0h2M6.34 17.66l-1.41 1.41M19.07 4.93l-1.41 1.41"/><circle cx="12" cy="12" r="4"/><path d="M12 16v1a2 2 0 002 2h0a2 2 0 002-2v-1"/></svg></span><div class=notice-content><strong>假设一：</strong> 窗口大小（ <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>C</mi></mrow><annotation encoding="application/x-tex">2C</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class=mord>2</span><span class="mord mathnormal" style=margin-right:.07153em>C</span></span></span></span> ）</div></div><p>于是，上面的式子可以改写为：</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mn>1</mn><mo>:</mo><mi>T</mi></mrow></msub><mo fence="true">)</mo></mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow><mo>⋅</mo><mi>P</mi><mrow><mo fence="true">(</mo><mi mathvariant="normal">context</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>≜</mo><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow><mo>⋅</mo><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mi>c</mi><mo>:</mo><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>t</mi><mo>+</mo><mi>c</mi></mrow></msub><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
P\left(w_{1: T}\right) &amp; =P\left(w_t\right) \cdot P\left(\operatorname{context}\left(w_t\right) \mid w_t\right) \\
&amp; \triangleq P\left(w_t\right) \cdot P\left(w_{t-c: t-1}, w_{t+1: t+c} \mid w_t\right)
\end{aligned}
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:3.0767em;vertical-align:-1.2883em></span><span class=mord><span class=mtable><span class=col-align-r><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.7883em><span style=top:-3.9483em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight" style=margin-right:.13889em>T</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span><span style=top:-2.3717em><span class=pstrut style=height:3em></span><span class=mord></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2883em><span></span></span></span></span></span><span class=col-align-l><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.7883em><span style=top:-3.9483em><span class=pstrut style=height:3em></span><span class=mord><span class=mord></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:.2222em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mop><span class="mord mathrm">context</span></span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span><span style=top:-2.3717em><span class=pstrut style=height:3em></span><span class=mord><span class=mord></span><span class=mspace style=margin-right:.2778em></span><span class="mrel amsrm">≜</span><span class=mspace style=margin-right:.2778em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:.2222em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">c</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2883em><span></span></span></span></span></span></span></span></span></span></span></span><p>下一步我们构造似然函数。由于我们不考虑 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(w_t)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mopen>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span>，因此对于所有样本的似然函数可简化为：</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munderover><mo>∏</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mi>c</mi><mo>:</mo><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>t</mi><mo>+</mo><mi>c</mi></mrow></msub><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\prod_{t=1}^T P\left(w_{t-c: t-1}, w_{t+1: t+c} \mid w_t\right)
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:3.0954em;vertical-align:-1.2671em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8829em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style=top:-4.3em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2671em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">c</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span></span></span><p>这里构造似然函数时，我们引入了假设二：对于不同的 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">w_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span>，条件联合概率分布 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mi>c</mi><mo>:</mo><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>t</mi><mo>+</mo><mi>c</mi></mrow></msub><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">P\left(w_{t-c:t-1}, w_{t+1:t+c} \mid w_t\right)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">c</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span></span> 是相互独立的。</p><div class="notice notice-tip" role=note><span class=notice-icon aria-hidden=true><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2v2m0 16v2M4.93 4.93l1.41 1.41M17.66 17.66l1.41 1.41M2 12h2m16 0h2M6.34 17.66l-1.41 1.41M19.07 4.93l-1.41 1.41"/><circle cx="12" cy="12" r="4"/><path d="M12 16v1a2 2 0 002 2h0a2 2 0 002-2v-1"/></svg></span><div class=notice-content><strong>假设二：</strong> 条件联合概率分布相互独立</div></div><p>对似然函数取对数，同时除以样本数 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.13889em>T</span></span></span></span>，可得：</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mn>1</mn><mi>T</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mi>log</mi><mo>⁡</mo><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mi>c</mi><mo>:</mo><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>t</mi><mo>+</mo><mi>c</mi></mrow></msub><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\frac{1}{T} \sum_{t=1}^T \log P\left(w_{t-c: t-1}, w_{t+1: t+c} \mid w_t\right)
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:3.0954em;vertical-align:-1.2671em></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3214em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:.13889em>T</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8829em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2671em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class=mop>lo<span style=margin-right:.01389em>g</span></span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">c</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span></span></span><div class="notice notice-tip" role=note><span class=notice-icon aria-hidden=true><svg class="icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 2v2m0 16v2M4.93 4.93l1.41 1.41M17.66 17.66l1.41 1.41M2 12h2m16 0h2M6.34 17.66l-1.41 1.41M19.07 4.93l-1.41 1.41"/><circle cx="12" cy="12" r="4"/><path d="M12 16v1a2 2 0 002 2h0a2 2 0 002-2v-1"/></svg></span><div class=notice-content><strong>假设三：</strong> 给定 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">w_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 的情况下，窗口内的其他随机变量 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">P\left(w_{t+i} \mid w_t\right)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span></span> 是独立同分布的（i.i.d.）</div></div><p>基于假设三，我们可以展开上面的对数似然函数：</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mfrac><mn>1</mn><mi>T</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mi>log</mi><mo>⁡</mo><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>−</mo><mi>c</mi><mo>:</mo><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>t</mi><mo>+</mo><mi>c</mi></mrow></msub><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mo lspace="0em" rspace="0em">≜</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mfrac><mn>1</mn><mi>T</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mi>log</mi><mo>⁡</mo><munder><mo>∏</mo><mstyle scriptlevel="1"><mtable rowspacing="0.1em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="1" displaystyle="false"><mrow><mi>i</mi><mo>∈</mo><mo stretchy="false">[</mo><mo>−</mo><mi>c</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="1" displaystyle="false"><mrow><mi>i</mi><mo mathvariant="normal">≠</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mstyle></munder><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mo lspace="0em" rspace="0em">=</mo></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mfrac><mn>1</mn><mi>T</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><munder><mo>∑</mo><mstyle scriptlevel="1"><mtable rowspacing="0.1em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="1" displaystyle="false"><mrow><mi>i</mi><mo>∈</mo><mo stretchy="false">[</mo><mo>−</mo><mi>c</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="1" displaystyle="false"><mrow><mi>i</mi><mo mathvariant="normal">≠</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mstyle></munder><mi>log</mi><mo>⁡</mo><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
&amp; \frac{1}{T} \sum_{t=1}^T \log P\left(w_{t-c: t-1}, w_{t+1: t+c} \mid w_t\right) \\
\triangleq &amp; \frac{1}{T} \sum_{t=1}^T \log \prod_{\substack{i \in[-c, c] \\
i \neq 0}} P\left(w_{t+i} \mid w_t\right) \\
= &amp; \frac{1}{T} \sum_{t=1}^T \sum_{\substack{i \in[-c, c] \\
i \neq 0}} \log P\left(w_{t+i} \mid w_t\right)
\end{aligned}
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:11.9286em;vertical-align:-5.7143em></span><span class=mord><span class=mtable><span class=col-align-r><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:6.2143em><span style=top:-8.2143em><span class=pstrut style=height:3.8283em></span><span class=mord></span></span><span style=top:-4.8188em><span class=pstrut style=height:3.8283em></span><span class=mord><span class="mrel amsrm">≜</span></span></span><span style=top:-.5523em><span class=pstrut style=height:3.8283em></span><span class=mord><span class=mrel>=</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:5.7143em><span></span></span></span></span></span><span class=col-align-l><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:6.2143em><span style=top:-8.2143em><span class=pstrut style=height:3.8283em></span><span class=mord><span class=mord></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3214em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:.13889em>T</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8829em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2671em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class=mop>lo<span style=margin-right:.01389em>g</span></span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">c</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">c</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span><span style=top:-4.8188em><span class=pstrut style=height:3.8283em></span><span class=mord><span class=mord></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3214em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:.13889em>T</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8829em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2671em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class=mop>lo<span style=margin-right:.01389em>g</span></span><span class=mspace style=margin-right:.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.05em><span style=top:-1.4979em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class=mtable><span class=col-align-c><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.1944em><span style=top:-3.1944em><span class=pstrut style=height:2.75em></span><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mopen mtight">[</span><span class="mord mtight">−</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">c</span><span class="mclose mtight">]</span></span></span><span style=top:-2.25em><span class=pstrut style=height:2.75em></span><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class=strut style=height:.8889em;vertical-align:-.1944em></span><span class=inner><span class="mord mtight"><span class="mrel mtight"></span></span></span><span class=fix></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mtight">0</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.6944em><span></span></span></span></span></span></span></span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∏</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:2.1382em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span><span style=top:-.5523em><span class=pstrut style=height:3.8283em></span><span class=mord><span class=mord></span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3214em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:.13889em>T</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8829em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2671em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.05em><span style=top:-1.4979em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class=mtable><span class=col-align-c><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.1944em><span style=top:-3.1944em><span class=pstrut style=height:2.75em></span><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mopen mtight">[</span><span class="mord mtight">−</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">c</span><span class="mclose mtight">]</span></span></span><span style=top:-2.25em><span class=pstrut style=height:2.75em></span><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class=strut style=height:.8889em;vertical-align:-.1944em></span><span class=inner><span class="mord mtight"><span class="mrel mtight"></span></span></span><span class=fix></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mtight">0</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.6944em><span></span></span></span></span></span></span></span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:2.1382em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class=mop>lo<span style=margin-right:.01389em>g</span></span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:5.7143em><span></span></span></span></span></span></span></span></span></span></span></span><p>利用这三个假设，我们得出了最终的似然函数。为什么要写出这样一个似然函数？是因为我们想建立模型和目标函数。在一系列假设后，我们发现这个公式最终表示的是给定一个中心词 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">w_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 时，窗口内其他词 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{t+i}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6389em;vertical-align:-.2083em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span></span></span></span> 的概率。</p><h2 id=word2vec-模型>Word2Vec 模型<a hidden class=anchor aria-hidden=true href=#word2vec-模型>#</a></h2><p>下面，我们写出优化问题的目标函数 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">J(\theta)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.09618em>J</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.02778em>θ</span><span class=mclose>)</span></span></span></span>，即负对数似然函数：</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mi>T</mi></mfrac><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><munder><mo>∑</mo><mstyle scriptlevel="1"><mtable rowspacing="0.1em" columnalign="center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="1" displaystyle="false"><mrow><mi>i</mi><mo>∈</mo><mo stretchy="false">[</mo><mo>−</mo><mi>c</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="1" displaystyle="false"><mrow><mi>i</mi><mo mathvariant="normal">≠</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mstyle></munder><mi>log</mi><mo>⁡</mo><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
J(\theta)=-\frac{1}{T} \sum_{t=1}^T \sum_{\substack{i \in[-c, c] \\ i \neq 0}} \log P\left(w_{t+i} \mid w_t\right)
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.09618em>J</span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.02778em>θ</span><span class=mclose>)</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:3.9666em;vertical-align:-2.1382em></span><span class=mord>−</span><span class=mord><span class="mopen nulldelimiter"></span><span class=mfrac><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.3214em><span style=top:-2.314em><span class=pstrut style=height:3em></span><span class=mord><span class="mord mathnormal" style=margin-right:.13889em>T</span></span></span><span style=top:-3.23em><span class=pstrut style=height:3em></span><span class=frac-line style=border-bottom-width:.04em></span></span><span style=top:-3.677em><span class=pstrut style=height:3em></span><span class=mord><span class=mord>1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.686em><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace style=margin-right:.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8829em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.13889em>T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2671em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.05em><span style=top:-1.4979em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class=mtable><span class=col-align-c><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.1944em><span style=top:-3.1944em><span class=pstrut style=height:2.75em></span><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">∈</span><span class="mopen mtight">[</span><span class="mord mtight">−</span><span class="mord mathnormal mtight">c</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">c</span><span class="mclose mtight">]</span></span></span><span style=top:-2.25em><span class=pstrut style=height:2.75em></span><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class=strut style=height:.8889em;vertical-align:-.1944em></span><span class=inner><span class="mord mtight"><span class="mrel mtight"></span></span></span><span class=fix></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mtight">0</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.6944em><span></span></span></span></span></span></span></span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:2.1382em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class=mop>lo<span style=margin-right:.01389em>g</span></span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span></span></span><p>现在，我们的问题在于条件概率分布 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">P\left(w_{t+i} \mid w_t\right)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span></span>。在给定 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">w_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 时，<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">w_{t+1}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6389em;vertical-align:-.2083em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span></span></span></span> 的概率分布应该是什么样子的？</p><p>下面，我们用 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>O</mi></msub></mrow><annotation encoding="application/x-tex">w_O</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.02778em>O</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 和 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>I</mi></msub></mrow><annotation encoding="application/x-tex">w_I</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.07847em>I</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 来分别表示 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">w_{t+1}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6389em;vertical-align:-.2083em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span></span></span></span> 和 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">w_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 以此简化符号，<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi></mrow><annotation encoding="application/x-tex">I</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.07847em>I</span></span></span></span> 表示输入（Input），<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi></mrow><annotation encoding="application/x-tex">O</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.02778em>O</span></span></span></span> 表示输出（Output）。此时，条件概率分布表示为：<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mrow><mo fence="true">(</mo><msub><mi>w</mi><mi>O</mi></msub><mo>∣</mo><msub><mi>w</mi><mi>I</mi></msub><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">P\left(w_O \mid w_I\right)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.02778em>O</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.07847em>I</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span></span></span></span>。</p><figure class=align-center><img loading=lazy src=images/word_vector_conditional_probability_distribution_table.svg#center alt=词向量条件概率分布的表格 width=600><figcaption><p>词向量条件概率分布的表格</p></figcaption></figure><p>在给定一个 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>I</mi></msub><mo>=</mo><msub><mi>ω</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">w_I = \omega_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.07847em>I</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.03588em>ω</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0359em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 作为中心词后，<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>O</mi></msub><mo>∣</mo><msub><mi>w</mi><mi>I</mi></msub><mo>=</mo><msub><mi>ω</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">w_O \mid w_I = \omega_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.02778em>O</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.07847em>I</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.03588em>ω</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0359em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 是一个离散型随机变量，我们可以通过表格的方式写出它的 <strong>概率质量函数（Probability mass function）</strong>，如上图所示。并且这个概率值满足下面的关系式：</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi mathvariant="normal">∣</mi><mi>V</mi><mi mathvariant="normal">∣</mi></mrow></munderover><msub><mi>p</mi><mi>j</mi></msub><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mspace width="1em"/><msub><mi>p</mi><mi>j</mi></msub><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">
\sum_{j=1}^{|V|} p_j=1, \quad p_j \in[0,1]
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:3.3748em;vertical-align:-1.4138em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.961em><span style=top:-1.8723em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.05724em>j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.386em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style=margin-right:.22222em>V</span><span class="mord mtight">∣</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.4138em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal">p</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:0;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.9305em;vertical-align:-.2861em></span><span class=mord>1</span><span class=mpunct>,</span><span class=mspace style=margin-right:1em></span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal">p</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:0;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>[</span><span class=mord>0</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>1</span><span class=mclose>]</span></span></span></span></span><p>那么，这个问题其实可以看做机器学习中的多分类问题。在给出输入 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>I</mi></msub><mo>=</mo><msub><mi>ω</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">w_I = \omega_i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.07847em>I</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.03588em>ω</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0359em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 后，我们来预测下一个词 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>O</mi></msub></mrow><annotation encoding="application/x-tex">w_O</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.02778em>O</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 的概率，即：</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><msub><mi>P</mi><mi>j</mi></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>P</mi><mrow><mo fence="true">{</mo><msub><mi>w</mi><mi>O</mi></msub><mo>=</mo><msub><mi>ω</mi><mi>j</mi></msub><mo>∣</mo><msub><mi>w</mi><mi>I</mi></msub><mo>=</mo><msub><mi>ω</mi><mi>i</mi></msub><mo fence="true">}</mo></mrow></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi mathvariant="normal">softmax</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="normal">Δ</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
P_j &amp; =P\left\{w_O=\omega_j \mid w_I=\omega_i\right\} \\
&amp; =\operatorname{softmax}(\Delta_j)
\end{aligned}
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:3em;vertical-align:-1.25em></span><span class=mord><span class=mtable><span class=col-align-r><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.75em><span style=top:-3.91em><span class=pstrut style=height:3em></span><span class=mord><span class=mord><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.1389em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2861em><span></span></span></span></span></span></span></span></span><span style=top:-2.41em><span class=pstrut style=height:3em></span><span class=mord></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.25em><span></span></span></span></span></span><span class=col-align-l><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.75em><span style=top:-3.91em><span class=pstrut style=height:3em></span><span class=mord><span class=mord></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>{</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.02778em>O</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.03588em>ω</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0359em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2861em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.07847em>I</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span><span class=mord><span class="mord mathnormal" style=margin-right:.03588em>ω</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0359em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>}</span></span></span></span><span style=top:-2.41em><span class=pstrut style=height:3em></span><span class=mord><span class=mord></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span><span class=mop><span class="mord mathrm">softmax</span></span><span class=mopen>(</span><span class=mord><span class=mord>Δ</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:0;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2861em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.25em><span></span></span></span></span></span></span></span></span></span></span></span><p>我们可以用神经网络的方式来建模这里的 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi></mrow><annotation encoding="application/x-tex">\Delta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class=mord>Δ</span></span></span></span>，然后用 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Softmax</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\operatorname{Softmax}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6944em></span><span class=mop><span class="mord mathrm">Softmax</span></span></span></span></span> 来做一下归一化，得到最终的概率值。</p><figure class=align-center><img loading=lazy src=images/neural_network_modeling_word_vector.svg#center alt=神经网络建模词向量 width=600><figcaption><p>神经网络建模词向量</p></figcaption></figure><p>观察这个神经网络，它可以表示成如下的矩阵乘法的形式：</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>ω</mi><mi>i</mi><mi mathvariant="normal">T</mi></msubsup><mo>⋅</mo><mi>W</mi><mo>⋅</mo><mi>U</mi><mo>=</mo><msup><mi mathvariant="normal">Δ</mi><mi mathvariant="normal">T</mi></msup></mrow><annotation encoding="application/x-tex">
\omega_i^\mathrm{T} \cdot W \cdot U = \Delta^\mathrm{T}
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.1383em;vertical-align:-.247em></span><span class=mord><span class="mord mathnormal" style=margin-right:.03588em>ω</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.8913em><span style=top:-2.453em;margin-left:-.0359em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.247em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.13889em>W</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.10903em>U</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.8913em></span><span class=mord><span class=mord>Δ</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8913em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">T</span></span></span></span></span></span></span></span></span></span></span></span><p>其中，<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ω</mi><mi>i</mi></msub><mo>=</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><msup><mo stretchy="false">]</mo><mi mathvariant="normal">T</mi></msup></mrow><annotation encoding="application/x-tex">\omega_i = [0, 0, \cdots, 0, 1, 0, \cdots, 0, 0]^\mathrm{T}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.03588em>ω</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0359em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:1.0913em;vertical-align:-.25em></span><span class=mopen>[</span><span class=mord>0</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>0</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=minner>⋯</span><span class=mspace style=margin-right:.1667em></span><span class=mspace style=margin-right:.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>0</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>1</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>0</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=minner>⋯</span><span class=mspace style=margin-right:.1667em></span><span class=mspace style=margin-right:.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>0</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>0</span><span class=mclose><span class=mclose>]</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8413em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">T</span></span></span></span></span></span></span></span></span></span></span>。矩阵乘法 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>ω</mi><mi>i</mi><mi mathvariant="normal">T</mi></msubsup><mo>⋅</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">\omega_i^\mathrm{T} \cdot W</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.1em;vertical-align:-.2587em></span><span class=mord><span class="mord mathnormal" style=margin-right:.03588em>ω</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.8413em><span style=top:-2.4413em;margin-left:-.0359em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2587em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>⋅</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.13889em>W</span></span></span></span> 实际就是将权重矩阵 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.13889em>W</span></span></span></span> 的第 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6595em></span><span class="mord mathnormal">i</span></span></span></span> 行取出来。</p><h2 id=word2vec-实现示例>Word2Vec 实现示例<a hidden class=anchor aria-hidden=true href=#word2vec-实现示例>#</a></h2><p>Word2Vec 包含两种对偶结构：Skip-gram 与 CBOW。</p><ul><li><strong>Skip-gram</strong>：已知中心词 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">w_t</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span>，预测窗口内的上下文词 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{t+i}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6389em;vertical-align:-.2083em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span></span></span></span>。适合小语料、能较好刻画低频词。</li><li><strong>CBOW</strong>：已知上下文，预测中心词。训练更快，适合大语料。</li></ul><h3 id=1-数据与词表构建>1. 数据与词表构建<a hidden class=anchor aria-hidden=true href=#1-数据与词表构建>#</a></h3><p>下面这段代码将语料打平成词序列，构建词表及索引映射。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>sentences</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;apple is red&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;banana is yellow&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;grape is purple&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;apple is sweet&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;banana is sweet&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;grape is sweet&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;orange is orange&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;apple is fruit&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;banana is fruit&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;grape is fruit&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;orange is fruit&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Convert sentences to list of words</span>
</span></span><span class=line><span class=cl><span class=n>words</span> <span class=o>=</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>sentences</span><span class=p>)</span><span class=o>.</span><span class=n>split</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>vocab</span> <span class=o>=</span> <span class=n>sort</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>words</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>word_to_idx</span> <span class=o>=</span> <span class=p>{</span><span class=n>w</span><span class=p>:</span> <span class=n>i</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>w</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>vocab</span><span class=p>)}</span>
</span></span><span class=line><span class=cl><span class=n>idx_to_word</span> <span class=o>=</span> <span class=p>{</span><span class=n>i</span><span class=p>:</span> <span class=n>w</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>w</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>vocab</span><span class=p>)}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>vocab_size</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>vocab</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><code>word_to_idx</code> / <code>idx_to_word</code> 提供了从离散词到序号的映射，后续 <code>nn.Embedding</code> 直接以词的<strong>索引</strong>作为输入进行查表。</li></ul><h3 id=2-构造-skip-gram-训练样本>2. 构造 Skip-gram 训练样本<a hidden class=anchor aria-hidden=true href=#2-构造-skip-gram-训练样本>#</a></h3><p><code>create_skip_gram_data</code> 会以窗口大小 <code>window_size=2</code> 滑动，生成 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mtext>中心词</mtext><mo separator="true">,</mo><mtext>上下文词</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\text{中心词}, \text{上下文词})</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord text"><span class="mord cjk_fallback">中心词</span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord text"><span class="mord cjk_fallback">上下文词</span></span><span class=mclose>)</span></span></span></span> 二元组。Skip-gram 的监督信号即这些配对的“正确上下文词”。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_skip_gram_data</span><span class=p>(</span><span class=n>sentences</span><span class=p>,</span> <span class=n>window_size</span><span class=o>=</span><span class=mi>2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>sentence</span> <span class=ow>in</span> <span class=n>sentences</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>words</span> <span class=o>=</span> <span class=n>sentence</span><span class=o>.</span><span class=n>split</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>word</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>words</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=nb>max</span><span class=p>(</span><span class=n>i</span> <span class=o>-</span> <span class=n>window_size</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=nb>min</span><span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=n>window_size</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>words</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>i</span> <span class=o>!=</span> <span class=n>j</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>data</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>word</span><span class=p>,</span> <span class=n>words</span><span class=p>[</span><span class=n>j</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>skip_gram_data</span> <span class=o>=</span> <span class=n>create_skip_gram_data</span><span class=p>(</span><span class=n>sentences</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>例子</strong>（以 “apple is red” 且窗口=2 为例）：</p><ul><li>生成的配对包括 <code>("apple","is")</code>, <code>("apple","red")</code>, <code>("is","apple")</code>, <code>("is","red")</code>, <code>("red","apple")</code>, <code>("red","is")</code>。</li><li>训练目标是：给定中心词（如 <code>"apple"</code>），最大化其投票出正确上下文（如 <code>"is"</code>, <code>"red"</code>）的概率。</li></ul><h3 id=3-模型定义>3. 模型定义<a hidden class=anchor aria-hidden=true href=#3-模型定义>#</a></h3><p>Skip-Gram 模型使用嵌入层（<code>nn.Embedding</code>）将输入单词索引映射到低维向量空间，然后通过线性层投影到词汇表大小的输出空间。该架构对应前文神经网络建模，其中输入到隐藏层的权重矩阵即为词嵌入矩阵。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>SkipGram</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>SkipGram</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>input_to_hidden</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>hidden_to_output</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>embedding_dim</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>  <span class=c1># x: [batch_size,]</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>input_to_hidden</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>   <span class=c1># [B, d]</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>hidden_to_output</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># [B, |V|] -&gt; logits</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>矩阵视角</strong>：Skip-gram 模型本质上是两个矩阵变换的组合。</p><ul><li>设嵌入矩阵为 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi mathvariant="normal">∣</mi><mi>V</mi><mi mathvariant="normal">∣</mi><mo>×</mo><mi>d</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W\in\mathbb{R}^{|V|\times d}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7224em;vertical-align:-.0391em></span><span class="mord mathnormal" style=margin-right:.13889em>W</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.888em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.888em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style=margin-right:.22222em>V</span><span class="mord mtight">∣</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">d</span></span></span></span></span></span></span></span></span></span></span></span>，输出投影为 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>d</mi><mo>×</mo><mi mathvariant="normal">∣</mi><mi>V</mi><mi mathvariant="normal">∣</mi></mrow></msup></mrow><annotation encoding="application/x-tex">U\in\mathbb{R}^{d\times |V|}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7224em;vertical-align:-.0391em></span><span class="mord mathnormal" style=margin-right:.10903em>U</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∈</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.888em></span><span class=mord><span class="mord mathbb">R</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.888em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mbin mtight">×</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight" style=margin-right:.22222em>V</span><span class="mord mtight">∣</span></span></span></span></span></span></span></span></span></span></span></span>。</li><li>one-hot 的 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>ω</mi><mi>i</mi><mi mathvariant="normal">T</mi></msubsup><mi>W</mi></mrow><annotation encoding="application/x-tex">\omega_i^\mathrm{T} W</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.1em;vertical-align:-.2587em></span><span class=mord><span class="mord mathnormal" style=margin-right:.03588em>ω</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.8413em><span style=top:-2.4413em;margin-left:-.0359em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathrm mtight">T</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2587em><span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:.13889em>W</span></span></span></span> 等价于从 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.13889em>W</span></span></span></span> 取出第 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6595em></span><span class="mord mathnormal">i</span></span></span></span> 行，即中心词的嵌入 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">e</mi><msub><mi>w</mi><mi>t</mi></msub></msub></mrow><annotation encoding="application/x-tex">\mathbf{e}_{w_t}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6945em;vertical-align:-.2501em></span><span class=mord><span class="mord mathbf">e</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.1514em><span style=top:-2.55em;margin-left:0;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2963em><span style=top:-2.357em;margin-left:-.0269em;margin-right:.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.143em><span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2501em><span></span></span></span></span></span></span></span></span></span>。</li><li>logits <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mo>=</mo><msub><mi mathvariant="bold">e</mi><msub><mi>w</mi><mi>t</mi></msub></msub><mi>U</mi></mrow><annotation encoding="application/x-tex">\Delta = \mathbf{e}_{w_t} U</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class=mord>Δ</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.9334em;vertical-align:-.2501em></span><span class=mord><span class="mord mathbf">e</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.1514em><span style=top:-2.55em;margin-left:0;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2963em><span style=top:-2.357em;margin-left:-.0269em;margin-right:.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.143em><span></span></span></span></span></span></span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2501em><span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:.10903em>U</span></span></span></span>，通过 softmax 得到 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(w_{t+i}\mid w_t)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mopen>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span>。</li></ul><p>通过 <code>nn.Embedding</code> 查表的方式等价于前文描述的：one-hot×权重，但训练实际只用 <code>nn.Embedding</code>，计算更高效。</p><h3 id=4-模型训练>4. 模型训练<a hidden class=anchor aria-hidden=true href=#4-模型训练>#</a></h3><p>训练过程使用交叉熵损失（CrossEntropyLoss）优化模型参数，通过 SGD 优化器迭代 10000 个 epoch。每 epoch 随机打乱数据，计算平均损失。嵌入维度为 2，学习率为 0.001。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>embedding_dim</span> <span class=o>=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>0.001</span>
</span></span><span class=line><span class=cl><span class=n>num_epochs</span> <span class=o>=</span> <span class=mi>10000</span>
</span></span><span class=line><span class=cl><span class=n>log_interval</span> <span class=o>=</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>SkipGram</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>losses</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>random</span><span class=o>.</span><span class=n>shuffle</span><span class=p>(</span><span class=n>skip_gram_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss_sum</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>context</span><span class=p>,</span> <span class=n>target</span> <span class=ow>in</span> <span class=n>skip_gram_data</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>context_idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=n>word_to_idx</span><span class=p>[</span><span class=n>context</span><span class=p>]],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>target_idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=n>word_to_idx</span><span class=p>[</span><span class=n>target</span><span class=p>]],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>context_idx</span><span class=p>)</span>      <span class=c1># logits: [1, |V|]</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>target_idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>loss_sum</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>loss_sum</span> <span class=o>=</span> <span class=n>loss_sum</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>skip_gram_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>losses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>loss_sum</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><code>CrossEntropyLoss(logits, target_idx)</code> 等价于 <code>log_softmax + NLLLoss</code>，直接最小化 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>log</mi><mo>⁡</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mi>i</mi></mrow></msub><mo>∣</mo><msub><mi>w</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">-\log P(w_{t+i}\mid w_t)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mord>−</span><span class=mspace style=margin-right:.1667em></span><span class=mop>lo<span style=margin-right:.01389em>g</span></span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.13889em>P</span><span class=mopen>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2083em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>∣</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mord><span class="mord mathnormal" style=margin-right:.02691em>w</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.2806em><span style=top:-2.55em;margin-left:-.0269em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span>。</li></ul><p>通过损失曲线可以看到，整体下降并趋于平稳，说明模型学到了 <strong>哪个中心词应与哪些上下文共现</strong> 的统计规律。</p><figure class=align-center><img loading=lazy src=images/skip_gram_emb_loss.png#center alt="Skip-gram 损失曲线" width=500><figcaption><p>Skip-gram 损失曲线</p></figcaption></figure><p>下图展示了词嵌入在二维空间的散点分布，例如水果相关词汇（如：“apple”、“banana”、“grape”）趋于聚类，颜色词汇（如：“red”、“yellow”）则形成另一簇，语义相近的词（如颜色词、果名）明显靠得更近。</p><figure class=align-center><img loading=lazy src=images/skip_gram_emb_embeddings.png#center alt="Skip-gram 词嵌入在二维空间的散点分布" width=500><figcaption><p>Skip-gram 词嵌入在二维空间的散点分布</p></figcaption></figure><h3 id=5-完整代码>5. 完整代码<a hidden class=anchor aria-hidden=true href=#5-完整代码>#</a></h3><p>为了方便参考，以下是整合后的完整代码：</p><p><details><summary markdown=span>完整代码</summary><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>random</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.optim</span> <span class=k>as</span> <span class=nn>optim</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Some sentences for training</span>
</span></span><span class=line><span class=cl><span class=n>sentences</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;apple is red&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;banana is yellow&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;grape is purple&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;apple is sweet&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;banana is sweet&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;grape is sweet&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;orange is orange&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;apple is fruit&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;banana is fruit&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;grape is fruit&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;orange is fruit&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Convert sentences to list of words</span>
</span></span><span class=line><span class=cl><span class=n>words</span> <span class=o>=</span> <span class=s2>&#34; &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>sentences</span><span class=p>)</span><span class=o>.</span><span class=n>split</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>vocab</span> <span class=o>=</span> <span class=nb>sorted</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>words</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>word_to_idx</span> <span class=o>=</span> <span class=p>{</span><span class=n>w</span><span class=p>:</span> <span class=n>i</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>w</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>vocab</span><span class=p>)}</span>
</span></span><span class=line><span class=cl><span class=n>idx_to_word</span> <span class=o>=</span> <span class=p>{</span><span class=n>i</span><span class=p>:</span> <span class=n>w</span> <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>w</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>vocab</span><span class=p>)}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>vocab_size</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>vocab</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Vocab: &#34;</span><span class=p>,</span> <span class=n>vocab</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Word to index: &#34;</span><span class=p>,</span> <span class=n>word_to_idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Index to word: &#34;</span><span class=p>,</span> <span class=n>idx_to_word</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Vocab size: &#34;</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Generate training data</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_skip_gram_data</span><span class=p>(</span><span class=n>sentences</span><span class=p>,</span> <span class=n>window_size</span><span class=o>=</span><span class=mi>2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>sentence</span> <span class=ow>in</span> <span class=n>sentences</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>words</span> <span class=o>=</span> <span class=n>sentence</span><span class=o>.</span><span class=n>split</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>word</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>words</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>j</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=nb>max</span><span class=p>(</span><span class=n>i</span> <span class=o>-</span> <span class=n>window_size</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=nb>min</span><span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=n>window_size</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>words</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>i</span> <span class=o>!=</span> <span class=n>j</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>data</span><span class=o>.</span><span class=n>append</span><span class=p>((</span><span class=n>word</span><span class=p>,</span> <span class=n>words</span><span class=p>[</span><span class=n>j</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>data</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>skip_gram_data</span> <span class=o>=</span> <span class=n>create_skip_gram_data</span><span class=p>(</span><span class=n>sentences</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Skip gram data: &#34;</span><span class=p>,</span> <span class=n>skip_gram_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Convert skip gram data to one-hot vectors</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>to_one_hot</span><span class=p>(</span><span class=n>word_idx</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>one_hot</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>one_hot</span><span class=p>[</span><span class=n>word_idx</span><span class=p>]</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>one_hot</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define skip gram model</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>SkipGram</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>SkipGram</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>input_to_hidden</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>hidden_to_output</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>embedding_dim</span><span class=p>,</span> <span class=n>vocab_size</span><span class=p>,</span> <span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>  <span class=c1># x: [batch_size,]</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>input_to_hidden</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>hidden_to_output</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define training parameters</span>
</span></span><span class=line><span class=cl><span class=n>embedding_dim</span> <span class=o>=</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl><span class=n>learning_rate</span> <span class=o>=</span> <span class=mf>0.001</span>
</span></span><span class=line><span class=cl><span class=n>num_epochs</span> <span class=o>=</span> <span class=mi>10000</span>
</span></span><span class=line><span class=cl><span class=n>log_interval</span> <span class=o>=</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Create skip gram model</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>SkipGram</span><span class=p>(</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Define loss function and optimizer</span>
</span></span><span class=line><span class=cl><span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>learning_rate</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Train the model</span>
</span></span><span class=line><span class=cl><span class=n>losses</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>random</span><span class=o>.</span><span class=n>shuffle</span><span class=p>(</span><span class=n>skip_gram_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss_sum</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>context</span><span class=p>,</span> <span class=n>target</span> <span class=ow>in</span> <span class=n>skip_gram_data</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>context_idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=n>word_to_idx</span><span class=p>[</span><span class=n>context</span><span class=p>]],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>target_idx</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>([</span><span class=n>word_to_idx</span><span class=p>[</span><span class=n>target</span><span class=p>]],</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Forward pass</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>context_idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>target_idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Backward and optimize</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>loss_sum</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>loss_sum</span> <span class=o>=</span> <span class=n>loss_sum</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=n>skip_gram_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>losses</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>loss_sum</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>epoch</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>%</span> <span class=n>log_interval</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Epoch [</span><span class=si>{}</span><span class=s2>/</span><span class=si>{}</span><span class=s2>], Loss: </span><span class=si>{:.4f}</span><span class=s2>&#34;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>epoch</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=n>num_epochs</span><span class=p>,</span> <span class=n>loss_sum</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Plot losses</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>losses</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&#34;Epoch&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&#34;Loss&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&#34;Skip Gram (nn.Embedding) Loss&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s2>&#34;skip_gram_emb_loss.png&#34;</span><span class=p>,</span> <span class=n>dpi</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Get embeddings</span>
</span></span><span class=line><span class=cl><span class=n>embeddings</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>input_to_hidden</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Embeddings:&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>word</span><span class=p>,</span> <span class=n>idx</span> <span class=ow>in</span> <span class=n>word_to_idx</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>word</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>embeddings</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Plot embeddings</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>5</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>word</span><span class=p>,</span> <span class=n>idx</span> <span class=ow>in</span> <span class=n>word_to_idx</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>scatter</span><span class=p>(</span><span class=n>embeddings</span><span class=p>[</span><span class=n>idx</span><span class=p>][</span><span class=mi>0</span><span class=p>],</span> <span class=n>embeddings</span><span class=p>[</span><span class=n>idx</span><span class=p>][</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>annotate</span><span class=p>(</span><span class=n>word</span><span class=p>,</span> <span class=p>(</span><span class=n>embeddings</span><span class=p>[</span><span class=n>idx</span><span class=p>][</span><span class=mi>0</span><span class=p>],</span> <span class=n>embeddings</span><span class=p>[</span><span class=n>idx</span><span class=p>][</span><span class=mi>1</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s2>&#34;Dimension 1&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s2>&#34;Dimension 2&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&#34;Skip Gram (nn.Embedding) Embeddings&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s2>&#34;skip_gram_emb_embeddings.png&#34;</span><span class=p>,</span> <span class=n>dpi</span><span class=o>=</span><span class=mi>300</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div></details></p><h2 id=参考资料>参考资料<a hidden class=anchor aria-hidden=true href=#参考资料>#</a></h2><ol><li><a href=https://www.bilibili.com/video/BV1hy4y1n7ik>词向量(Word Vector)【白板推导系列】</a></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://ehehe.cn/tags/word2vec/>Word2Vec</a></li><li><a href=https://ehehe.cn/tags/%E8%AF%8D%E5%B5%8C%E5%85%A5/>词嵌入</a></li><li><a href=https://ehehe.cn/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/>自然语言处理</a></li><li><a href=https://ehehe.cn/tags/skip-gram/>Skip-Gram</a></li><li><a href=https://ehehe.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></li></ul><nav class=paginav><a class=prev href=https://ehehe.cn/posts/2024/01-nerf/><span class=title>« Prev</span><br><span>基于 NeRF 的三维场景生成</span>
</a><a class=next href=https://ehehe.cn/posts/2023/02-swin-transformer/><span class=title>Next »</span><br><span>Swin Transformer：层级式特征图与移动窗口注意力机制</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://ehehe.cn/>Yan Tang</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){function e(){var e,t,n,s=document.getElementsByTagName("code");for(n=0;n<s.length;){if(t=s[n],t.parentNode.tagName!=="PRE"&&t.childElementCount===0&&(e=t.textContent,/^\$[^$]/.test(e)&&/[^$]\$$/.test(e)&&(e=e.replace(/^\$/,"\\(").replace(/\$$/,"\\)"),t.textContent=e),/^\\\((.|\s)+\\\)$/.test(e)||/^\\\[(.|\s)+\\\]$/.test(e)||/^\$(.|\s)+\$$/.test(e)||/^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(e))){t.outerHTML=t.innerHTML;continue}n++}}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",e,{once:!0}):e()})()</script><script>(function(){var n=window.pageYOffset||document.documentElement.scrollTop||0,s=800,t=!1,e=null;function o(){if(t=!1,e||(e=document.getElementById("top-link")),!e)return;var o=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,i=o>n;n=o<0?0:o,o>s&&!i?(e.style.visibility="visible",e.style.opacity="1"):(e.style.visibility="hidden",e.style.opacity="0")}window.addEventListener("scroll",function(){t||(window.requestAnimationFrame(o),t=!0)},{passive:!0})})()</script><script>(function(){var t=10;function n(e){if(!e)return[0,20];var n,s,o=window.getComputedStyle(e),t=parseFloat(o.lineHeight);return(!t||isNaN(t))&&(t=20),n=e.getBoundingClientRect(),s=n.height||e.offsetHeight||0,[Math.round(s/t),t]}function e(){var e=document.querySelectorAll(".highlight");if(!e||!e.length)return;Array.prototype.forEach.call(e,function(e){if(e.classList.contains("expanded")||e.classList.contains("collapsible"))return;var s,o,a,r,c,l,i=e.querySelector("pre code");if(!i)return;if(r=i.className||"",r.indexOf("language-mermaid")>=0||e.classList.contains("mermaid"))return;if(a=n(i),c=a[0],l=a[1],c<=t)return;e.classList.add("collapsible"),e.style.setProperty("--code-line-height",l+"px"),e.id||(e.id="code-block-"+Math.random().toString(36).slice(2)),o=document.createElement("div"),o.className="code-expand-wrapper",s=document.createElement("button"),s.type="button",s.className="code-expand-link",s.textContent="Show more",s.setAttribute("aria-expanded","false"),s.setAttribute("aria-controls",e.id),s.addEventListener("click",function(){var n,i,a,o=e.classList.contains("expanded"),r=getComputedStyle(e).getPropertyValue("--code-line-height"),t=parseFloat(r)*(parseFloat(getComputedStyle(e).getPropertyValue("--code-max-lines"))||10);(!isFinite(t)||t<=0)&&(t=10*20),i=e.getBoundingClientRect().height,a=o?t:e.scrollHeight,e.style.maxHeight=i+"px",e.offsetHeight,o?e.classList.remove("expanded"):e.classList.add("expanded"),e.style.maxHeight=a+"px",n=function(t){if(t.propertyName!=="max-height")return;if(e.removeEventListener("transitionend",n),e.style.maxHeight="",e.classList.contains("expanded"))s.textContent="Show less",s.setAttribute("aria-expanded","true");else{s.textContent="Show more",s.setAttribute("aria-expanded","false");try{e.scrollIntoView({behavior:"smooth",block:"nearest"})}catch{}}window.dispatchEvent(new Event("resize"))},e.addEventListener("transitionend",n)}),o.appendChild(s),e.nextSibling?e.parentNode.insertBefore(o,e.nextSibling):e.parentNode.appendChild(o)})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",e,{once:!0}):e()})()</script><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>