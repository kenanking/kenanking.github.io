<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>基于 NeRF 的三维场景生成 | Yan Tang</title><meta name=keywords content="NeRF"><meta name=description content="基于 NeRF 的三维场景生成"><meta name=author content="Yan Tang"><link rel=canonical href=https://kenanking.github.io/posts/2024/01-nerf/><link crossorigin=anonymous href=/assets/css/stylesheet.7d6c2be2ce8d304b9de78bb980a8328b9454f69f9c59241fe5c9b37e708b283c.css integrity="sha256-fWwr4s6NMEud54u5gKgyi5RU9p+cWSQf5cmzfnCLKDw=" rel="preload stylesheet" as=style><link rel=icon href=https://kenanking.github.io/assets/images/favicon-16x16.ico><link rel=icon type=image/png sizes=16x16 href=https://kenanking.github.io/assets/images/favicon-16x16.ico><link rel=icon type=image/png sizes=32x32 href=https://kenanking.github.io/assets/images/favicon-32x32.ico><link rel=apple-touch-icon href=https://kenanking.github.io/assets/images/apple-touch-icon.png><link rel=mask-icon href=https://kenanking.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://kenanking.github.io/posts/2024/01-nerf/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link href=https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css rel=stylesheet integrity=sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP crossorigin=anonymous><meta property="og:url" content="https://kenanking.github.io/posts/2024/01-nerf/"><meta property="og:site_name" content="Yan Tang"><meta property="og:title" content="基于 NeRF 的三维场景生成"><meta property="og:description" content="基于 NeRF 的三维场景生成"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-02-29T14:20:32+00:00"><meta property="article:modified_time" content="2024-02-29T14:20:32+00:00"><meta property="article:tag" content="NeRF"><meta name=twitter:card content="summary"><meta name=twitter:title content="基于 NeRF 的三维场景生成"><meta name=twitter:description content="基于 NeRF 的三维场景生成"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://kenanking.github.io/posts/"},{"@type":"ListItem","position":2,"name":"基于 NeRF 的三维场景生成","item":"https://kenanking.github.io/posts/2024/01-nerf/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"基于 NeRF 的三维场景生成","name":"基于 NeRF 的三维场景生成","description":"基于 NeRF 的三维场景生成","keywords":["NeRF"],"articleBody":"背景 1.1 经典三维场景表征与神经表征 经典的三维场景表征方法有 体素表示、点云表示 和 网格表示，这三种表示是直接的、显而易见的，因此归为 显式的 场景表示类别。这里介绍的 NeRF（Neural Radiance Fields）其实也是一种三维场景表征，但是是一种 隐式的 场景表示（implicit scene representation），因为它不能像点云、网格、体素一样直接看见一个三维模型，需要将神经表征转换到显示的表征或渲染成可见的图像才可以被看到。\n显示场景表征的特点是，它表示的 信号是离散的。相反，隐式神经表征 将信号参数化为连续函数，通常来说，普通的函数不可能做到这样一件事，因此用神经网络来逼近这样一个复杂的“自然函数”。\n显示 场景表征——离散 隐式 场景表征——连续 三维场景表征\n1.2 经典的 SFM 重建方法 经典 SFM 重建方法\n基于输入图像对相应特征进行提取，并根据特征相似性进行匹配；使用一些几何先验性知识，对匹配结果进行确认。这个过程是特征匹配的过程。经过以上步骤之后可以获得相机的位姿。 使用相机位姿投影并经过图像配准、三角化测量等步骤反复迭代，可以获得特征点的三维空间坐标。 再经过 bundle adjustment（BA）和噪声过滤的操作，便可以获得三维重建的最终结果。 1.3 NeRF 方法的思想 NeRF 工作流程\n使用 Nerf 进行重建，也是需要相机姿态的，这一步和 colmap 没有区别。\nNeRF 方法的主要想法通过输入稀疏的图像集，来优化底层的连续神经网络，该神经网络将三维场景隐式存储其中，我们只需要通过输入一个相机位姿，就可以获得场景图片，实现了合成复杂场景的全新视图。\n输入图像的位姿是已知的，这一位姿既可以通过外部测量的方式获取，也可以、也是最常用的方法是使用 SFM（运动恢复结构）确定每张图像对应相机的外方位元素。\n1.4 NeRF 的作用 三维场景内插 左侧是输入 NeRF 中的稀疏采样的图像（大约有五、六张），在 NeRF 迭代优化后，我们可以得到该场景在新视角下的影像。因此，NeRF 解决了三维场景内插的问题。\n稀疏采样图像与同一场景下的新视角\n生成三维模型 三维模型\n深度估计 深度估计\nNeRF 方法 2.1 NeRF——使用连续神经网络表示三维场景 NeRF 是一种三维场景的神经表征，通过输入稀疏图像训练，NeRF 可以内插出同一场景的不同影像。\n下面，我们来看一下 NeRF 的具体内容。NeRF 是 Neural Radiance Fields 的缩写，神经是指神经网络，辐射是因为这个神经网络表示了场景中的辐射信息。其中的场是指一个连续的函数映射，也就是这里的 FΘF_\\ThetaFΘ​，神经辐射场使用一个神经网络作为这里的函数映射。另外，也需要说明这里使用的不是卷积神经网络，而是一个相对浅层的多层感知机：\nNeRF 方法\n2.2 2D-\u003e3D 类比 NeRF 的问题，如果简化到二维，其实就是图像回归问题。给定一个神经网络，它的输入是平面上的坐标 xxx 和 yyy，表示了一个像素，输出是该点处的颜色值 (R,G,B)(R,G,B)(R,G,B)。为了能够完整地映射出原图像，这个神经网络需要记忆下原图像信息，因此在这里的神经网络是过拟合的。\nFΘ:x→c F_\\Theta : \\mathbf{x} \\rightarrow \\mathbf{c} FΘ​:x→c 图像回归示例\n这一问题在二维情况下，看起来是没有意义的，但这是对 NeRF 的一个很好的类推。在 NeRF 中，我们也用一个神经网络记忆了不同视角下图像信息，从而能够内插出新视角下的新图像。在 NeRF 中，我们需要神经网络是过拟合的，要求它能较好地学习到图像中的高频信息。\n真实图片与不使用位置编码的图像\n不过，我们看到在这个二维情况下，图像信息虽然好像恢复了，但没有完全恢复，图像仍然很模糊。这个问题在后面会提到如何解决（位置编码）。\n2.3 立体渲染 NeRF 如何生成特定视角下的图像？——立体渲染（volume rendering）\n在光线上采样一系列点 通过神经网络输出颜色值和密度 将颜色值和密度累加生成图像 NeRF 输入与输出\n从这张图我们可以看到 NeRF 的输入和输出对应的具体含义。对于从左边相机拍摄的图像，以光线 1 为例，我们在上面均匀采样一系列点，这每一个点对应神经网络的输入，通过神经网络的映射，我们得到了右边对应的输出。\n在得到了这一条射线上采样点的颜色值和透明度后，我们希望能得到该光线在图像上成像后的颜色值。这就需要用到 渲染。\n渲染就是用计算机模拟拍照这一过程，模拟“拍照”的对象是已存在的某种三维场景表示。\nNeRF 将场景表示为空间中任何点的密度 σ\\sigmaσ 和颜色值 c\\mathbf{c}c。 有了以 NeRF 形式存在的场景表示后，可以对该场景进行渲染，模拟生成新视角的图片。论文使用经典 立体渲染（volume rendering） 的原理，对经过相机的光线进行均匀采样，然后积分求和得到该光线的颜色。通过求解穿过场景的任何光线的颜色，就可以渲染合成新的图像。\nNeRF 立体渲染\n渲染一条光线：r(t)=o+td\\mathbf{r}(t)=\\mathbf{o}+t\\mathbf{d}r(t)=o+td C≈∑i=1NTiαici C \\approx \\sum_{i=1}^{N} T_i \\alpha_i c_i C≈i=1∑N​Ti​αi​ci​ 从 t1t_1t1​ 起被遮挡的光线量： Ti=∏j=1i−1(1−αj) T_i = \\prod_{j=1}^{i-1}(1 - \\alpha_j) Ti​=j=1∏i−1​(1−αj​) 第 iii 段贡献的光线量： αi=1−e−σiδti \\alpha_i = 1 - e^{-\\sigma_i \\delta t_i} αi​=1−e−σi​δti​从这里的公式可以看到，渲染一条光线的颜色，就是对光线上个点的颜色值进行加权求和，权由光线的路径和路径上各段的透明度确定。\nYour browser does not support the video tag. 2.4 使用梯度下降优化渲染损失 在渲染出一条光线的颜色后，与该光线的真实颜色对比，就可以计算出渲染的损失值。该光线的真实颜色由输出的图像确定。\nmin⁡Θ∑i∥render⁡(i)(FΘ)−Igt(i)∥2 \\min _{\\Theta} \\sum_i\\left\\|\\operatorname{render}^{(i)}\\left(F_{\\Theta}\\right)-I_{\\mathrm{gt}}^{(i)}\\right\\|^2 Θmin​i∑​​render(i)(FΘ​)−Igt(i)​​2 NeRF 渲染损失\n我们看到立体渲染的公式仅包含了简单的乘加和指数运算，每一步都是可微的，因此可以使用梯度下降的方式进行优化。\n训练完成后，就可以得到一个以多层感知机表示的三维场景。\n2.5 位置编码 通过前面的介绍，我们已经可以实现一个简单的 NeRF 了，这里可以看到简单实现的结果。不过我们会发现这个图像有点模糊，NeRF 模型没有很好地学习到图像中的高频信息。在论文中，作者使用了 位置编码 的方法，让神经网络能够更好地学习高频信息。\nNeRF 原始图像与位置编码\n在论文中，使用了 傅里叶基函数，对输入空间坐标坐标 (x,y,z)(x,y,z)(x,y,z) 和方向 (θ,ϕ)(\\theta,\\phi)(θ,ϕ) 进行编码。这里以二维为例，左图是之前的神经网络，这里多了一个 γ(x,y)\\gamma (x,y)γ(x,y) 的环节，也就是对输入 xxx，yyy 进行位置编码。编码的方式可以从右图中看到。xxx 和 yyy 表示了图像中像素的位置，首先将 xxx 和 yyy 归一化到 [−1,1][-1,1][−1,1] 的区间，然后分别用傅里叶基函数进行编码，最后将两者编码的结果合并在一起。\nγ(x)=(sin⁡(20πx),cos⁡(20πx),⋯ ,sin⁡(2L−1πx),cos⁡(2L−1πx)) \\gamma(\\mathrm{x})=\\left(\\sin \\left(2^0 \\pi \\mathrm{x}\\right), \\cos \\left(2^0 \\pi \\mathrm{x}\\right), \\cdots, \\sin \\left(2^{L-1} \\pi \\mathrm{x}\\right), \\cos \\left(2^{L-1} \\pi \\mathrm{x}\\right)\\right) γ(x)=(sin(20πx),cos(20πx),⋯,sin(2L−1πx),cos(2L−1πx)) NeRF 加入位置编码后的图像回归示例\n原来神经网络的输入是只有 xxx，yyy 的一个二维向量，现在的输入变成了一个高维向量。\n在上文中已经展示了使用位置编码后神经网络对二维图像的拟合结果，明显可以看到位置编码的结果更加清晰。\n2.6 为什么 Fourier 位置编码有效？ 这里主要是为了解释为什么傅里叶位置编码会有效？这部分偏向我个人的看法。这里进一步把二维图像回归的问题，简化为一维曲线拟合的问题。\n曲线拟合示例\n在曲线拟合问题中，如果只输入 xxx，我们可以拟合一条直线，为了拟合复杂的曲线，我们从用二次曲线或三次曲线等，也就是使用 多项式基函数，将输入 xxx，变换为 (x0,x1,…,xN)(x^0,x^1,\\ldots,x^N)(x0,x1,…,xN) 等。\n为了更好地拟合图像中的高频信息，可以使用 高频的基函数，如 傅里叶基函数 作为输入。从右图中可以看到，当 L=8L=8L=8 时，傅里叶基函数对高频信息有较好的拟合。不过，这里的 NNN 也不宜选择过大，会增加图像中的噪声。\n实验 colmap Colmap 是一个开源的三维重建框架，提供了通用的运动恢复结构（SFM）和立体几何重建的相关功能。在实验中可用于获取相机的真实位姿。\ninstant-ngp instant-ngp 是英伟达实验室发布的一个使用 NeRF 快速三维重建的项目，能够在几秒内实现 NeRF 训练的收敛，在实际测试中，通常 2-3 秒可以看到结果，在 2 分钟内基本可以稳定下来。\n参考资料 Mildenhall, Ben, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi and Ren Ng. 2020. “NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis.” In ECCV. Tancik, Matthew, Pratul Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan Barron, and Ren Ng. 2020. “Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains.” In NIPS. Mescheder, Lars, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and Andreas Geiger. 2019. “Occupancy Networks: Learning 3D Reconstruction in Function Space.” In CVPR. “NeRF: Neural Radiance Fields.” https://www.youtube.com/watch?v=LRAqeM8EjOo. ","wordCount":"372","inLanguage":"en","datePublished":"2024-02-29T14:20:32Z","dateModified":"2024-02-29T14:20:32Z","author":{"@type":"Person","name":"Yan Tang"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://kenanking.github.io/posts/2024/01-nerf/"},"publisher":{"@type":"Organization","name":"Yan Tang","logo":{"@type":"ImageObject","url":"https://kenanking.github.io/assets/images/favicon-16x16.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://kenanking.github.io/ accesskey=h title="Yan Tang (Alt + H)">Yan Tang</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://kenanking.github.io/ title=Posts><span>Posts</span></a></li><li><a href=https://kenanking.github.io/about/ title=About><span>About</span></a></li><li><a href=https://kenanking.github.io/publications/ title=Publications><span>Publications</span></a></li><li><a href=https://kenanking.github.io/archives/ title=Archives><span>Archives</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">基于 NeRF 的三维场景生成</h1><div class=post-description>基于 NeRF 的三维场景生成</div><div class=post-meta><span title='2024-02-29 14:20:32 +0000 UTC'>February 29, 2024</span>&nbsp;·&nbsp;<span>2 min</span>&nbsp;·&nbsp;<span>Yan Tang</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e8%83%8c%e6%99%af aria-label=背景>背景</a><ul><li><a href=#11-%e7%bb%8f%e5%85%b8%e4%b8%89%e7%bb%b4%e5%9c%ba%e6%99%af%e8%a1%a8%e5%be%81%e4%b8%8e%e7%a5%9e%e7%bb%8f%e8%a1%a8%e5%be%81 aria-label="1.1 经典三维场景表征与神经表征">1.1 经典三维场景表征与神经表征</a></li><li><a href=#12-%e7%bb%8f%e5%85%b8%e7%9a%84-sfm-%e9%87%8d%e5%bb%ba%e6%96%b9%e6%b3%95 aria-label="1.2 经典的 SFM 重建方法">1.2 经典的 SFM 重建方法</a></li><li><a href=#13-nerf-%e6%96%b9%e6%b3%95%e7%9a%84%e6%80%9d%e6%83%b3 aria-label="1.3 NeRF 方法的思想">1.3 NeRF 方法的思想</a></li><li><a href=#14-nerf-%e7%9a%84%e4%bd%9c%e7%94%a8 aria-label="1.4 NeRF 的作用">1.4 NeRF 的作用</a></li></ul></li><li><a href=#nerf-%e6%96%b9%e6%b3%95 aria-label="NeRF 方法">NeRF 方法</a><ul><li><a href=#21-nerf%e4%bd%bf%e7%94%a8%e8%bf%9e%e7%bb%ad%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e8%a1%a8%e7%a4%ba%e4%b8%89%e7%bb%b4%e5%9c%ba%e6%99%af aria-label="2.1 NeRF——使用连续神经网络表示三维场景">2.1 NeRF——使用连续神经网络表示三维场景</a></li><li><a href=#22-2d-3d-%e7%b1%bb%e6%af%94 aria-label="2.2 2D->3D 类比">2.2 2D->3D 类比</a></li><li><a href=#23-%e7%ab%8b%e4%bd%93%e6%b8%b2%e6%9f%93 aria-label="2.3 立体渲染">2.3 立体渲染</a></li><li><a href=#24-%e4%bd%bf%e7%94%a8%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8d%e4%bc%98%e5%8c%96%e6%b8%b2%e6%9f%93%e6%8d%9f%e5%a4%b1 aria-label="2.4 使用梯度下降优化渲染损失">2.4 使用梯度下降优化渲染损失</a></li><li><a href=#25-%e4%bd%8d%e7%bd%ae%e7%bc%96%e7%a0%81 aria-label="2.5 位置编码">2.5 位置编码</a></li><li><a href=#26-%e4%b8%ba%e4%bb%80%e4%b9%88-fourier-%e4%bd%8d%e7%bd%ae%e7%bc%96%e7%a0%81%e6%9c%89%e6%95%88 aria-label="2.6 为什么 Fourier 位置编码有效？">2.6 为什么 Fourier 位置编码有效？</a></li></ul></li><li><a href=#%e5%ae%9e%e9%aa%8c aria-label=实验>实验</a></li><li><a href=#%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99 aria-label=参考资料>参考资料</a></li></ul></div></details></div><div class=post-content><h2 id=背景>背景<a hidden class=anchor aria-hidden=true href=#背景>#</a></h2><h3 id=11-经典三维场景表征与神经表征>1.1 经典三维场景表征与神经表征<a hidden class=anchor aria-hidden=true href=#11-经典三维场景表征与神经表征>#</a></h3><p>经典的三维场景表征方法有 <strong>体素表示</strong>、<strong>点云表示</strong> 和 <strong>网格表示</strong>，这三种表示是直接的、显而易见的，因此归为 <strong>显式的</strong> 场景表示类别。这里介绍的 NeRF（Neural Radiance Fields）其实也是一种三维场景表征，但是是一种 <strong>隐式的</strong> 场景表示（implicit scene representation），因为它不能像点云、网格、体素一样直接看见一个三维模型，需要将神经表征转换到显示的表征或渲染成可见的图像才可以被看到。</p><p>显示场景表征的特点是，它表示的 <strong>信号是离散的</strong>。相反，隐式神经表征 <strong>将信号参数化为连续函数</strong>，通常来说，普通的函数不可能做到这样一件事，因此用神经网络来逼近这样一个复杂的“自然函数”。</p><ul><li><strong>显示</strong> 场景表征——<strong>离散</strong></li><li><strong>隐式</strong> 场景表征——<strong>连续</strong></li></ul><figure class=align-center><img loading=lazy src=images/3d-scene-representation.png#center alt=三维场景表征 width=80%><figcaption><p>三维场景表征</p></figcaption></figure><h3 id=12-经典的-sfm-重建方法>1.2 经典的 SFM 重建方法<a hidden class=anchor aria-hidden=true href=#12-经典的-sfm-重建方法>#</a></h3><figure class=align-center><img loading=lazy src=images/classic-sfm-reconstruction.png#center alt="经典 SFM 重建方法" width=90%><figcaption><p>经典 SFM 重建方法</p></figcaption></figure><ol><li>基于输入图像对相应特征进行提取，并根据特征相似性进行匹配；使用一些几何先验性知识，对匹配结果进行确认。这个过程是特征匹配的过程。经过以上步骤之后可以获得相机的位姿。</li><li>使用相机位姿投影并经过图像配准、三角化测量等步骤反复迭代，可以获得特征点的三维空间坐标。</li><li>再经过 bundle adjustment（BA）和噪声过滤的操作，便可以获得三维重建的最终结果。</li></ol><h3 id=13-nerf-方法的思想>1.3 NeRF 方法的思想<a hidden class=anchor aria-hidden=true href=#13-nerf-方法的思想>#</a></h3><figure class=align-center><img loading=lazy src=images/nerf-workflow.png#center alt="NeRF 工作流程" width=90%><figcaption><p>NeRF 工作流程</p></figcaption></figure><p>使用 Nerf 进行重建，也是需要相机姿态的，这一步和 colmap 没有区别。</p><p>NeRF 方法的主要想法通过输入稀疏的图像集，来优化底层的连续神经网络，该神经网络将三维场景隐式存储其中，我们只需要通过输入一个相机位姿，就可以获得场景图片，实现了合成复杂场景的全新视图。</p><p>输入图像的位姿是已知的，这一位姿既可以通过外部测量的方式获取，也可以、也是最常用的方法是使用 SFM（运动恢复结构）确定每张图像对应相机的外方位元素。</p><h3 id=14-nerf-的作用>1.4 NeRF 的作用<a hidden class=anchor aria-hidden=true href=#14-nerf-的作用>#</a></h3><ul><li><strong>三维场景内插</strong></li></ul><p>左侧是输入 NeRF 中的稀疏采样的图像（大约有五、六张），在 NeRF 迭代优化后，我们可以得到该场景在新视角下的影像。因此，NeRF 解决了三维场景内插的问题。</p><figure class="multi-figure align-center"><div class=multi-figure-container><div class=multi-figure-row data-images=2><figure class=multi-figure-item><img loading=lazy decoding=async src=images/sparse-sampling-image.webp alt></figure><figure class=multi-figure-item><img loading=lazy decoding=async src=images/new-view-image.webp alt></figure></div></div><figcaption><p>稀疏采样图像与同一场景下的新视角</p></figcaption></figure><ul><li><strong>生成三维模型</strong></li></ul><figure class=align-center><img loading=lazy src=images/3d-model.png#center alt=三维模型 width=75%><figcaption><p>三维模型</p></figcaption></figure><ul><li><strong>深度估计</strong></li></ul><figure class=align-center><img loading=lazy src=images/depth-estimation.png#center alt=深度估计 width=100%><figcaption><p>深度估计</p></figcaption></figure><h2 id=nerf-方法>NeRF 方法<a hidden class=anchor aria-hidden=true href=#nerf-方法>#</a></h2><h3 id=21-nerf使用连续神经网络表示三维场景>2.1 NeRF——使用连续神经网络表示三维场景<a hidden class=anchor aria-hidden=true href=#21-nerf使用连续神经网络表示三维场景>#</a></h3><p>NeRF 是一种三维场景的神经表征，通过输入稀疏图像训练，NeRF 可以内插出同一场景的不同影像。</p><p>下面，我们来看一下 NeRF 的具体内容。NeRF 是 Neural Radiance Fields 的缩写，神经是指神经网络，辐射是因为这个神经网络表示了场景中的辐射信息。其中的场是指一个连续的函数映射，也就是这里的 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi mathvariant="normal">Θ</mi></msub></mrow><annotation encoding="application/x-tex">F_\Theta</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8333em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.13889em>F</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.1389em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">Θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span>，神经辐射场使用一个神经网络作为这里的函数映射。另外，也需要说明这里使用的不是卷积神经网络，而是一个相对浅层的多层感知机：</p><figure class=align-center><img loading=lazy src=images/nerf-method.jpg#center alt="NeRF 方法" width=80%><figcaption><p>NeRF 方法</p></figcaption></figure><h3 id=22-2d-3d-类比>2.2 2D->3D 类比<a hidden class=anchor aria-hidden=true href=#22-2d-3d-类比>#</a></h3><p>NeRF 的问题，如果简化到二维，其实就是图像回归问题。给定一个神经网络，它的输入是平面上的坐标 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal">x</span></span></span></span> 和 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.625em;vertical-align:-.1944em></span><span class="mord mathnormal" style=margin-right:.03588em>y</span></span></span></span>，表示了一个像素，输出是该点处的颜色值 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>R</mi><mo separator="true">,</mo><mi>G</mi><mo separator="true">,</mo><mi>B</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(R,G,B)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.00773em>R</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal">G</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.05017em>B</span><span class=mclose>)</span></span></span></span>。为了能够完整地映射出原图像，这个神经网络需要记忆下原图像信息，因此在这里的神经网络是过拟合的。</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>F</mi><mi mathvariant="normal">Θ</mi></msub><mo>:</mo><mi mathvariant="bold">x</mi><mo>→</mo><mi mathvariant="bold">c</mi></mrow><annotation encoding="application/x-tex">
F_\Theta : \mathbf{x} \rightarrow \mathbf{c}
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8333em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.13889em>F</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.1389em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">Θ</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>:</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.4444em></span><span class="mord mathbf">x</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>→</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.4444em></span><span class="mord mathbf">c</span></span></span></span></span><figure class=align-center><img loading=lazy src=images/image-regression-example.jpg#center alt=图像回归示例 width=70%><figcaption><p>图像回归示例</p></figcaption></figure><p>这一问题在二维情况下，看起来是没有意义的，但这是对 NeRF 的一个很好的类推。在 NeRF 中，我们也用一个神经网络记忆了不同视角下图像信息，从而能够内插出新视角下的新图像。在 NeRF 中，我们需要神经网络是过拟合的，要求它能较好地学习到图像中的高频信息。</p><figure class="multi-figure align-center"><div class=multi-figure-container><div class=multi-figure-row data-images=3><figure class=multi-figure-item><img loading=lazy decoding=async src=images/real-image.png alt></figure><figure class=multi-figure-item><img loading=lazy decoding=async src=images/no-position-encoding.webp alt></figure><figure class=multi-figure-item><img loading=lazy decoding=async src=images/position-encoding.webp alt></figure></div></div><figcaption><p>真实图片与不使用位置编码的图像</p></figcaption></figure><p>不过，我们看到在这个二维情况下，图像信息虽然好像恢复了，但没有完全恢复，图像仍然很模糊。这个问题在后面会提到如何解决（位置编码）。</p><h3 id=23-立体渲染>2.3 立体渲染<a hidden class=anchor aria-hidden=true href=#23-立体渲染>#</a></h3><p>NeRF 如何生成特定视角下的图像？——<strong>立体渲染（volume rendering）</strong></p><ul><li>在光线上采样一系列点</li><li>通过神经网络输出颜色值和密度</li><li>将颜色值和密度累加生成图像</li></ul><figure class=align-center><img loading=lazy src=images/nerf-input-output.png#center alt="NeRF 输入与输出" width=100%><figcaption><p>NeRF 输入与输出</p></figcaption></figure><p>从这张图我们可以看到 NeRF 的输入和输出对应的具体含义。对于从左边相机拍摄的图像，以光线 1 为例，我们在上面均匀采样一系列点，这每一个点对应神经网络的输入，通过神经网络的映射，我们得到了右边对应的输出。</p><p>在得到了这一条射线上采样点的颜色值和透明度后，我们希望能得到该光线在图像上成像后的颜色值。这就需要用到 <strong>渲染</strong>。</p><p><strong>渲染就是用计算机模拟拍照这一过程，模拟“拍照”的对象是已存在的某种三维场景表示。</strong></p><p>NeRF 将场景表示为空间中任何点的密度 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal" style=margin-right:.03588em>σ</span></span></span></span> 和颜色值 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">c</mi></mrow><annotation encoding="application/x-tex">\mathbf{c}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4444em></span><span class="mord mathbf">c</span></span></span></span>。 有了以 NeRF 形式存在的场景表示后，可以对该场景进行渲染，模拟生成新视角的图片。论文使用经典 <strong>立体渲染（volume rendering）</strong> 的原理，对经过相机的光线进行均匀采样，然后积分求和得到该光线的颜色。通过求解穿过场景的任何光线的颜色，就可以渲染合成新的图像。</p><figure class=align-center><img loading=lazy src=images/nerf-volume-rendering.jpg#center alt="NeRF 立体渲染" width=40%><figcaption><p>NeRF 立体渲染</p></figcaption></figure><ul><li>渲染一条光线：<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">r</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="bold">o</mi><mo>+</mo><mi>t</mi><mi mathvariant="bold">d</mi></mrow><annotation encoding="application/x-tex">\mathbf{r}(t)=\mathbf{o}+t\mathbf{d}</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathbf">r</span><span class=mopen>(</span><span class="mord mathnormal">t</span><span class=mclose>)</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.6667em;vertical-align:-.0833em></span><span class="mord mathbf">o</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>+</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.6944em></span><span class="mord mathnormal">t</span><span class="mord mathbf">d</span></span></span></span></li></ul><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>C</mi><mo>≈</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>T</mi><mi>i</mi></msub><msub><mi>α</mi><mi>i</mi></msub><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
C \approx \sum_{i=1}^{N} T_i \alpha_i c_i
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.07153em>C</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>≈</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:3.106em;vertical-align:-1.2777em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8283em><span style=top:-1.8723em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style=top:-4.3em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.10903em>N</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2777em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal" style=margin-right:.13889em>T</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.1389em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mord><span class="mord mathnormal" style=margin-right:.0037em>α</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0037em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mord><span class="mord mathnormal">c</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:0;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span></span><ul><li>从 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">t_1</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.7651em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal">t</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3011em><span style=top:-2.55em;margin-left:0;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span></span></span></span> 起被遮挡的光线量：</li></ul><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>T</mi><mi>i</mi></msub><mo>=</mo><munderover><mo>∏</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></munderover><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>α</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
T_i = \prod_{j=1}^{i-1}(1 - \alpha_j)
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.8333em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.13889em>T</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.1389em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:3.2254em;vertical-align:-1.4138em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.8117em><span style=top:-1.8723em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.05724em>j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style=top:-4.3em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.4138em><span></span></span></span></span></span><span class=mopen>(</span><span class=mord>1</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:1.0361em;vertical-align:-.2861em></span><span class=mord><span class="mord mathnormal" style=margin-right:.0037em>α</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0037em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.05724em>j</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.2861em><span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span></span><ul><li>第 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6595em></span><span class="mord mathnormal">i</span></span></span></span> 段贡献的光线量：</li></ul><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>α</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn><mo>−</mo><msup><mi>e</mi><mrow><mo>−</mo><msub><mi>σ</mi><mi>i</mi></msub><mi>δ</mi><msub><mi>t</mi><mi>i</mi></msub></mrow></msup></mrow><annotation encoding="application/x-tex">
\alpha_i = 1 - e^{-\sigma_i \delta t_i}
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.5806em;vertical-align:-.15em></span><span class=mord><span class="mord mathnormal" style=margin-right:.0037em>α</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3117em><span style=top:-2.55em;margin-left:-.0037em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.7278em;vertical-align:-.0833em></span><span class=mord>1</span><span class=mspace style=margin-right:.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:.2222em></span></span><span class=base><span class=strut style=height:.8991em></span><span class=mord><span class="mord mathnormal">e</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8991em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style=margin-right:.03588em>σ</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3281em><span style=top:-2.357em;margin-left:-.0359em;margin-right:.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.143em><span></span></span></span></span></span></span><span class="mord mathnormal mtight" style=margin-right:.03785em>δ</span><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3281em><span style=top:-2.357em;margin-left:0;margin-right:.0714em><span class=pstrut style=height:2.5em></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.143em><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><p>从这里的公式可以看到，<strong>渲染一条光线的颜色，就是对光线上个点的颜色值进行加权求和，权由光线的路径和路径上各段的透明度确定</strong>。</p><div style=width:100%;max-width:100%><video controls width=100%>
<source src=videos/nerf-method-introduction.mp4 type=video/mp4>Your browser does not support the video tag.</video></div><h3 id=24-使用梯度下降优化渲染损失>2.4 使用梯度下降优化渲染损失<a hidden class=anchor aria-hidden=true href=#24-使用梯度下降优化渲染损失>#</a></h3><p>在渲染出一条光线的颜色后，与该光线的真实颜色对比，就可以计算出渲染的损失值。该光线的真实颜色由输出的图像确定。</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mi mathvariant="normal">Θ</mi></munder><munder><mo>∑</mo><mi>i</mi></munder><msup><mrow><mo fence="true">∥</mo><msup><mrow><mi mathvariant="normal">render</mi><mo>⁡</mo></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msup><mrow><mo fence="true">(</mo><msub><mi>F</mi><mi mathvariant="normal">Θ</mi></msub><mo fence="true">)</mo></mrow><mo>−</mo><msubsup><mi>I</mi><mrow><mi mathvariant="normal">g</mi><mi mathvariant="normal">t</mi></mrow><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup><mo fence="true">∥</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">
\min _{\Theta} \sum_i\left\|\operatorname{render}^{(i)}\left(F_{\Theta}\right)-I_{\mathrm{gt}}^{(i)}\right\|^2
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:2.6317em;vertical-align:-1.2777em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.6679em><span style=top:-2.3557em;margin-left:0><span class=pstrut style=height:3em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">Θ</span></span></span></span><span style=top:-3em><span class=pstrut style=height:3em></span><span><span class=mop>min</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.7443em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.05em><span style=top:-1.8723em;margin-left:0><span class=pstrut style=height:3.05em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style=top:-3.05em><span class=pstrut style=height:3.05em></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:1.2777em><span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class=minner><span class=mopen><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.15em><span style=top:-3.15em><span class=pstrut style=height:3.8em></span><span style=width:.556em;height:1.8em><svg width=".556em" height="1.8em" viewBox="0 0 556 1800"><path d="M145 15v585 6e2 585c2.667 10 9.667 15 21 15 10 0 16.667-5 20-15v-585-6e2V15c-2.667-10-9.667-15-21-15-10 0-16.667 5-20 15zm43 0H145v585 6e2 585h43zm179 0v585 6e2 585c2.667 10 9.667 15 21 15 10 0 16.667-5 20-15v-585-6e2V15c-2.667-10-9.667-15-21-15-10 0-16.667 5-20 15zm43 0H367v585 6e2 585h43z"/></svg></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.65em><span></span></span></span></span></span></span><span class=mop><span class=mop><span class="mord mathrm">render</span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.9723em><span style=top:-3.1473em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0>(</span><span class=mord><span class="mord mathnormal" style=margin-right:.13889em>F</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:.3283em><span style=top:-2.55em;margin-left:-.1389em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">Θ</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.15em><span></span></span></span></span></span></span><span class="mclose delimcenter" style=top:0>)</span></span><span class=mspace style=margin-right:.2222em></span><span class=mbin>−</span><span class=mspace style=margin-right:.2222em></span><span class=mord><span class="mord mathnormal" style=margin-right:.07847em>I</span><span class=msupsub><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.0448em><span style=top:-2.4542em;margin-left:-.0785em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">gt</span></span></span></span></span><span style=top:-3.2198em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.3819em><span></span></span></span></span></span></span><span class=mclose><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class=vlist-r><span class=vlist style=height:1.15em><span style=top:-3.15em><span class=pstrut style=height:3.8em></span><span style=width:.556em;height:1.8em><svg width=".556em" height="1.8em" viewBox="0 0 556 1800"><path d="M145 15v585 6e2 585c2.667 10 9.667 15 21 15 10 0 16.667-5 20-15v-585-6e2V15c-2.667-10-9.667-15-21-15-10 0-16.667 5-20 15zm43 0H145v585 6e2 585h43zm179 0v585 6e2 585c2.667 10 9.667 15 21 15 10 0 16.667-5 20-15v-585-6e2V15c-2.667-10-9.667-15-21-15-10 0-16.667 5-20 15zm43 0H367v585 6e2 585h43z"/></svg></span></span></span><span class=vlist-s>​</span></span><span class=vlist-r><span class=vlist style=height:.65em><span></span></span></span></span></span></span></span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:1.354em><span style=top:-3.6029em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><figure class=align-center><img loading=lazy src=images/nerf-rendering-loss.jpg#center alt="NeRF 渲染损失" width=70%><figcaption><p>NeRF 渲染损失</p></figcaption></figure><p>我们看到立体渲染的公式仅包含了简单的乘加和指数运算，每一步都是可微的，因此可以使用梯度下降的方式进行优化。</p><p>训练完成后，就可以得到一个以多层感知机表示的三维场景。</p><h3 id=25-位置编码>2.5 位置编码<a hidden class=anchor aria-hidden=true href=#25-位置编码>#</a></h3><p>通过前面的介绍，我们已经可以实现一个简单的 NeRF 了，这里可以看到简单实现的结果。不过我们会发现这个图像有点模糊，NeRF 模型没有很好地学习到图像中的高频信息。在论文中，作者使用了 <strong>位置编码</strong> 的方法，让神经网络能够更好地学习高频信息。</p><figure class="multi-figure align-center"><div class=multi-figure-container><div class=multi-figure-row data-images=2><figure class=multi-figure-item><img loading=lazy decoding=async src=images/nerf-naive.webp alt></figure><figure class=multi-figure-item><img loading=lazy decoding=async src=images/nerf-encoding.webp alt></figure></div></div><figcaption><p>NeRF 原始图像与位置编码</p></figcaption></figure><p>在论文中，使用了 <strong>傅里叶基函数</strong>，对输入空间坐标坐标 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x,y,z)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.03588em>y</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.04398em>z</span><span class=mclose>)</span></span></span></span> 和方向 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>θ</mi><mo separator="true">,</mo><mi>ϕ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\theta,\phi)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>(</span><span class="mord mathnormal" style=margin-right:.02778em>θ</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal">ϕ</span><span class=mclose>)</span></span></span></span> 进行编码。这里以二维为例，左图是之前的神经网络，这里多了一个 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>γ</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\gamma (x,y)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.05556em>γ</span><span class=mopen>(</span><span class="mord mathnormal">x</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class="mord mathnormal" style=margin-right:.03588em>y</span><span class=mclose>)</span></span></span></span> 的环节，也就是对输入 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal">x</span></span></span></span>，<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.625em;vertical-align:-.1944em></span><span class="mord mathnormal" style=margin-right:.03588em>y</span></span></span></span> 进行位置编码。编码的方式可以从右图中看到。<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal">x</span></span></span></span> 和 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.625em;vertical-align:-.1944em></span><span class="mord mathnormal" style=margin-right:.03588em>y</span></span></span></span> 表示了图像中像素的位置，首先将 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal">x</span></span></span></span> 和 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.625em;vertical-align:-.1944em></span><span class="mord mathnormal" style=margin-right:.03588em>y</span></span></span></span> 归一化到 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[-1,1]</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class=mopen>[</span><span class=mord>−</span><span class=mord>1</span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord>1</span><span class=mclose>]</span></span></span></span> 的区间，然后分别用傅里叶基函数进行编码，最后将两者编码的结果合并在一起。</p><span class=katex-display><span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>γ</mi><mo stretchy="false">(</mo><mi mathvariant="normal">x</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mo fence="true">(</mo><mi>sin</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msup><mn>2</mn><mn>0</mn></msup><mi>π</mi><mi mathvariant="normal">x</mi><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mi>cos</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msup><mn>2</mn><mn>0</mn></msup><mi>π</mi><mi mathvariant="normal">x</mi><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><mi>sin</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msup><mn>2</mn><mrow><mi>L</mi><mo>−</mo><mn>1</mn></mrow></msup><mi>π</mi><mi mathvariant="normal">x</mi><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mi>cos</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msup><mn>2</mn><mrow><mi>L</mi><mo>−</mo><mn>1</mn></mrow></msup><mi>π</mi><mi mathvariant="normal">x</mi><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\gamma(\mathrm{x})=\left(\sin \left(2^0 \pi \mathrm{x}\right), \cos \left(2^0 \pi \mathrm{x}\right), \cdots, \sin \left(2^{L-1} \pi \mathrm{x}\right), \cos \left(2^{L-1} \pi \mathrm{x}\right)\right)
</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-.25em></span><span class="mord mathnormal" style=margin-right:.05556em>γ</span><span class=mopen>(</span><span class="mord mathrm">x</span><span class=mclose>)</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:1.2413em;vertical-align:-.35em></span><span class=minner><span class="mopen delimcenter" style=top:0><span class="delimsizing size1">(</span></span><span class=mop>sin</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0><span class="delimsizing size1">(</span></span><span class=mord><span class=mord>2</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8641em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:.03588em>π</span><span class="mord mathrm">x</span><span class="mclose delimcenter" style=top:0><span class="delimsizing size1">)</span></span></span><span class=mspace style=margin-right:.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mop>cos</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0><span class="delimsizing size1">(</span></span><span class=mord><span class=mord>2</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8641em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:.03588em>π</span><span class="mord mathrm">x</span><span class="mclose delimcenter" style=top:0><span class="delimsizing size1">)</span></span></span><span class=mspace style=margin-right:.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=minner>⋯</span><span class=mspace style=margin-right:.1667em></span><span class=mspace style=margin-right:.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mop>sin</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0><span class="delimsizing size1">(</span></span><span class=mord><span class=mord>2</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8913em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:.03588em>π</span><span class="mord mathrm">x</span><span class="mclose delimcenter" style=top:0><span class="delimsizing size1">)</span></span></span><span class=mspace style=margin-right:.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mop>cos</span><span class=mspace style=margin-right:.1667em></span><span class=minner><span class="mopen delimcenter" style=top:0><span class="delimsizing size1">(</span></span><span class=mord><span class=mord>2</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8913em><span style=top:-3.113em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord mathnormal" style=margin-right:.03588em>π</span><span class="mord mathrm">x</span><span class="mclose delimcenter" style=top:0><span class="delimsizing size1">)</span></span></span><span class="mclose delimcenter" style=top:0><span class="delimsizing size1">)</span></span></span></span></span></span></span><figure class="multi-figure align-center"><div class=multi-figure-container><div class=multi-figure-row data-images=2><figure class=multi-figure-item><img loading=lazy decoding=async src=images/nerf-position-encoding-example.jpg alt></figure><figure class=multi-figure-item><img loading=lazy decoding=async src=images/nerf-position-encoding.gif alt></figure></div></div><figcaption><p>NeRF 加入位置编码后的图像回归示例</p></figcaption></figure><p>原来神经网络的输入是只有 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal">x</span></span></span></span>，<span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.625em;vertical-align:-.1944em></span><span class="mord mathnormal" style=margin-right:.03588em>y</span></span></span></span> 的一个二维向量，现在的输入变成了一个高维向量。</p><p>在上文中已经展示了使用位置编码后神经网络对二维图像的拟合结果，明显可以看到位置编码的结果更加清晰。</p><h3 id=26-为什么-fourier-位置编码有效>2.6 为什么 Fourier 位置编码有效？<a hidden class=anchor aria-hidden=true href=#26-为什么-fourier-位置编码有效>#</a></h3><p>这里主要是为了解释为什么傅里叶位置编码会有效？这部分偏向我个人的看法。这里进一步把二维图像回归的问题，简化为一维曲线拟合的问题。</p><figure class="multi-figure align-center"><div class=multi-figure-container><div class=multi-figure-row data-images=2><figure class=multi-figure-item><img loading=lazy decoding=async src=images/curve_fitting_poly.gif alt></figure><figure class=multi-figure-item><img loading=lazy decoding=async src=images/curve_fitting_fourier.gif alt></figure></div></div><figcaption><p>曲线拟合示例</p></figcaption></figure><p>在曲线拟合问题中，如果只输入 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal">x</span></span></span></span>，我们可以拟合一条直线，为了拟合复杂的曲线，我们从用二次曲线或三次曲线等，也就是使用 <strong>多项式基函数</strong>，将输入 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.4306em></span><span class="mord mathnormal">x</span></span></span></span>，变换为 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msup><mi>x</mi><mn>0</mn></msup><mo separator="true">,</mo><msup><mi>x</mi><mn>1</mn></msup><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msup><mi>x</mi><mi>N</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x^0,x^1,\ldots,x^N)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1.0913em;vertical-align:-.25em></span><span class=mopen>(</span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8141em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=minner>…</span><span class=mspace style=margin-right:.1667em></span><span class=mpunct>,</span><span class=mspace style=margin-right:.1667em></span><span class=mord><span class="mord mathnormal">x</span><span class=msupsub><span class=vlist-t><span class=vlist-r><span class=vlist style=height:.8413em><span style=top:-3.063em;margin-right:.05em><span class=pstrut style=height:2.7em></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style=margin-right:.10903em>N</span></span></span></span></span></span></span></span><span class=mclose>)</span></span></span></span> 等。</p><p>为了更好地拟合图像中的高频信息，可以使用 <strong>高频的基函数</strong>，如 <strong>傅里叶基函数</strong> 作为输入。从右图中可以看到，当 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">L=8</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal">L</span><span class=mspace style=margin-right:.2778em></span><span class=mrel>=</span><span class=mspace style=margin-right:.2778em></span></span><span class=base><span class=strut style=height:.6444em></span><span class=mord>8</span></span></span></span> 时，傅里叶基函数对高频信息有较好的拟合。不过，这里的 <span class=katex><span class=katex-mathml><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:.6833em></span><span class="mord mathnormal" style=margin-right:.10903em>N</span></span></span></span> 也不宜选择过大，会增加图像中的噪声。</p><h2 id=实验>实验<a hidden class=anchor aria-hidden=true href=#实验>#</a></h2><ul><li><a href=https://github.com/colmap/colmap>colmap</a></li></ul><p>Colmap 是一个开源的三维重建框架，提供了通用的运动恢复结构（SFM）和立体几何重建的相关功能。在实验中可用于获取相机的真实位姿。</p><ul><li><a href=https://github.com/NVlabs/instant-ngp>instant-ngp</a></li></ul><p>instant-ngp 是英伟达实验室发布的一个使用 NeRF 快速三维重建的项目，能够在几秒内实现 NeRF 训练的收敛，在实际测试中，通常 2-3 秒可以看到结果，在 2 分钟内基本可以稳定下来。</p><h2 id=参考资料>参考资料<a hidden class=anchor aria-hidden=true href=#参考资料>#</a></h2><ol><li>Mildenhall, Ben, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi and Ren Ng. 2020. “NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis.” In <em>ECCV</em>.</li><li>Tancik, Matthew, Pratul Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan Barron, and Ren Ng. 2020. “Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains.” In <em>NIPS</em>.</li><li>Mescheder, Lars, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and Andreas Geiger. 2019. “Occupancy Networks: Learning 3D Reconstruction in Function Space.” In <em>CVPR</em>.</li><li>“NeRF: Neural Radiance Fields.” <a href="https://www.youtube.com/watch?v=LRAqeM8EjOo">https://www.youtube.com/watch?v=LRAqeM8EjOo</a>.</li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://kenanking.github.io/tags/nerf/>NeRF</a></li></ul><nav class=paginav><a class=prev href=https://kenanking.github.io/posts/2025/02-dino-visualization/><span class=title>« Prev</span><br><span>DINOv2 可视化 🦖</span>
</a><a class=next href=https://kenanking.github.io/posts/2024/02-word2vec/><span class=title>Next »</span><br><span>词嵌入方法（Word2Vec）</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://kenanking.github.io/>Yan Tang</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){function e(){var e,t,n,s=document.getElementsByTagName("code");for(n=0;n<s.length;){if(t=s[n],t.parentNode.tagName!=="PRE"&&t.childElementCount===0&&(e=t.textContent,/^\$[^$]/.test(e)&&/[^$]\$$/.test(e)&&(e=e.replace(/^\$/,"\\(").replace(/\$$/,"\\)"),t.textContent=e),/^\\\((.|\s)+\\\)$/.test(e)||/^\\\[(.|\s)+\\\]$/.test(e)||/^\$(.|\s)+\$$/.test(e)||/^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(e))){t.outerHTML=t.innerHTML;continue}n++}}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",e,{once:!0}):e()})()</script><script>(function(){var n=window.pageYOffset||document.documentElement.scrollTop||0,s=800,t=!1,e=null;function o(){if(t=!1,e||(e=document.getElementById("top-link")),!e)return;var o=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,i=o>n;n=o<0?0:o,o>s&&!i?(e.style.visibility="visible",e.style.opacity="1"):(e.style.visibility="hidden",e.style.opacity="0")}window.addEventListener("scroll",function(){t||(window.requestAnimationFrame(o),t=!0)},{passive:!0})})()</script><script>(function(){var t=10;function n(e){if(!e)return[0,20];var n,s,o=window.getComputedStyle(e),t=parseFloat(o.lineHeight);return(!t||isNaN(t))&&(t=20),n=e.getBoundingClientRect(),s=n.height||e.offsetHeight||0,[Math.round(s/t),t]}function e(){var e=document.querySelectorAll(".highlight");if(!e||!e.length)return;Array.prototype.forEach.call(e,function(e){if(e.classList.contains("expanded")||e.classList.contains("collapsible"))return;var s,o,a,r,c,l,i=e.querySelector("pre code");if(!i)return;if(r=i.className||"",r.indexOf("language-mermaid")>=0||e.classList.contains("mermaid"))return;if(a=n(i),c=a[0],l=a[1],c<=t)return;e.classList.add("collapsible"),e.style.setProperty("--code-line-height",l+"px"),e.id||(e.id="code-block-"+Math.random().toString(36).slice(2)),o=document.createElement("div"),o.className="code-expand-wrapper",s=document.createElement("button"),s.type="button",s.className="code-expand-link",s.textContent="Show more",s.setAttribute("aria-expanded","false"),s.setAttribute("aria-controls",e.id),s.addEventListener("click",function(){var n,i,a,o=e.classList.contains("expanded"),r=getComputedStyle(e).getPropertyValue("--code-line-height"),t=parseFloat(r)*(parseFloat(getComputedStyle(e).getPropertyValue("--code-max-lines"))||10);(!isFinite(t)||t<=0)&&(t=10*20),i=e.getBoundingClientRect().height,a=o?t:e.scrollHeight,e.style.maxHeight=i+"px",e.offsetHeight,o?e.classList.remove("expanded"):e.classList.add("expanded"),e.style.maxHeight=a+"px",n=function(t){if(t.propertyName!=="max-height")return;if(e.removeEventListener("transitionend",n),e.style.maxHeight="",e.classList.contains("expanded"))s.textContent="Show less",s.setAttribute("aria-expanded","true");else{s.textContent="Show more",s.setAttribute("aria-expanded","false");try{e.scrollIntoView({behavior:"smooth",block:"nearest"})}catch{}}window.dispatchEvent(new Event("resize"))},e.addEventListener("transitionend",n)}),o.appendChild(s),e.nextSibling?e.parentNode.insertBefore(o,e.nextSibling):e.parentNode.appendChild(o)})}document.readyState==="loading"?document.addEventListener("DOMContentLoaded",e,{once:!0}):e()})()</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>