<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Yan Tang</title><link>https://ehehe.cn/</link><description>Recent content on Yan Tang</description><generator>Hugo -- 0.154.5</generator><language>zh-cn</language><lastBuildDate>Wed, 19 Nov 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://ehehe.cn/index.xml" rel="self" type="application/rss+xml"/><item><title>LeJEPAï¼šå¯è¯æ˜ã€å¯æ‰©å±•çš„è‡ªç›‘ç£å­¦ä¹ æ–°èŒƒå¼</title><link>https://ehehe.cn/posts/2025/04-lejepa/</link><pubDate>Wed, 19 Nov 2025 00:00:00 +0000</pubDate><guid>https://ehehe.cn/posts/2025/04-lejepa/</guid><description>æœ¬æ–‡è®°å½•äº† LeJEPA è®ºæ–‡çš„é˜…è¯»ç¬”è®°ã€‚</description></item><item><title>æ·±å…¥ç†è§£ PyTorch SGD ä¼˜åŒ–å™¨å‚æ•°</title><link>https://ehehe.cn/posts/2025/03-pytorch-sgd-optimizer/</link><pubDate>Wed, 05 Nov 2025 00:00:00 +0000</pubDate><guid>https://ehehe.cn/posts/2025/03-pytorch-sgd-optimizer/</guid><description>æœ¬æ–‡é€šè¿‡å¯è§†åŒ–æŸå¤±å‡½æ•°å’Œæ¢¯åº¦ä¸‹é™è·¯å¾„ï¼Œæ·±å…¥æ¢è®¨äº† PyTorch SGD ä¼˜åŒ–å™¨ä¸­çš„å„ç§å‚æ•°ï¼ˆå¦‚åŠ¨é‡ã€æƒé‡è¡°å‡ã€Nesterov åŠ¨é‡ã€åŠ¨é‡æŠ‘åˆ¶å› å­ç­‰ï¼‰å¯¹ç®€å•çº¿æ€§å›å½’é—®é¢˜çš„å½±å“ï¼Œä»¥æ·±å…¥ç†è§£ç¥ç»ç½‘ç»œè®­ç»ƒä¸­çš„å¤æ‚æ€§ã€‚</description></item><item><title>Flow-SAR: Cross-Domain SAR Image Translation Using Flow Models</title><link>https://ehehe.cn/publications/2025-flow-sar/</link><pubDate>Wed, 03 Sep 2025 00:00:00 +0000</pubDate><guid>https://ehehe.cn/publications/2025-flow-sar/</guid><description>We propose Flow-SAR, a two-stage SAR image cross-domain translation framework using invertible flow models to address domain discrepancy in SAR target recognition. Unlike GAN-based methods that suffer from training instability, Flow-SAR maps domains to a shared latent space with Gaussian prior and aligns distributions through latent translation. The framework first estimates a global translation vector for coarse alignment, then refines with class-specific vectors using pseudo-labeling to enhance intra-class consistency. Experiments on SAMPLE dataset show Flow-SAR improves both visual realism and target recognition performance.</description></item><item><title>å¼ºåŒ–å­¦ä¹ ç© Flappy Bird</title><link>https://ehehe.cn/posts/2025/01-flappy-bird-dqn/</link><pubDate>Sun, 24 Aug 2025 20:18:30 +0000</pubDate><guid>https://ehehe.cn/posts/2025/01-flappy-bird-dqn/</guid><description>Flappy Bird æ˜¯ä¸€æ¬¾çœ‹ä¼¼ç®€å•çš„ç§»åŠ¨ç«¯æ¸¸æˆï¼Œç©å®¶éœ€è¦æ§åˆ¶ä¸€åªå°é¸Ÿå‘å‰é£è¡Œï¼Œå¹¶ç©¿è¶Šä¸€ç³»åˆ—éšœç¢ç‰©ã€‚å°é¸Ÿåªæœ‰é£ç¿”å’Œä¸‹è½ä¸¤ç§åŠ¨ä½œï¼Œé€šè¿‡æ§åˆ¶å°é¸Ÿçš„é£è¡Œé«˜åº¦æ¥ç©¿è¶Šéšœç¢ç‰©ã€‚æœ¬æ–‡è®°å½•äº†æˆ‘ä½¿ç”¨ DQN è®­ç»ƒ Flappy Bird çš„è¿‡ç¨‹ã€‚</description></item><item><title>Through-Wall Human Activity Recognition with Compact MIMO Ultra-Wideband Radar</title><link>https://ehehe.cn/publications/2025-through-wall-har/</link><pubDate>Mon, 14 Jul 2025 00:00:00 +0000</pubDate><guid>https://ehehe.cn/publications/2025-through-wall-har/</guid><description>An integrated human activity recognition system that combines compact MIMO ultra-wideband radar with deep learning approaches, achieving 99% recognition accuracy in through-wall environments and representing an 8% improvement over state-of-the-art methods.</description></item><item><title>Ultra-Lightweight Automatic License Plate Recognition System for Microcontrollers: A Cost-Effective and Energy-Efficient Solution</title><link>https://ehehe.cn/publications/2024-tiny-alpr/</link><pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate><guid>https://ehehe.cn/publications/2024-tiny-alpr/</guid><description>A novel ultra-lightweight ALPR system specifically designed for deployment on microcontrollers, offering a cost-effective and energy-efficient solution for large-scale applications and naturally mitigates the issues of large perspective transformations frequently encountered in real-world settings.</description></item><item><title>DINOv2 å¯è§†åŒ– ğŸ¦–</title><link>https://ehehe.cn/posts/2025/02-dino-visualization/</link><pubDate>Sat, 09 Nov 2024 00:00:00 +0000</pubDate><guid>https://ehehe.cn/posts/2025/02-dino-visualization/</guid><description>ä»‹ç»å¦‚ä½•é€šè¿‡ PCA æ–¹å¼å¯è§†åŒ– DINOv2 æ¨¡å‹çš„å›¾åƒåµŒå…¥è¡¨ç¤ºã€‚</description></item><item><title>Style Reconstruction-Driven Networks for Occlusion-Aware License Plate Recognition</title><link>https://ehehe.cn/publications/2024-style-reconstruction/</link><pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate><guid>https://ehehe.cn/publications/2024-style-reconstruction/</guid><description>A novel style reconstruction-based network that can transform input license plates into standardized images and addresses the class imbalance in existing license plate datasets by computes character prediction confidence using a lightweight matching module.</description></item><item><title>åŸºäº NeRF çš„ä¸‰ç»´åœºæ™¯ç”Ÿæˆ</title><link>https://ehehe.cn/posts/2024/01-nerf/</link><pubDate>Thu, 29 Feb 2024 14:20:32 +0000</pubDate><guid>https://ehehe.cn/posts/2024/01-nerf/</guid><description>åŸºäº NeRF çš„ä¸‰ç»´åœºæ™¯ç”Ÿæˆ</description></item><item><title>è¯åµŒå…¥æ–¹æ³•ï¼ˆWord2Vecï¼‰</title><link>https://ehehe.cn/posts/2024/02-word2vec/</link><pubDate>Wed, 28 Feb 2024 23:06:29 +0000</pubDate><guid>https://ehehe.cn/posts/2024/02-word2vec/</guid><description>æœ¬ç¯‡æ–‡ç« ä»‹ç»äº†Word2Vecæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡åœ¨ç»™å®šä¸­å¿ƒè¯çš„æƒ…å†µä¸‹é¢„æµ‹ä¸Šä¸‹æ–‡è¯çš„æ¦‚ç‡æ¥å­¦ä¹ å•è¯çš„åˆ†å¸ƒå¼è¡¨ç¤ºï¼Œä»è€Œå…‹æœäº†ç‹¬çƒ­è¡¨ç¤ºçš„ç¼ºç‚¹ï¼Œæé«˜äº†è¯æ±‡ç›¸ä¼¼åº¦çš„è¡¨è¾¾èƒ½åŠ›ã€‚</description></item><item><title>A CFAR-Enhanced Ship Detector for SAR Images Based on YOLOv5s</title><link>https://ehehe.cn/publications/2024-cfar-ship-detector/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://ehehe.cn/publications/2024-cfar-ship-detector/</guid><description>Proposes a YOLOv5s-based ship detection method for SAR images with CFAR enhancement. The method introduces a sub-net to learn traditional features, augmenting ship feature representation and incorporating frequency-domain information into channel attention mechanisms, achieving 68.04% detection accuracy and 60.25% recall with a compact 18.51M model size.</description></item><item><title>Swin Transformerï¼šå±‚çº§å¼ç‰¹å¾å›¾ä¸ç§»åŠ¨çª—å£æ³¨æ„åŠ›æœºåˆ¶</title><link>https://ehehe.cn/posts/2023/02-swin-transformer/</link><pubDate>Wed, 09 Aug 2023 00:00:00 +0000</pubDate><guid>https://ehehe.cn/posts/2023/02-swin-transformer/</guid><description>Swin Transformer æ˜¯ä¸€ç§åˆ›æ–°çš„ Vision Transformer æ¶æ„ï¼Œé€šè¿‡å¼•å…¥å±‚çº§å¼ç‰¹å¾å›¾å’Œç§»åŠ¨çª—å£æ³¨æ„åŠ›æœºåˆ¶ï¼Œè§£å†³äº† Vision Transformer åœ¨è®¡ç®—å¤æ‚åº¦å’Œå¤šå°ºåº¦ç‰¹å¾æå–æ–¹é¢çš„é™åˆ¶ï¼Œä½¿å…¶æˆä¸ºè®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­é«˜æ•ˆçš„éª¨å¹²ç½‘ç»œã€‚</description></item><item><title>Vision Transformer â€”â€” å›¾åƒè¯†åˆ«ä¸­çš„ Transformer æ¶æ„</title><link>https://ehehe.cn/posts/2023/01-vit/</link><pubDate>Wed, 26 Jul 2023 15:27:24 +0000</pubDate><guid>https://ehehe.cn/posts/2023/01-vit/</guid><description>æœ¬æ–‡ä»‹ç»äº† Vision Transformer (ViT) çš„æ ¸å¿ƒæ¦‚å¿µï¼ŒåŒ…æ‹¬å¦‚ä½•å°† Transformer æ¶æ„åº”ç”¨äºå›¾åƒè¯†åˆ«ä»»åŠ¡ï¼Œä»¥åŠä¸ä¼ ç»Ÿ CNNs çš„æ¯”è¾ƒã€‚</description></item><item><title>DeepLabv2ï¼šåŸºäºç©ºæ´å·ç§¯ä¸ ASPP çš„è¯­ä¹‰å›¾åƒåˆ†å‰²</title><link>https://ehehe.cn/posts/2023/07-deeplabv2/</link><pubDate>Tue, 04 Jul 2023 00:00:00 +0000</pubDate><guid>https://ehehe.cn/posts/2023/07-deeplabv2/</guid><description>DeepLabv2 é€šè¿‡ç©ºæ´å·ç§¯å’Œä¸Šé‡‡æ ·æ»¤æ³¢å™¨è¿›è¡Œå¯†é›†ç‰¹å¾æå–ï¼Œå°†åœ¨å›¾åƒåˆ†ç±»ä¸Šè®­ç»ƒçš„ç½‘ç»œé‡æ–°ç”¨äºè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ã€‚æ–‡ä¸­è¿›ä¸€æ­¥æå‡ºASPPä»¥åœ¨å¤šä¸ªå°ºåº¦ä¸Šç¼–ç å¯¹è±¡ä»¥åŠå›¾åƒä¸Šä¸‹æ–‡ã€‚ä¸ºäº†äº§ç”Ÿè¯­ä¹‰å‡†ç¡®çš„é¢„æµ‹å’Œç²¾ç»†çš„ç‰©ä½“è¾¹ç•Œåˆ†å‰²å›¾ï¼Œæ–‡ä¸­è¿˜ç»“åˆäº†æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œå’Œå…¨è¿æ¥æ¡ä»¶éšæœºåœºçš„æ€æƒ³ã€‚</description></item><item><title>æœºå™¨å­¦ä¹ ä¸­çš„çˆ±å› æ–¯å¦æ±‚å’Œï¼ˆEinsumsï¼‰</title><link>https://ehehe.cn/posts/2022/01-einsums/</link><pubDate>Sun, 20 Mar 2022 12:32:44 +0000</pubDate><guid>https://ehehe.cn/posts/2022/01-einsums/</guid><description>æœºå™¨å­¦ä¹ ä¸­çš„çˆ±å› æ–¯å¦æ±‚å’Œï¼ˆEinsumsï¼‰</description></item><item><title>ç»“åˆè¡Œé©¶åœºæ™¯è¯­ä¹‰çš„è½¨è¿¹-è·¯ç½‘å®æ—¶åŒ¹é…æ–¹æ³•</title><link>https://ehehe.cn/publications/2021-realtime-map-matching/</link><pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate><guid>https://ehehe.cn/publications/2021-realtime-map-matching/</guid><description>æå‡ºäº†ä¸€ç§ç»“åˆè¡Œé©¶åœºæ™¯è¯­ä¹‰çš„è½¨è¿¹-è·¯ç½‘å®æ—¶åŒ¹é…æ–¹æ³•ã€‚è¯¥æ–¹æ³•åœ¨æ™ºèƒ½äº¤é€šã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸèµ·ç€å…³é”®ä½œç”¨ï¼Œé€šè¿‡è€ƒè™‘è¡Œé©¶åœºæ™¯çš„è¯­ä¹‰ä¿¡æ¯æ¥æé«˜åœ°å›¾åŒ¹é…çš„å‡†ç¡®æ€§å’Œå®æ—¶æ€§ã€‚</description></item><item><title>About</title><link>https://ehehe.cn/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ehehe.cn/about/</guid><description>About Yan Tang</description></item></channel></rss>