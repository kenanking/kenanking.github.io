<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Yan Tang</title><link>https://kenanking.github.io/</link><description>Recent content on Yan Tang</description><generator>Hugo -- 0.150.1</generator><language>zh-cn</language><lastBuildDate>Wed, 03 Sep 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://kenanking.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Flow-SAR: Cross-Domain SAR Image Translation Using Flow Models</title><link>https://kenanking.github.io/publications/2025-flow-sar/</link><pubDate>Wed, 03 Sep 2025 00:00:00 +0000</pubDate><guid>https://kenanking.github.io/publications/2025-flow-sar/</guid><description>We propose Flow-SAR, a two-stage SAR image cross-domain translation framework using invertible flow models to address domain discrepancy in SAR target recognition. Unlike GAN-based methods that suffer from training instability, Flow-SAR maps domains to a shared latent space with Gaussian prior and aligns distributions through latent translation. The framework first estimates a global translation vector for coarse alignment, then refines with class-specific vectors using pseudo-labeling to enhance intra-class consistency. Experiments on SAMPLE dataset show Flow-SAR improves both visual realism and target recognition performance.</description></item><item><title>强化学习玩 Flappy Bird</title><link>https://kenanking.github.io/posts/2025/01-flappy-bird-dqn/</link><pubDate>Sun, 24 Aug 2025 20:18:30 +0000</pubDate><guid>https://kenanking.github.io/posts/2025/01-flappy-bird-dqn/</guid><description>Flappy Bird 是一款看似简单的移动端游戏，玩家需要控制一只小鸟向前飞行，并穿越一系列障碍物。小鸟只有飞翔和下落两种动作，通过控制小鸟的飞行高度来穿越障碍物。本文记录了我使用 DQN 训练 Flappy Bird 的过程。</description></item><item><title>Through-Wall Human Activity Recognition with Compact MIMO Ultra-Wideband Radar</title><link>https://kenanking.github.io/publications/2025-through-wall-har/</link><pubDate>Mon, 14 Jul 2025 00:00:00 +0000</pubDate><guid>https://kenanking.github.io/publications/2025-through-wall-har/</guid><description>An integrated human activity recognition system that combines compact MIMO ultra-wideband radar with deep learning approaches, achieving 99% recognition accuracy in through-wall environments and representing an 8% improvement over state-of-the-art methods.</description></item><item><title>Ultra-Lightweight Automatic License Plate Recognition System for Microcontrollers: A Cost-Effective and Energy-Efficient Solution</title><link>https://kenanking.github.io/publications/2024-tiny-alpr/</link><pubDate>Sun, 01 Dec 2024 00:00:00 +0000</pubDate><guid>https://kenanking.github.io/publications/2024-tiny-alpr/</guid><description>A novel ultra-lightweight ALPR system specifically designed for deployment on microcontrollers, offering a cost-effective and energy-efficient solution for large-scale applications and naturally mitigates the issues of large perspective transformations frequently encountered in real-world settings.</description></item><item><title>DINOv2 可视化 🦖</title><link>https://kenanking.github.io/posts/2025/02-dino-visualization/</link><pubDate>Sat, 09 Nov 2024 00:00:00 +0000</pubDate><guid>https://kenanking.github.io/posts/2025/02-dino-visualization/</guid><description>介绍如何通过 PCA 方式可视化 DINOv2 模型的图像嵌入表示。</description></item><item><title>Style Reconstruction-Driven Networks for Occlusion-Aware License Plate Recognition</title><link>https://kenanking.github.io/publications/2024-style-reconstruction/</link><pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate><guid>https://kenanking.github.io/publications/2024-style-reconstruction/</guid><description>A novel style reconstruction-based network that can transform input license plates into standardized images and addresses the class imbalance in existing license plate datasets by computes character prediction confidence using a lightweight matching module.</description></item><item><title>基于 NeRF 的三维场景生成</title><link>https://kenanking.github.io/posts/2024/01-nerf/</link><pubDate>Thu, 29 Feb 2024 14:20:32 +0000</pubDate><guid>https://kenanking.github.io/posts/2024/01-nerf/</guid><description>基于 NeRF 的三维场景生成</description></item><item><title>词嵌入方法（Word2Vec）</title><link>https://kenanking.github.io/posts/2024/02-word2vec/</link><pubDate>Wed, 28 Feb 2024 23:06:29 +0000</pubDate><guid>https://kenanking.github.io/posts/2024/02-word2vec/</guid><description>本篇文章介绍了Word2Vec方法，该方法通过在给定中心词的情况下预测上下文词的概率来学习单词的分布式表示，从而克服了独热表示的缺点，提高了词汇相似度的表达能力。</description></item><item><title>A CFAR-Enhanced Ship Detector for SAR Images Based on YOLOv5s</title><link>https://kenanking.github.io/publications/2024-cfar-ship-detector/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://kenanking.github.io/publications/2024-cfar-ship-detector/</guid><description>Proposes a YOLOv5s-based ship detection method for SAR images with CFAR enhancement. The method introduces a sub-net to learn traditional features, augmenting ship feature representation and incorporating frequency-domain information into channel attention mechanisms, achieving 68.04% detection accuracy and 60.25% recall with a compact 18.51M model size.</description></item><item><title>Swin Transformer：层级式特征图与移动窗口注意力机制</title><link>https://kenanking.github.io/posts/2023/02-swin-transformer/</link><pubDate>Wed, 09 Aug 2023 00:00:00 +0000</pubDate><guid>https://kenanking.github.io/posts/2023/02-swin-transformer/</guid><description>Swin Transformer 是一种创新的 Vision Transformer 架构，通过引入层级式特征图和移动窗口注意力机制，解决了 Vision Transformer 在计算复杂度和多尺度特征提取方面的限制，使其成为计算机视觉任务中高效的骨干网络。</description></item><item><title>Vision Transformer —— 图像识别中的 Transformer 架构</title><link>https://kenanking.github.io/posts/2023/01-vit/</link><pubDate>Wed, 26 Jul 2023 15:27:24 +0000</pubDate><guid>https://kenanking.github.io/posts/2023/01-vit/</guid><description>本文介绍了 Vision Transformer (ViT) 的核心概念，包括如何将 Transformer 架构应用于图像识别任务，以及与传统 CNNs 的比较。</description></item><item><title>DeepLabv2：基于空洞卷积与 ASPP 的语义图像分割</title><link>https://kenanking.github.io/posts/2023/07-deeplabv2/</link><pubDate>Tue, 04 Jul 2023 00:00:00 +0000</pubDate><guid>https://kenanking.github.io/posts/2023/07-deeplabv2/</guid><description>DeepLabv2 通过空洞卷积和上采样滤波器进行密集特征提取，将在图像分类上训练的网络重新用于语义分割任务。文中进一步提出ASPP以在多个尺度上编码对象以及图像上下文。为了产生语义准确的预测和精细的物体边界分割图，文中还结合了深度卷积神经网络和全连接条件随机场的思想。</description></item><item><title>机器学习中的爱因斯坦求和（Einsums）</title><link>https://kenanking.github.io/posts/2022/01-einsums/</link><pubDate>Sun, 20 Mar 2022 12:32:44 +0000</pubDate><guid>https://kenanking.github.io/posts/2022/01-einsums/</guid><description>机器学习中的爱因斯坦求和（Einsums）</description></item><item><title>结合行驶场景语义的轨迹-路网实时匹配方法</title><link>https://kenanking.github.io/publications/2021-realtime-map-matching/</link><pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate><guid>https://kenanking.github.io/publications/2021-realtime-map-matching/</guid><description>提出了一种结合行驶场景语义的轨迹-路网实时匹配方法。该方法在智能交通、自动驾驶等领域起着关键作用，通过考虑行驶场景的语义信息来提高地图匹配的准确性和实时性。</description></item><item><title>About</title><link>https://kenanking.github.io/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://kenanking.github.io/about/</guid><description>About Yan Tang</description></item></channel></rss>